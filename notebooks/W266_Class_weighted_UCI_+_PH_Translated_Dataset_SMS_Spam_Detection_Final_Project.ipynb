{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W266: Class-weighted UCI + PH Translated Dataset SMS Spam Detection Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MySc4TsBTRdT",
        "HCn1BoEaPA6E",
        "JqfIxHLRPFqv",
        "nvR_4nFjOZ8W"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Table of content and model results\n",
        "\n"
      ],
      "metadata": {
        "id": "zL6g1T8Jeyi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zewIcVHferk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "AitRMbM6R_23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.8.3 --quiet"
      ],
      "metadata": {
        "id": "uFMQmofaT2x_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7423df-1bf6-4955-efa5-107bf6c73a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "id": "ZepWG26Pb36a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4207124f-41a2-438e-d8be-e7a6d1864700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 53.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-text==2.8.2 --quiet"
      ],
      "metadata": {
        "id": "LBz57saHcLid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584199c9-3417-422c-88e6-c5a965715c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 3.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# misc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)\n",
        "\n",
        "# report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.utils import compute_class_weight\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# word2vec\n",
        "import nltk\n",
        "import gensim\n",
        "from nltk.data import find\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "# BERT\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "metadata": {
        "id": "EvPhbSW1rrdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LYU51GnwRSs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba164646-f540-4ea0-a603-88d311915340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and clean data"
      ],
      "metadata": {
        "id": "U6oStQMXSEyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename uci data to just data\n",
        "#data = pd.read_csv(\"/content/drive/MyDrive/W266: SMS Spam Detection Final Project/data/data_clean_trans.csv\")\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/W266/data/data_clean_trans.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "E2RqNNQxKuVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "0023a30d-28dd-4f47-b64d-a91cdfac22fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  spam                                               text  \\\n",
              "0              0     0  Go until jurong point, crazy.. Available only ...   \n",
              "1              1     0                    Ok lar... Joking wif u oni...\\n   \n",
              "2              2     1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3              3     0  U dun say so early hor... U c already then say...   \n",
              "4              4     0  Nah I don't think he goes to usf, he lives aro...   \n",
              "...          ...   ...                                                ...   \n",
              "6102        6102     1  You have passed the official certification onl...   \n",
              "6103        6103     1  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...   \n",
              "6104        6104     1  Hi, I'm a Shopee Hiring Manager and I'm curren...   \n",
              "6105        6105     1  4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...   \n",
              "6106        6106     1  Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...   \n",
              "\n",
              "      crowd                                            spanish language  \\\n",
              "0         0  Vaya hasta Jurong Point, loco ... disponible s...       en   \n",
              "1         0               Ok lar ... bromeando wif u oni ...\\n       en   \n",
              "2         0  Entrada gratuita en 2 una compensación de wkly...       en   \n",
              "3         0    No digo tan temprano hor ... ya c ya digo ...\\n       en   \n",
              "4         0  No, no creo que vaya a la USF, aunque vive por...       en   \n",
              "...     ...                                                ...      ...   \n",
              "6102      1  Ha aprobado la certificación oficial de la aud...       en   \n",
              "6103      1  ¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...       en   \n",
              "6104      1  Hola, soy un gerente de contratación de Shopee...       en   \n",
              "6105      1  ¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...      fil   \n",
              "6106      1  Sissy, solo 1p por apuesta para Cutt.ly/BingOp...      fil   \n",
              "\n",
              "                                                english  \n",
              "0     Go until jurong point, crazy.. Available only ...  \n",
              "1                       Ok lar... Joking wif u oni...\\n  \n",
              "2     Free entry in 2 a wkly comp to win FA Cup fina...  \n",
              "3     U dun say so early hor... U c already then say...  \n",
              "4     Nah I don't think he goes to usf, he lives aro...  \n",
              "...                                                 ...  \n",
              "6102  You have passed the official certification onl...  \n",
              "6103  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...  \n",
              "6104  Hi, I'm a Shopee Hiring Manager and I'm curren...  \n",
              "6105  4 pcs solar lights for only 1,499!\\nMost cheap...  \n",
              "6106  Sissy, just 1p per bet for cutt.ly/bingoplus-p...  \n",
              "\n",
              "[6107 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2816b585-a507-4358-bae3-40dde4da7ec5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>spam</th>\n",
              "      <th>text</th>\n",
              "      <th>crowd</th>\n",
              "      <th>spanish</th>\n",
              "      <th>language</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Vaya hasta Jurong Point, loco ... disponible s...</td>\n",
              "      <td>en</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar ... bromeando wif u oni ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>0</td>\n",
              "      <td>Entrada gratuita en 2 una compensación de wkly...</td>\n",
              "      <td>en</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "      <td>No digo tan temprano hor ... ya c ya digo ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "      <td>No, no creo que vaya a la USF, aunque vive por...</td>\n",
              "      <td>en</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6102</th>\n",
              "      <td>6102</td>\n",
              "      <td>1</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "      <td>1</td>\n",
              "      <td>Ha aprobado la certificación oficial de la aud...</td>\n",
              "      <td>en</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6103</th>\n",
              "      <td>6103</td>\n",
              "      <td>1</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...</td>\n",
              "      <td>en</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6104</th>\n",
              "      <td>6104</td>\n",
              "      <td>1</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "      <td>1</td>\n",
              "      <td>Hola, soy un gerente de contratación de Shopee...</td>\n",
              "      <td>en</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6105</th>\n",
              "      <td>6105</td>\n",
              "      <td>1</td>\n",
              "      <td>4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...</td>\n",
              "      <td>fil</td>\n",
              "      <td>4 pcs solar lights for only 1,499!\\nMost cheap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6106</th>\n",
              "      <td>6106</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, solo 1p por apuesta para Cutt.ly/BingOp...</td>\n",
              "      <td>fil</td>\n",
              "      <td>Sissy, just 1p per bet for cutt.ly/bingoplus-p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6107 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2816b585-a507-4358-bae3-40dde4da7ec5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2816b585-a507-4358-bae3-40dde4da7ec5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2816b585-a507-4358-bae3-40dde4da7ec5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.convert_dtypes()\n",
        "data.dtypes"
      ],
      "metadata": {
        "id": "47UovwLKgvce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b51c60-dffb-4dc2-bdad-9a58452807e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0     Int64\n",
              "spam           Int64\n",
              "text          string\n",
              "crowd          Int64\n",
              "spanish       string\n",
              "language      string\n",
              "english       string\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "0RuqEtIVSOkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(data[\"spam\"] == 1)"
      ],
      "metadata": {
        "id": "n6pRHRdg8MoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31936ed0-dc71-4fb3-c796-9145b765d3dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1280"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(data[\"spam\"] == 0)"
      ],
      "metadata": {
        "id": "DKlzqlpy8u1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880a25f3-732f-462b-e2a7-8f3401966f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4827"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data"
      ],
      "metadata": {
        "id": "GmTIZRghbCkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data['english'], data['spam']\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)\n"
      ],
      "metadata": {
        "id": "KlJMJlhpVtnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class weight"
      ],
      "metadata": {
        "id": "yf42Dg_m-0kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_weight = compute_class_weight(class_weight ='balanced',\n",
        "                                               classes=np.unique(train_y),\n",
        "                                               y=train_y)\n",
        "class_weight = dict(zip(np.unique(np.unique(train_y)), class_weight))\n",
        "class_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tXF-vc3-x2l",
        "outputId": "c862a039-c4a9-4650-e300-cd3bfefed587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.6314632885211996, 1: 2.4016715830875124}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "VVX5ga_ODFrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(test_name, y_true, y_pred):\n",
        "    print('%s: accuracy = %.4f, precision = %.4f, recall = %.4f, f1 = %.4f'\n",
        "          % (test_name,\n",
        "             metrics.accuracy_score(y_true, y_pred),\n",
        "             metrics.precision_score(y_true, y_pred),\n",
        "             metrics.recall_score(y_true, y_pred),\n",
        "             metrics.f1_score(y_true, y_pred)))"
      ],
      "metadata": {
        "id": "rYG1iASIDEj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base models\n",
        "\n",
        "- Word2Vec embeddings\n",
        "  - CNN\n",
        "  - LSTM\n",
        "\n",
        "- BERT embeddings\n",
        "  - Fully connected network\n",
        "  - CNN\n"
      ],
      "metadata": {
        "id": "K0oBtsKoSTEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Word2Vec embeddings"
      ],
      "metadata": {
        "id": "MySc4TsBTRdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('word2vec_sample')"
      ],
      "metadata": {
        "id": "7BFkjykfSUQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c5a21e-d44a-4797-b748-e8f011da3013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))"
      ],
      "metadata": {
        "id": "Gz7wtvLeXJb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
      ],
      "metadata": {
        "id": "uY2qQt3oTxpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a Word2Vec embedding\n",
        "EMBEDDING_DIM = len(model['university'])      # we know... it's 300\n",
        "\n",
        "# initialize embedding matrix and word-to-id map:\n",
        "embedding_matrix = np.zeros((len(model.vocab.keys()) + 1, EMBEDDING_DIM))       \n",
        "vocab_dict = {}\n",
        "\n",
        "# build the embedding matrix and the word-to-id map:\n",
        "for i, word in enumerate(model.vocab.keys()):\n",
        "    embedding_vector = model[word]\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        vocab_dict[word] = i\n",
        "\n"
      ],
      "metadata": {
        "id": "LJwX14iJWwvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "train_tokens = tokenizer.tokenize(train_X)\n",
        "test_tokens = tokenizer.tokenize(test_X)"
      ],
      "metadata": {
        "id": "hlQF33RqYvfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens[0]"
      ],
      "metadata": {
        "id": "5SvpFHLNZVJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96058085-5fc9-450c-f2a9-690a17746d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(18,), dtype=string, numpy=\n",
              "array([b\"You've\", b'won', b'tkts', b'to', b'the', b'EURO2004', b'CUP',\n",
              "       b'FINAL', b'or', b'\\xc2\\xa3800', b'CASH,', b'to', b'collect',\n",
              "       b'CALL', b'09058099801', b'b4190604,', b'POBOX', b'7876150ppm'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: make sure this is tuned\n",
        "MAX_SEQUENCE_LENGTH = 5"
      ],
      "metadata": {
        "id": "FTR331lLZi8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sents_to_ids(token_list_list, label_list, num_examples=100000000):\n",
        "    \"\"\"\n",
        "    converting a list of strings to a list of lists of word ids\n",
        "    \"\"\"\n",
        "    text_ids = []\n",
        "    text_labels = []\n",
        "    example_count = 0\n",
        "    use_token_list_list = token_list_list[:num_examples]\n",
        "    for i, token_list in enumerate(use_token_list_list):\n",
        "        if i < num_examples:\n",
        "            try:\n",
        "                example = []\n",
        "                for token in list(token_list.numpy()):\n",
        "                    decoded = token.decode('utf-8').replace('.','').replace(',','').replace('!','')\n",
        "                    try:\n",
        "                        example.append(vocab_dict[decoded])\n",
        "                        \n",
        "                    except:\n",
        "                        example.append(43981)\n",
        "                if len(example) >= MAX_SEQUENCE_LENGTH:\n",
        "                    text_ids.append(example[:MAX_SEQUENCE_LENGTH])\n",
        "                    text_labels.append(label_list[i])\n",
        "                    if example_count % 5000 == 0:\n",
        "                        print('Examples processed: ', example_count)\n",
        "                    example_count += 1\n",
        "                else:\n",
        "                    pass\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    \n",
        "    print('Number of examples retained: ', example_count) \n",
        "    return (np.array(text_ids),   np.array(text_labels)) "
      ],
      "metadata": {
        "id": "ohRUVRzOZmi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to tensor\n",
        "y_train = tf.convert_to_tensor(list(train_y))\n",
        "y_test = tf.convert_to_tensor(list(test_y))"
      ],
      "metadata": {
        "id": "WsNjF9JlZzl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input, train_input_labels = sents_to_ids(train_tokens, y_train)\n",
        "test_input, test_input_labels = sents_to_ids(test_tokens, y_test)"
      ],
      "metadata": {
        "id": "RJrOVPu2Zniw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59fc492-48f8-4dbe-de85-c2530807f3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples processed:  0\n",
            "Number of examples retained:  4605\n",
            "Examples processed:  0\n",
            "Number of examples retained:  1147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN"
      ],
      "metadata": {
        "id": "HCn1BoEaPA6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                            embedding_matrix.shape[1],\n",
        "                            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "metadata": {
        "id": "hypVVE0gVWFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify model hyperparameters.\n",
        "epochs = 10\n",
        "num_filters = [3, 2, 1]\n",
        "kernel_sizes = [2, 4, 5]\n",
        "dense_layer_dims = [100, 30]\n",
        "dropout_rate = 0.5"
      ],
      "metadata": {
        "id": "eQ6kHgIYV4Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')"
      ],
      "metadata": {
        "id": "g3uG2-WBV_qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_embeddings = cnn_embedding_layer(cnn_input_layer)\n",
        "\n",
        "h = cnn_embeddings"
      ],
      "metadata": {
        "id": "5-JgitXCWAEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layers_for_all_kernel_sizes = []\n",
        "for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "    conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
        "    conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "    conv_layers_for_all_kernel_sizes.append(conv_layer)"
      ],
      "metadata": {
        "id": "pIlpLN0GWCOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)"
      ],
      "metadata": {
        "id": "u1Nv8GblWHoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = keras.layers.Dropout(rate=dropout_rate)(h)"
      ],
      "metadata": {
        "id": "28nx55AtWJCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dense_layer_dim in dense_layer_dims:  \n",
        "    h = keras.layers.Dense(dense_layer_dim, activation='relu')(h)"
      ],
      "metadata": {
        "id": "tbUQSErWWLbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_prediction = keras.layers.Dense(1, activation='sigmoid')(h)"
      ],
      "metadata": {
        "id": "D_RnD91QWMeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = keras.Model(inputs=cnn_input_layer, outputs=cnn_prediction)\n",
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # From information theory notebooks.\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Wnq2VzMtWRv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "JOuRrsY_WUqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ddf4da-745c-4b54-9405-3364e3100ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_28\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 5, 300)       13194600    ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_61 (Conv1D)             (None, 4, 3)         1803        ['embedding_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_62 (Conv1D)             (None, 2, 2)         2402        ['embedding_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_63 (Conv1D)             (None, 1, 1)         1501        ['embedding_4[0][0]']            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_61 (Globa  (None, 3)           0           ['conv1d_61[0][0]']              \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " global_max_pooling1d_62 (Globa  (None, 2)           0           ['conv1d_62[0][0]']              \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " global_max_pooling1d_63 (Globa  (None, 1)           0           ['conv1d_63[0][0]']              \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, 6)            0           ['global_max_pooling1d_61[0][0]',\n",
            "                                                                  'global_max_pooling1d_62[0][0]',\n",
            "                                                                  'global_max_pooling1d_63[0][0]']\n",
            "                                                                                                  \n",
            " dropout_988 (Dropout)          (None, 6)            0           ['concatenate_16[0][0]']         \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 100)          700         ['dropout_988[0][0]']            \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 30)           3030        ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 1)            31          ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,204,067\n",
            "Trainable params: 9,467\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_history = cnn_model.fit(train_input,\n",
        "             np.array(train_input_labels),\n",
        "             validation_data=(test_input, np.array(test_input_labels)),\n",
        "             class_weight = class_weight,\n",
        "             batch_size=32,\n",
        "             epochs=5\n",
        "             )"
      ],
      "metadata": {
        "id": "tpYEf_jcWX5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e398b1-86a1-4309-e333-96588149672e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "144/144 [==============================] - 2s 7ms/step - loss: 0.6080 - accuracy: 0.7153 - val_loss: 0.4615 - val_accuracy: 0.7742\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.4519 - accuracy: 0.7685 - val_loss: 0.3811 - val_accuracy: 0.8605\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.4076 - accuracy: 0.7824 - val_loss: 0.3293 - val_accuracy: 0.8814\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.3705 - accuracy: 0.8115 - val_loss: 0.3065 - val_accuracy: 0.8901\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.3617 - accuracy: 0.8017 - val_loss: 0.2910 - val_accuracy: 0.8989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "Ms5WvFFmxfVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_pred = cnn_model.predict(train_input)"
      ],
      "metadata": {
        "id": "7CaQHMQ0njBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = cnn_model.predict(test_input)"
      ],
      "metadata": {
        "id": "OdKTBCbhx_Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_input_labels), np.round(dev_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "VaVtHFQfmEWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d1a540-2d45-48ae-b26e-49dae3e8e91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + CNN, train data', np.array(train_input_labels), np.round(dev_pred,0))"
      ],
      "metadata": {
        "id": "aOF95pmvmJZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9666575c-1f59-4cea-e1b2-1e440e057c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + CNN, train data: accuracy = 0.9168, precision = 0.7530, recall = 0.9260, f1 = 0.8306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO can't analyze because some texts were discarded during conversion to ids\n",
        "\n",
        "train_y = train_input_labels\n",
        "train_y_predict = np.round(dev_pred,0)"
      ],
      "metadata": {
        "id": "xt42pkNS_093"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "-omYmQGZxieV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_input_labels), np.round(test_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "7LD-s2MtyKjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b875b849-7ff9-43e7-824b-041b656f41c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + CNN, test data', np.array(test_input_labels), np.round(test_pred,0))"
      ],
      "metadata": {
        "id": "dGiiWFj0yRms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e59050c2-d42c-4974-cc44-6bf4d71dd619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + CNN, test data: accuracy = 0.8989, precision = 0.7231, recall = 0.9004, f1 = 0.8020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM"
      ],
      "metadata": {
        "id": "JqfIxHLRPFqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                                embedding_matrix.shape[1],\n",
        "                                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False)"
      ],
      "metadata": {
        "id": "Cy47mRpm5SIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classificaiton_rnn_model(rnn_dim):\n",
        "  \"\"\"\n",
        "  max_length:         maximum input length\n",
        "  rnn_dim:            dimension of the rnn \n",
        "  return_sequences:   should the output vectors get returned?  \n",
        "  return_state:       should the final cell states get returned?\n",
        "  \"\"\"\n",
        "  \n",
        "  rnn_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
        "\n",
        "  rnn_embeddings = rnn_embedding_layer(rnn_input_layer)\n",
        "\n",
        "  # only return the last output from the RNN calculation \n",
        "  rnn_output = tf.keras.layers.LSTM(rnn_dim, return_sequences=False, return_state=False, name='LSTM')\\\n",
        "              (rnn_embeddings)\n",
        "\n",
        "  rnn_hidden = tf.keras.layers.Dense(100, activation='relu', name='rnn_hidden')(rnn_output)\n",
        "\n",
        "\n",
        "  rnn_classification = tf.keras.layers.Dense(1, \n",
        "                                            activation='sigmoid', \n",
        "                                            name='rnn_classification')(rnn_hidden)\n",
        "\n",
        "  # model definition\n",
        "\n",
        "  rnn_model = tf.keras.models.Model(inputs=rnn_input_layer, outputs=[rnn_classification])\n",
        "\n",
        "  rnn_model.compile(loss='binary_crossentropy',\n",
        "                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,\n",
        "                                                  beta_1=0.9,\n",
        "                                                  beta_2=0.999,\n",
        "                                                  epsilon=1e-07,\n",
        "                                                  amsgrad=False,\n",
        "                                                  name='Adam'),\n",
        "                  metrics='accuracy')\n",
        "    \n",
        "  return rnn_model"
      ],
      "metadata": {
        "id": "hK3YxuI8eKTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = build_classificaiton_rnn_model(rnn_dim=3)"
      ],
      "metadata": {
        "id": "OHrHxtyk4cKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_history = rnn_model.fit(train_input,\n",
        "             np.array(train_input_labels),\n",
        "             validation_data=(test_input, np.array(test_input_labels)),\n",
        "             class_weight = class_weight,\n",
        "             batch_size=32,\n",
        "              epochs=5\n",
        "             )"
      ],
      "metadata": {
        "id": "-AUPvbpc6RuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a2b9c6-40e3-46c3-e08c-38ffea5b0a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "144/144 [==============================] - 3s 9ms/step - loss: 0.5952 - accuracy: 0.7731 - val_loss: 0.4048 - val_accuracy: 0.8117\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.3977 - accuracy: 0.8308 - val_loss: 0.3957 - val_accuracy: 0.8317\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.3532 - accuracy: 0.8593 - val_loss: 0.3252 - val_accuracy: 0.8631\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.3303 - accuracy: 0.8738 - val_loss: 0.3368 - val_accuracy: 0.8710\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.3127 - accuracy: 0.8808 - val_loss: 0.2977 - val_accuracy: 0.8797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_pred = rnn_model.predict(train_input)\n",
        "test_pred = rnn_model.predict(test_input)"
      ],
      "metadata": {
        "id": "ZwSlWRFUGk0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "2kbcOSmlzXPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_input_labels), np.round(dev_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "NGhe9NTTz56f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a40df0-5f0b-4435-ba6c-16af1a1cca60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + LSTM model, train data: ', np.array(train_input_labels), np.round(dev_pred,0))"
      ],
      "metadata": {
        "id": "V86vJljoFz78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da60ee7-4dc9-4b19-d1f5-adf135e83b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + LSTM model, train data: : accuracy = 0.8988, precision = 0.7250, recall = 0.8708, f1 = 0.7912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "d9bCMLtwzbdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_input_labels), np.round(test_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "x0AkRHhiz9ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4b5151-5d36-4bc3-d568-dd60f3862e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + LSTM model, test data: ', np.array(test_input_labels), np.round(test_pred,0))"
      ],
      "metadata": {
        "id": "lcGDGWK3zgtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4bf7043-c949-4f80-fa81-270c15640bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + LSTM model, test data: : accuracy = 0.8797, precision = 0.6965, recall = 0.8352, f1 = 0.7596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT"
      ],
      "metadata": {
        "id": "w1IBwZ6ibHQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: have to split data again after W2V?\n",
        "X, y = data['text'], data['spam']\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)"
      ],
      "metadata": {
        "id": "FbbwrxBeU4m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "rXye48IxccJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab131a8-9667-4f90-c4e3-61dca1d8bc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 100\n",
        "#max_length = 160                  # set max_length\n",
        "\n",
        "\n",
        "all_train_examples = list(train_X)\n",
        "all_test_examples = list(test_X)\n",
        "\n",
        "\n",
        "x_train = bert_tokenizer(all_train_examples, \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train = tf.convert_to_tensor(list(train_y))\n",
        "\n",
        "x_test = bert_tokenizer(all_test_examples, \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test = tf.convert_to_tensor(list(test_y))"
      ],
      "metadata": {
        "id": "Tz3kbAVobIh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bert_pooled_model(train_layers=-1,\n",
        "                          hidden_size = 100, \n",
        "                          dropout=0.3,\n",
        "                          learning_rate=0.00005):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the Pooled Ouutput for classification purposes\n",
        "    \"\"\"\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # TO-DO: play around with restricting and not restricting BERT layers\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "\n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') #--SOLUTION--\n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    ##bert_inputs = {'input_ids': input_ids,\n",
        "    #              'token_type_ids': token_type_ids,\n",
        "    #              'attention_mask': attention_mask\n",
        "    #               }\n",
        "\n",
        "    #bert_out = bert_model([input_ids, token_type_ids, attention_mask])\n",
        "\n",
        "    \n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                   'token_type_ids': token_type_ids,\n",
        "                   'attention_mask': attention_mask}         \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    pooled_token = bert_out[1]\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(pooled_token)\n",
        "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
        "\n",
        "    \n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy') \n",
        "\n",
        "\n",
        "    \n",
        "    return classification_model"
      ],
      "metadata": {
        "id": "P38CSU4MdCuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model = create_bert_pooled_model()"
      ],
      "metadata": {
        "id": "G-EjxbRtdbjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96706db-384d-4610-e1c8-7bcdec396d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model_history = pooled_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),\n",
        "                                                  class_weight = class_weight,   \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=1)  "
      ],
      "metadata": {
        "id": "Z2H4_W9TddnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552a9523-8e45-4145-f409-a98acc44e4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "611/611 [==============================] - 92s 122ms/step - loss: 0.1333 - accuracy: 0.9642 - val_loss: 0.0722 - val_accuracy: 0.9853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3K2UBrszEDyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "SQvNSj_Ihzt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "tITeF3S-mNhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "ZuDpR0Db0q3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "t7sl94GmpB44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "bc50a3d2-2a07-4b48-f777-304e8042f637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3db79d8d50>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + FCN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "id": "6DPLZ7TMq5Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a528b4-c55b-4a71-8bd9-10fcbe439bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + FCN, train data: : accuracy = 0.9928, precision = 0.9852, recall = 0.9803, f1 = 0.9828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "GSnDZLuR0uec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "fkVzGDvO0w_X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e937817b-56ea-4237-a4d5-4acb1f61d856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3db796b2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "AJTkYBdb0xZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11f0693-5010-4a5e-e108-f43ae3aa00af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + FCN, test data: : accuracy = 0.9853, precision = 0.9730, recall = 0.9582, f1 = 0.9655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT Analysis"
      ],
      "metadata": {
        "id": "nvR_4nFjOZ8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_predict = train_y_predict.ravel()"
      ],
      "metadata": {
        "id": "r9GIj68vnXge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spam examples\n",
        "data['text'][data[\"spam\"] == 1]"
      ],
      "metadata": {
        "id": "jDIZfakXgsOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3a5d33-8264-47a1-b301-febcd46ec072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "5       FreeMsg Hey there darling it's been 3 week's n...\n",
              "8       WINNER!! As a valued network customer you have...\n",
              "9       Had your mobile 11 months or more? U R entitle...\n",
              "11      SIX chances to win CASH! From 100 to 20,000 po...\n",
              "                              ...                        \n",
              "6102    You have passed the official certification onl...\n",
              "6103    Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...\n",
              "6104    Hi, I'm a Shopee Hiring Manager and I'm curren...\n",
              "6105    4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\n",
              "Pinaka mur...\n",
              "6106    Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...\n",
              "Name: text, Length: 1280, dtype: string"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missclassified_text = train_X[train_y != train_y_predict]\n",
        "missclassified_label = train_y[train_y != train_y_predict]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'missclassified_true_label': missclassified_label})\n",
        "\n",
        "#df_report['missclassified_true_label'].value_counts()\n",
        "df_report"
      ],
      "metadata": {
        "id": "zhz2qnZqJHdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98b1bba9-a93c-44f7-ab57-ceb819b14cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  \\\n",
              "1612                                                645   \n",
              "2247  Hi ya babe x u 4goten bout me?' scammers getti...   \n",
              "1290  Hey...Great deal...Farm tour 9am to 5pm $95/pa...   \n",
              "1729  As per your request 'Maangalyam (Alaipayuthe)'...   \n",
              "1353  Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur S...   \n",
              "5767     Stay a while 'cause somethings always cooking.   \n",
              "5687  Huwag sayangin ang boto. Dito na sa sigurado. ...   \n",
              "4249  accordingly. I repeat, just text the word ok o...   \n",
              "1766  Hi this is yijue... It's regarding the 3230 te...   \n",
              "1407  URGENT, IMPORTANT INFORMATION FOR O2 USER. TOD...   \n",
              "3824  Please protect yourself from e-threats. SIB ne...   \n",
              "2823  ROMCAPspam Everyone around should be respondin...   \n",
              "384          Hey i will be late ah... Meet you at 945+\n",
              "   \n",
              "2965  Do you ever notice that when you're driving, a...   \n",
              "5768          Come on in, feel free to do some looking.   \n",
              "692   Sorry to trouble u again. Can buy 4d for my da...   \n",
              "4762  It's é only $140 ard...É rest all ard $180 at ...   \n",
              "4394  RECPT 1/3. You have ordered a Ringtone. Your o...   \n",
              "2692                       Hey tmr meet at bugis 930 ?\n",
              "   \n",
              "5771  My Grandfather smoked his whole life. I was ab...   \n",
              "68    Did you hear about the new \"Divorce Barbie\"? I...   \n",
              "5486  , ,  and  picking them up from various points ...   \n",
              "227   Will u meet ur dream partner soon? Is ur caree...   \n",
              "5791  ,,need low % for Money this time..im willing t...   \n",
              "4949  Hi this is Amy, we will be sending you a free ...   \n",
              "1724  Hi Jon, Pete here, Ive bin 2 Spain recently & ...   \n",
              "5773               Budget for all your needs, type yes    \n",
              "4650  Please protect yourself from e-threats. SIB ne...   \n",
              "1875  Would you like to see my XXX pics they are so ...   \n",
              "6015  Hey! Reply me here because it's not connecting...   \n",
              "3291  My tuition is at 330. Hm we go for the 1120 to...   \n",
              "6070            Replt to my email now; mlvbxz@gmail.com   \n",
              "869   Hello. We need some posh birds and chaps to us...   \n",
              "5451  Latest News! Police station toilet stolen, cop...   \n",
              "3539  We are pleased to inform that your application...   \n",
              "\n",
              "      missclassified_true_label  \n",
              "1612                          0  \n",
              "2247                          1  \n",
              "1290                          0  \n",
              "1729                          0  \n",
              "1353                          0  \n",
              "5767                          1  \n",
              "5687                          1  \n",
              "4249                          1  \n",
              "1766                          0  \n",
              "1407                          1  \n",
              "3824                          0  \n",
              "2823                          1  \n",
              "384                           0  \n",
              "2965                          1  \n",
              "5768                          1  \n",
              "692                           0  \n",
              "4762                          0  \n",
              "4394                          1  \n",
              "2692                          0  \n",
              "5771                          1  \n",
              "68                            1  \n",
              "5486                          0  \n",
              "227                           1  \n",
              "5791                          1  \n",
              "4949                          1  \n",
              "1724                          0  \n",
              "5773                          1  \n",
              "4650                          0  \n",
              "1875                          1  \n",
              "6015                          1  \n",
              "3291                          0  \n",
              "6070                          1  \n",
              "869                           1  \n",
              "5451                          1  \n",
              "3539                          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f34fea9-1ec9-4510-a6c0-611931202292\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>missclassified_true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1612</th>\n",
              "      <td>645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>Hi ya babe x u 4goten bout me?' scammers getti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>Hey...Great deal...Farm tour 9am to 5pm $95/pa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1729</th>\n",
              "      <td>As per your request 'Maangalyam (Alaipayuthe)'...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1353</th>\n",
              "      <td>Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur S...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5767</th>\n",
              "      <td>Stay a while 'cause somethings always cooking.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5687</th>\n",
              "      <td>Huwag sayangin ang boto. Dito na sa sigurado. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4249</th>\n",
              "      <td>accordingly. I repeat, just text the word ok o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1766</th>\n",
              "      <td>Hi this is yijue... It's regarding the 3230 te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>URGENT, IMPORTANT INFORMATION FOR O2 USER. TOD...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3824</th>\n",
              "      <td>Please protect yourself from e-threats. SIB ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2823</th>\n",
              "      <td>ROMCAPspam Everyone around should be respondin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>Hey i will be late ah... Meet you at 945+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>Do you ever notice that when you're driving, a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5768</th>\n",
              "      <td>Come on in, feel free to do some looking.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>Sorry to trouble u again. Can buy 4d for my da...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4762</th>\n",
              "      <td>It's é only $140 ard...É rest all ard $180 at ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4394</th>\n",
              "      <td>RECPT 1/3. You have ordered a Ringtone. Your o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2692</th>\n",
              "      <td>Hey tmr meet at bugis 930 ?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5771</th>\n",
              "      <td>My Grandfather smoked his whole life. I was ab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Did you hear about the new \"Divorce Barbie\"? I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5486</th>\n",
              "      <td>, ,  and  picking them up from various points ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>Will u meet ur dream partner soon? Is ur caree...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5791</th>\n",
              "      <td>,,need low % for Money this time..im willing t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4949</th>\n",
              "      <td>Hi this is Amy, we will be sending you a free ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724</th>\n",
              "      <td>Hi Jon, Pete here, Ive bin 2 Spain recently &amp; ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5773</th>\n",
              "      <td>Budget for all your needs, type yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4650</th>\n",
              "      <td>Please protect yourself from e-threats. SIB ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1875</th>\n",
              "      <td>Would you like to see my XXX pics they are so ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6015</th>\n",
              "      <td>Hey! Reply me here because it's not connecting...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3291</th>\n",
              "      <td>My tuition is at 330. Hm we go for the 1120 to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6070</th>\n",
              "      <td>Replt to my email now; mlvbxz@gmail.com</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5451</th>\n",
              "      <td>Latest News! Police station toilet stolen, cop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3539</th>\n",
              "      <td>We are pleased to inform that your application...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f34fea9-1ec9-4510-a6c0-611931202292')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f34fea9-1ec9-4510-a6c0-611931202292 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f34fea9-1ec9-4510-a6c0-611931202292');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_X[train_y != train_y_predict].loc[1460]"
      ],
      "metadata": {
        "id": "NS5sFIWen1xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_report.loc[2965]"
      ],
      "metadata": {
        "id": "Dg1gvY-gKQXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64849bf-17b7-4dec-e12a-1ee56af549b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "missclassified_text          Do you ever notice that when you're driving, a...\n",
              "missclassified_true_label                                                    1\n",
              "Name: 2965, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Baseline BERT observations\n",
        "-----------------------------\n",
        "\n",
        "As expected more text messages that were SPAM got classified as HAM because HAM is the majority class in our dataset.\n",
        "\n",
        "I looked at a couple examples of texts that got misclassified as HAM and they're tricky to tell if it's a ham or spam messages. The 2 examples contained generic sayings that even a human could mistakenly classify as spam.\n",
        "\n",
        "\n",
        "*Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur Soul Ur Guide And U Will Never loose in world....gnun - Sent via WAY2SMS.COM*\n",
        "\n",
        "*1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cancer. 1Lemon/Day=No Fat. 1Cup Milk/day=No Bone Problms 3 Litres Watr/Day=No Diseases Snd ths 2 Whom U Care..:-)*\n",
        "\n",
        "\n",
        "In general the misclassified messages are hard to tell for certain that they are ham or spam.\n"
      ],
      "metadata": {
        "id": "8skK76XCHeC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT + CNN"
      ],
      "metadata": {
        "id": "wcXX9CM28l71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bert_cnn_model(train_layers=-1,\n",
        "                          hidden_size = 100, \n",
        "                          learning_rate=0.00005,\n",
        "                          num_filters = [100, 100, 50, 25],\n",
        "                          kernel_sizes = [3, 5, 10, 20],\n",
        "                          dense_layer_dims = 100,\n",
        "                          dropout = 0.3):\n",
        "    \"\"\"\n",
        "    Build a  classification model with BERT, where you apply CNN layers  to the BERT output\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # TO-DO: play around with restricting and not restricting BERT layers\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "    \n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') \n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    # bert_inputs = {'input_ids': input_ids} \n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                'token_type_ids': token_type_ids,\n",
        "                'attention_mask': attention_mask}      \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    pooled_token = bert_out[0][:, 1:-1]\n",
        "\n",
        "    # CNN -----\n",
        "\n",
        "    conv_layers_for_all_kernel_sizes = []\n",
        "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "        conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(pooled_token)\n",
        "        conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "        conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
        "\n",
        "    h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
        "    #h = keras.layers.Dropout(rate=dropout)(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(dense_layer_dims, activation='relu')(h)\n",
        "    h = tf.keras.layers.Dropout(rate=dropout)(h) \n",
        "\n",
        "    # -----\n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(h)\n",
        "\n",
        "    # classification_model = tf.keras.Model(inputs=[input_ids], outputs=[classification])\n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy')\n",
        "\n",
        "\n",
        "    ### END YOUR CODE\n",
        "    \n",
        "    return classification_model"
      ],
      "metadata": {
        "id": "jKXuto0I8pNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model()\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            class_weight = class_weight, \n",
        "                                            batch_size=8, \n",
        "                                            epochs=1)  "
      ],
      "metadata": {
        "id": "fkQ5v7lI9Ppr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd172cc-aa6d-4ffa-90af-d466e5672ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 81s 106ms/step - loss: 0.1106 - accuracy: 0.9650 - val_loss: 0.0691 - val_accuracy: 0.9828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "zw3v5VG0BAjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ORW4C-bR3Z_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "5Gp9o1HI2tC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "IW32_54PCpg1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "c193ad68-c289-43ba-bafb-210868e725d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3db61d4450>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "id": "msQ5VDvRCrpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff19ae9-f54c-45ba-b6dd-03c922b11070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9941, precision = 0.9778, recall = 0.9941, f1 = 0.9859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "4OnfDJiJ3khq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "3Yvu9Rsk4Dd-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1bee0987-4dd9-4138-d2b6-5768e0407aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3db7a3f910>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "2lQNG1Oz3o7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b2b7c7-b17b-4193-8753-e93dd452398d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, test data: : accuracy = 0.9828, precision = 0.9481, recall = 0.9734, f1 = 0.9606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train\n",
        "\n",
        "  - Word2Vec embeddings\n",
        "    - CNN  |  accuracy = 0.9336, precision = 0.8344, recall = 0.8700, f1 = 0.8519\n",
        "    - LSTM  |  accuracy = 0.9172, precision = 0.8217, recall = 0.7956, f1 = 0.8085\n",
        "\n",
        "  - BERT with\n",
        "    - Fully connected network  |  accuracy = 0.9873, precision = 0.9827, recall = 0.9555, f1 = 0.9689\n",
        "    - CNN  |  accuracy = 0.9865, precision = 1.0000, recall = 0.9348, f1 = 0.9663\n",
        "\n",
        "- Test\n",
        "\n",
        "  - Word2Vec embeddings\n",
        "    - W2V + CNN, test data: : accuracy = 0.8949, precision = 0.7567, recall = 0.7773, f1 = 0.7669\n",
        "    - W2V + LSTM model, test data: : accuracy = 0.8897, precision = 0.7452, recall = 0.7656, f1 = 0.7553\n",
        "\n",
        "  - BERT with\n",
        "    - BERT + FCN, test data: : accuracy = 0.9885, precision = 0.9841, recall = 0.9611, f1 = 0.9724\n",
        "    - BERT + CNN, test data: : accuracy = 0.9828, precision = 0.9958, recall = 0.9222, f1 = 0.9576\n"
      ],
      "metadata": {
        "id": "1feUh1bIDy5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuned models"
      ],
      "metadata": {
        "id": "NlfXqmUi8a3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT tuning"
      ],
      "metadata": {
        "id": "scIsHg775HLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1:** Increase the number of epochs because the training kept on improving in the first epoch and we may want to have a couple passes through the model in order to find the most optimal weights for this classification task. Also tune if freezing or unfreezing BERT layers will improve performance. I assume that unfreezing the layers may introduce too many parameters and the model will overfit. But we're expecting the number of epochs to increase performance."
      ],
      "metadata": {
        "id": "TBGWQOpC56YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model = create_bert_pooled_model()"
      ],
      "metadata": {
        "id": "sSut37Sb5ZXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d18439f-fed1-4e06-f1b0-653b521a8bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model_history = pooled_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  class_weight = class_weight, \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=3)  "
      ],
      "metadata": {
        "id": "g5xRcuyI5xJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc06479-61e0-4124-c5f7-09f041a946a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "611/611 [==============================] - 78s 103ms/step - loss: 0.1728 - accuracy: 0.9515 - val_loss: 0.1405 - val_accuracy: 0.9795\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 72s 117ms/step - loss: 0.0841 - accuracy: 0.9861 - val_loss: 0.2200 - val_accuracy: 0.9607\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 59s 96ms/step - loss: 0.1609 - accuracy: 0.9519 - val_loss: 0.1109 - val_accuracy: 0.9771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "i1Zhlh2l8PWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "SmBMa6qr8VSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "_fwXVGMy8hgd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8523131b-c2ea-4382-c7f2-ab354c0b508b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3fc07f1390>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYaklEQVR4nO3de5hV5Xn38e8PEEXAgIcaTgoqxqKXojFANBqjCQKxhcRoMFWn1nasQmIaNWrjIaK+r7VR3xgtdVAUTARJjDqvJVFCbBLTqKAiCkiZ4okRRAUPSByY2Xf/2Avc6szee2TP7MXy9+F6rln7XqdnXQ43t8969lqKCMzMLF26VLsDZmb2UU7OZmYp5ORsZpZCTs5mZink5GxmlkLdOvoEm19f6ekg9hE9+h9V7S5YCjVvatS2HqM9OWeH3ffZ5vN1FFfOZmYp1OGVs5lZp8q1VLsHFeHkbGbZ0tJc7R5UhJOzmWVKRK7aXagIJ2czy5ack7OZWfq4cjYzSyHfEDQzSyFXzmZm6ROerWFmlkK+IWhmlkIe1jAzSyHfEDQzSyFXzmZmKeQbgmZmKeQbgmZm6RORjTFnP8/ZzLIlcuW3IiTtJOlxSU9LWiLpiiR+h6TnJS1K2vAkLkk3SmqQtFjSYQXHqpG0Imk15VyGK2czy5bKDWs0AcdGxAZJOwCPSPpVsu6CiPjFh7YfCwxN2khgKjBS0q7A5cDhQABPSKqPiPXFTu7K2cyypUKVc+RtSD7ukLRir8AaD8xM9nsU6COpH3A8MC8i1iUJeR4wptRlODmbWba0bC67SaqVtLCg1RYeSlJXSYuAteQT7GPJqquToYsbJO2YxAYALxfsviqJtRUvysMaZpYt7RjWiIg6oK7I+hZguKQ+wL2SDgIuBtYA3ZN9LwSmbEuXW+PK2cyypULDGh84ZMSbwMPAmIhYnQxdNAG3AyOSzRqBQQW7DUxibcWLcnI2s2zJ5cpvRUjaI6mYkdQD+ArwXDKOjCQBE4Bnk13qgdOTWRujgLciYjXwIDBaUl9JfYHRSawoD2uYWbZUbrZGP2CGpK7kC9k5EfGApN9K2gMQsAj4x2T7ucA4oAHYCJwBEBHrJF0JLEi2mxIR60qd3MnZzDIlWjZX5jgRi4FDW4kf28b2AUxqY910YHp7zu/kbGbZ4gcfmZmlkJ+tYWaWQq6czcxSyJWzmVkKuXI2M0uhZj9s38wsfVw5m5mlkMeczcxSyJWzmVkKuXI2M0shV85mZink2RpmZikUxd4ktf1wcjazbPGYs5lZCjk5m5mlkG8ImpmlUEtLtXtQEU7OZpYtHtYwM0uhjCRnv33bzLIlcuW3IiTtJOlxSU9LWiLpiiQ+RNJjkhok3S2pexLfMfnckKwfXHCsi5P4cknHl3MZTs5mlimRi7JbCU3AsRFxCDAcGCNpFPAvwA0RsR+wHjgz2f5MYH0SvyHZDknDgInAgcAY4N+SN3oX5eRsZtmSy5Xfioi8DcnHHZIWwLHAL5L4DGBCsjw++Uyy/jhJSuKzI6IpIp4HGoARpS7DydnMsqWlpewmqVbSwoJWW3goSV0lLQLWAvOA/wHejIgt3xFfBQxIlgcALwMk698CdiuMt7JPm3xD0MyypR03BCOiDqgrsr4FGC6pD3AvcMA2969MTs5mli0dMFsjIt6U9DDweaCPpG5JdTwQaEw2awQGAaskdQM+BbxREN+icJ82eVhjGzQ1bWLi35/L12vOYfzfnMVNt94JwKMLn+KkMyZzYs0kTjv7PF5a9coH9pv38CMcdORYnl323wA8s3Q5J9ZM4sSaSXy95hx+87s/dvq1WMcbOLA/v3no5yx++mGeXvRbvj05fx/psku/x4vPL2ThgodYuOAhxo45tso93c5FlN+KkLRHUjEjqQfwFWAZ8DDwjWSzGuD+ZLk++Uyy/rcREUl8YjKbYwgwFHi81GW4ct4G3bvvwPQbr2HnnXuwubmZ088+n6NGHc6VP7qZG6+5jH0H78XsXz7ALXfM4upLzgPg3Xc38tOf38/Bwz6z9Tj77bM3d992I926deW119dxYs05HHPkKLp1K3lD17Yjzc3NXPD9K3hq0bP06tWTxx/7Nb+Z/3sAfnzjNK6/4ZYq9zAjKlc59wNmJDMrugBzIuIBSUuB2ZKuAp4Cbku2vw24U1IDsI78DA0iYomkOcBSoBmYlAyXFOXkvA0ksfPOPYD8X7zm5mYkIfJJGOCdDe+yx+67bd3nJ9Nm8nennsTtd/1ia6zHTjttXW7atAmkzrkA61Rr1qxlzZq1AGzY8C7PPbeCAf0/XeVeZVDpKXJliYjFwKGtxFfSymyLiHgPOKmNY10NXN2e85dMzpIOID8VZMvdxUagPiKWtedEWdXS0sLJf/cdXmp8hVO+fgIHH3gAV1z0Xc4+/zJ22rE7PXvuzF11NwCwdHkDa9a+zhePGPGB5AyweMlzXPp/buCVV9fyfy8931Vzxu2990CGH3IQjz3+FEcc8TnOOfsMTj31GzzxxGIu+P4U3nzzrWp3cfuVkWdrFB1zlnQhMBsQ+TGSx5PlWZIuKrLf1ukpt86cVcn+pk7Xrl25Z8bNzL/3Tp5Z+t+sWPkCM+++l6k/msL8+37KhHGjufbGaeRyOa79SR0XfPsfWj3OwQcewP0/u4XZt/6YW++cQ1PTpk6+EussPXvuzJy7p/G98y/nnXc28O+3zGT/A47gs4ePZs2atfzrtZdVu4vbtcjlym5pVqpyPhM4MCI2FwYlXQ8sAa5pbafC6SmbX1+ZjdcSlLBL716MOOxg/vCnhSxvWMnBB+Zn3Iw97mjOOu8S3t34ZxpWvsgZk78PwOvr1vPtC6/gJ/9yOQf95f5bj7Pv4L3YuUcPVqx84QNxy4Zu3brx87unMWvWvdx3368AWLv29a3rb73tZ9x/34y2drdyVGhYo9pKzdbIAf1bifdL1n2irVv/Jm+/k/8C0XtNTfxpwVPsM3gQG97dyAsvrQLgvxY8xT5770XvXj15ZO7dPHTPDB66ZwYHH3jA1sS86pU1NDfn/1fslTWv8vyLLzOg355Vuy7rONPqrmPZcw38vx+/P7X205/+i63LE8aPZcmS5dXoWnZU6Nka1Vaqcv4uMF/SCt7/hstewH7A5I7s2PbgtTfW84OrfkRLLkfkguOPPYpjjhzJDy/8Dv/0g6tRF7FL715cefE/FT3Ok4uXcNudc+jWrRtduohLzp9E3z6f6qSrsM5y5BGf47RTv8HiZ5aycMFDAFx66TV885sTOOSQYUQEL764irPPubDKPd3OZaRyVpSe69eF/J3JwhuCC8qZCgKfnGENa58e/Y+qdhcshZo3NW7zVKV3L5tYds7pOWV2aqdGlZytERE54NFO6IuZ2bZL+XBFuTzP2cyyJSPDGk7OZpYpaZ8iVy4nZzPLFlfOZmYp5ORsZpZCGfn6tpOzmWVKGe8G3C44OZtZtjg5m5mlkGdrmJmlkCtnM7MUcnI2M0ufaPGwhplZ+rhyNjNLn6xMpSv1sH0zs+1LLspvRUgaJOlhSUslLZF0bhL/oaRGSYuSNq5gn4slNUhaLun4gviYJNZQ7BV/hVw5m1m2VG7IuRk4LyKelNQbeELSvGTdDRHxo8KNJQ0DJgIHkn+D1G8kbXnX3M3AV4BVwAJJ9RGxtNjJnZzNLFOiuTLZOSJWA6uT5XckLeP9l460ZjwwOyKagOclNZB/UQlAQ0SsBJA0O9m2aHL2sIaZZUuu/CapVtLCglbb2iElDQYOBR5LQpMlLZY0XVLfJDaA91/nB/kqeUCReFFOzmaWKZGL8ltEXUQcXtDqPnw8Sb2Ae4DvRsTbwFRgX2A4+cr6uo64Dg9rmFm2VHCas6QdyCfmn0XELwEi4tWC9dOAB5KPjcCggt0HJjGKxNvkytnMMqU9lXMxkgTcBiyLiOsL4v0KNvsa8GyyXA9MlLSjpCHAUOBxYAEwVNIQSd3J3zSsL3UdrpzNLFsqVzkfCZwGPCNpURL7Z+AUScOBAF4AzgKIiCWS5pC/0dcMTIqIFgBJk4EHga7A9IhYUurkiujYCdubX1+ZjRnhVlE9+h9V7S5YCjVvatS2HuONr36x7Jyz23/8bpvP11FcOZtZpkQ2Hq3h5GxmGePkbGaWPq6czcxSyMnZzCyFoiW19/jaxcnZzDLFlbOZWQpFzpWzmVnquHI2M0uhCFfOZmap48rZzCyFcp6tYWaWPr4haGaWQk7OZmYp1MEP2uw0Ts5mlimunM3MUshT6czMUqjFszXMzNLHlbOZWQplZczZb982s0yJKL8VI2mQpIclLZW0RNK5SXxXSfMkrUh+9k3iknSjpAZJiyUdVnCsmmT7FZJqyrkOJ2czy5TIqexWQjNwXkQMA0YBkyQNAy4C5kfEUGB+8hlgLDA0abXAVMgnc+ByYCQwArh8S0IvxsnZzDKlJdel7FZMRKyOiCeT5XeAZcAAYDwwI9lsBjAhWR4PzIy8R4E+kvoBxwPzImJdRKwH5gFjSl2Hk7OZZUp7hjUk1UpaWNBqWzumpMHAocBjwJ4RsTpZtQbYM1keALxcsNuqJNZWvCjfEDSzTMm1Y7ZGRNQBdcW2kdQLuAf4bkS8Lb1//IgISR3ynURXzmaWKREqu5UiaQfyiflnEfHLJPxqMlxB8nNtEm8EBhXsPjCJtRUvysnZzDKlgrM1BNwGLIuI6wtW1QNbZlzUAPcXxE9PZm2MAt5Khj8eBEZL6pvcCBydxIrq8GGNnfsf1dGnsO3Qaf1HVbsLllHtGdYo4UjgNOAZSYuS2D8D1wBzJJ0JvAicnKybC4wDGoCNwBkAEbFO0pXAgmS7KRGxrtTJPeZsZplSahZGuSLiEaCtTH9cK9sHMKmNY00Hprfn/E7OZpYpGXliqJOzmWVLBYc1qsrJ2cwyxQ8+MjNLoYy8fNvJ2cyyJdq8h7d9cXI2s0xp9rCGmVn6uHI2M0shjzmbmaWQK2czsxRy5WxmlkItrpzNzNInI+93dXI2s2zJuXI2M0sfP/jIzCyFfEPQzCyFcvKwhplZ6rRUuwMV4uRsZpni2RpmZink2RpmZimUldkalXkToplZSuRUfitF0nRJayU9WxD7oaRGSYuSNq5g3cWSGiQtl3R8QXxMEmuQdFE51+HkbGaZkmtHK8MdwJhW4jdExPCkzQWQNAyYCByY7PNvkrpK6grcDIwFhgGnJNsW5WENM8uUlgoOOUfE7yUNLnPz8cDsiGgCnpfUAIxI1jVExEoASbOTbZcWO5grZzPLlPZUzpJqJS0saLVlnmaypMXJsEffJDYAeLlgm1VJrK14UU7OZpYp7UnOEVEXEYcXtLoyTjEV2BcYDqwGrqv8VXhYw8wypqNfIRgRr25ZljQNeCD52AgMKth0YBKjSLxNrpzNLFMqfEPwIyT1K/j4NWDLTI56YKKkHSUNAYYCjwMLgKGShkjqTv6mYX2p87hyNrNMqeTXtyXNAo4Bdpe0CrgcOEbScPJTql8AzgKIiCWS5pC/0dcMTIqIluQ4k4EHga7A9IhYUurcTs5mlimV/Pp2RJzSSvi2IttfDVzdSnwuMLc953ZyNrNM8SNDzcxSyMnZzCyFsvJsDSdnM8sUPzLUzCyF/LB9M7MUymVkYMPJ2cwyxTcEzcxSKBt1s5OzmWWMK2czsxRqVjZqZydnM8uUbKRmJ2czyxgPa5iZpZCn0pmZpVA2UrOTs5lljIc1zMxSqCUjtbOTs5lliitnM7MUClfOZmbp48rZSurSpQuPPforGhvXMOFrNQBMmXIhJ554Ai0tLdTdMpObbp5e5V5aR/vKGV/l6IlfRhK/mz2PedP/g7Nv+h6f3qc/ADvv0pONb7/L5ePOp2efXkyaegFDDt6XP/7iP/np5bdWuffbn0pOpZM0HTgBWBsRByWxXYG7gcHkX/B6ckSslyTgx8A4YCPwtxHxZLJPDXBJctirImJGqXM7OXeg73z771n23Ap26d0bgJrTT2bQwP4cdNDRRAR77LFblXtoHW3A/oM4euKXuXL8hTRvbuZ7My7l6flPMHXy9Vu3+eYPavjzOxsB2Ny0mXuvm8WAz+zFwP33qla3t2sVHtS4A7gJmFkQuwiYHxHXSLoo+XwhMBYYmrSRwFRgZJLMLwcOT7r3hKT6iFhf7MRdKnsdtsWAAf0YO/Y4pk+ftTV21lmnc9XVNxCR//V57bU3qtU96yT99hvIykUr2PTeJnItOZY/toTPjhn5gW1GfPUIHqt/BIBNf25ixcLn2Ny0uRrdzYRmouxWSkT8Hlj3ofB4YEvlOwOYUBCfGXmPAn0k9QOOB+ZFxLokIc8DxpQ6t5NzB7nuuiu4+OKryOXeHwHbZ5/BnHTSX/Pon+by/+vvZL/9hlSxh9YZGpe/xP6f+0t69ulF9526c/CXDmPXfrtvXb//iGG89fqbvPrC6ir2MluiHX8k1UpaWNBqyzjFnhGx5T/YGmDPZHkA8HLBdquSWFvxoj72sIakMyLi9jbW1QK1AF26foouXXp+3NNsl8aN+zKvrX2dJ596hqOP/vzW+I47due995oY9flxTJgwlml11/GlY79exZ5aR1v9P43M/ff7OP/Oy2ja2MRLS1/4wD/YI//6C1urZquM9twQjIg6oO7jnisiQuqYx+Bty5jzFUCrybnwgnfoPiAb81ra4YgjDueEE0YzZsyx7LTTjuyyS29m3HEjqxpXc999cwG4775fceu060scybLgD3Pm84c58wE48YJvsW51fjirS9cufPb4kVzxVxdUs3uZ0wlT6V6V1C8iVifDFmuTeCMwqGC7gUmsETjmQ/H/LHWSosMakha30Z7h/VLePuSSS65hyD6HM3T/UfzNqefw8MN/pOZvv0N9/a855otHAHD00Z9nxYqVVe6pdYbeu+0CwK79d+ezY0bxaP0fABj2hYNZvbKR9Ws+PKRp2yLXjvYx1QM1yXINcH9B/HTljQLeSoY/HgRGS+orqS8wOokVVapy3pP8YPaH7yoK+K+yLsO2uvbam5k54ybOPfcf2LBhI2f9oyumT4LJUy+gZ9/etDS3cOel0/jz2/mZGSP/qvUhjX99ZCo79epBtx26cejoEVx32hReaVjV2d3ebrVERafSzSJf9e4uaRX5WRfXAHMknQm8CJycbD6X/DS6BvJT6c4AiIh1kq4EFiTbTYmIkv8iK4pciKTbgNsj4iO/QZLuiohvlTrBJ3FYw0o7tf+oanfBUuj2F+7Rth7jW3t/reycc9eL927z+TpK0co5Is4ssq5kYjYz62z++raZWQr569tmZinkN6GYmaWQhzXMzFKokrM1qsnJ2cwyxcMaZmYp5BuCZmYp5DFnM7MU8rCGmVkKFfvW8/bEydnMMqXFlbOZWfp4WMPMLIU8rGFmlkKunM3MUshT6czMUshf3zYzSyEPa5iZpZCTs5lZCnm2hplZCmWlcu5S7Q6YmVVStONPKZJekPSMpEWSFiaxXSXNk7Qi+dk3iUvSjZIaJC2WdNi2XIeTs5llSkvkym5l+lJEDI+Iw5PPFwHzI2IoMD/5DDAWGJq0WmDqtlyHk7OZZUpElN0+pvHAjGR5BjChID4z8h4F+kjq93FP4uRsZpmSI8pukmolLSxotR86XAAPSXqiYN2eEbE6WV4D7JksDwBeLth3VRL7WHxD0MwypT3fEIyIOqCuyCZfiIhGSX8BzJP03If2D0kdcgfSydnMMiVXwal0EdGY/Fwr6V5gBPCqpH4RsToZtlibbN4IDCrYfWAS+1g8rGFmmVKp2RqSekrqvWUZGA08C9QDNclmNcD9yXI9cHoya2MU8FbB8Ee7uXI2s0xpxyyMUvYE7pUE+Vx5V0T8WtICYI6kM4EXgZOT7ecC44AGYCNwxrac3MnZzDKlUsMaEbESOKSV+BvAca3EA5hUkZPj5GxmGeNHhpqZpVAlbwhWk5OzmWWKK2czsxRqiZZqd6EinJzNLFP8yFAzsxTKyiNDnZzNLFNcOZuZpZBna5iZpZBna5iZpVAFv75dVU7OZpYpHnM2M0shjzmbmaWQK2czsxTyPGczsxRy5WxmlkKerWFmlkK+IWhmlkIe1jAzSyF/Q9DMLIVcOZuZpVBWxpyVlX9ltgeSaiOirtr9sHTx74W1pku1O/AJU1vtDlgq+ffCPsLJ2cwshZyczcxSyMm5c3lc0Vrj3wv7CN8QNDNLIVfOZmYp5ORsZpZCTs6dRNIYScslNUi6qNr9seqTNF3SWknPVrsvlj5Ozp1AUlfgZmAsMAw4RdKw6vbKUuAOYEy1O2Hp5OTcOUYADRGxMiI2AbOB8VXuk1VZRPweWFftflg6OTl3jgHAywWfVyUxM7NWOTmbmaWQk3PnaAQGFXwemMTMzFrl5Nw5FgBDJQ2R1B2YCNRXuU9mlmJOzp0gIpqBycCDwDJgTkQsqW6vrNokzQL+BHxG0ipJZ1a7T5Ye/vq2mVkKuXI2M0shJ2czsxRycjYzSyEnZzOzFHJyNjNLISdnM7MUcnI2M0uh/wXh7eX/tBVFPQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "ujsahj568sx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a8e2466a-be12-4ec0-bb6a-a6bd79eae118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3db60bfa90>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "print_metrics('BERT 3e + FCN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "id": "8MZXVo-w82-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399b9221-a75d-4616-8591-5f8e78e4a90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, train data: : accuracy = 0.9855, precision = 0.9749, recall = 0.9548, f1 = 0.9647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "print_metrics('BERT 3e + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "Qe85CHhs86_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d275b7a6-2d74-4df9-ab59-28605fb10325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, test data: : accuracy = 0.9771, precision = 0.9644, recall = 0.9278, f1 = 0.9457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "missclassified_text = train_X[train_y != train_y_predict.reshape(-1)]\n",
        "missclassified_label = train_y[train_y != train_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "id": "dOsSKjxl_-Hs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a671bbdf-faeb-4baa-cbad-b2569c861fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "3430  I don't know jack shit about anything or i'd s...           0\n",
              "4111  Yo, you gonna still be in stock tomorrow/today...           0\n",
              "4491  My computer just fried the only essential part...           0\n",
              "856   Talk sexy!! Make new friends or fall in love i...           1\n",
              "5431  Er yeah, i will b there at 15:26, sorry! Just ...           0\n",
              "...                                                 ...         ...\n",
              "1235  \"Hello-/@drivby-:0quit edrunk sorry iff pthis ...           0\n",
              "191   Are you unique enough? Find out from 30th Augu...           1\n",
              "5797  Globe: You’ve won the Netflix Mug in our Givea...           1\n",
              "2490  I have 2 docs appointments next week.:/ I'm ti...           0\n",
              "5088  Omg if its not one thing its another. My cat h...           0\n",
              "\n",
              "[71 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c22025f9-fd89-4d73-b25d-183bd384e704\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3430</th>\n",
              "      <td>I don't know jack shit about anything or i'd s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4111</th>\n",
              "      <td>Yo, you gonna still be in stock tomorrow/today...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4491</th>\n",
              "      <td>My computer just fried the only essential part...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>Talk sexy!! Make new friends or fall in love i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5431</th>\n",
              "      <td>Er yeah, i will b there at 15:26, sorry! Just ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>\"Hello-/@drivby-:0quit edrunk sorry iff pthis ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Are you unique enough? Find out from 30th Augu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5797</th>\n",
              "      <td>Globe: You’ve won the Netflix Mug in our Givea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2490</th>\n",
              "      <td>I have 2 docs appointments next week.:/ I'm ti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5088</th>\n",
              "      <td>Omg if its not one thing its another. My cat h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c22025f9-fd89-4d73-b25d-183bd384e704')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c22025f9-fd89-4d73-b25d-183bd384e704 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c22025f9-fd89-4d73-b25d-183bd384e704');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "id": "Cw3hwJzD-GIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "89b6b4ed-30f6-4155-9ae8-92d16cd2eb56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "4821  Check Out Choose Your Babe Videos @ sms.shsex....           1\n",
              "5667  Keep safe and let me assist you to have a CÀSH...           1\n",
              "5738  Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst & eà...           1\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "913   Can't. I feel nauseous. I'm so pissed. I didn'...           0\n",
              "1556  Ok i found dis pierre cardin one which looks n...           0\n",
              "3864  Oh my god! I've found your number again! I'm s...           1\n",
              "1073  Dear U've been invited to XCHAT. This is our f...           1\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "5615  Did you know that people in cluttered homes ar...           1\n",
              "4005  Well there's a pattern emerging of my friends ...           0\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "4931  Hi, the SEXYCHAT girls are waiting for you to ...           1\n",
              "5783  50k - 2M is the offer just inquire now get it ...           1\n",
              "2680  New Tones This week include: 1)McFly-All Ab..,...           1\n",
              "1244     No shoot me. I'm in the docs waiting room. :/\n",
              "           0\n",
              "4330  1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...           0\n",
              "3422  Welcome! Please reply with your AGE and GENDER...           1\n",
              "6066  Woodsville Residences\n",
              "in Merville Paranaque\n",
              "\n",
              "T...           1\n",
              "4190  Well the general price is  &lt;#&gt; /oz, let ...           0\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "5963  Download to get an exclusive bonus, the super ...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "5728  50k-2M  is the offer just inquire  now get it ...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "6068  Keep safe and let me assist you to have a CÀSH...           1\n",
              "4016  You will be receiving this week's Triple Echo ...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df366f4f-85dc-4aea-98e6-6b59984b90de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4821</th>\n",
              "      <td>Check Out Choose Your Babe Videos @ sms.shsex....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5667</th>\n",
              "      <td>Keep safe and let me assist you to have a CÀSH...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst &amp; eà...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>Can't. I feel nauseous. I'm so pissed. I didn'...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1556</th>\n",
              "      <td>Ok i found dis pierre cardin one which looks n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3864</th>\n",
              "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1073</th>\n",
              "      <td>Dear U've been invited to XCHAT. This is our f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5615</th>\n",
              "      <td>Did you know that people in cluttered homes ar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4005</th>\n",
              "      <td>Well there's a pattern emerging of my friends ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4931</th>\n",
              "      <td>Hi, the SEXYCHAT girls are waiting for you to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5783</th>\n",
              "      <td>50k - 2M is the offer just inquire now get it ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1244</th>\n",
              "      <td>No shoot me. I'm in the docs waiting room. :/</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4330</th>\n",
              "      <td>1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3422</th>\n",
              "      <td>Welcome! Please reply with your AGE and GENDER...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6066</th>\n",
              "      <td>Woodsville Residences\n",
              "in Merville Paranaque\n",
              "\n",
              "T...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4190</th>\n",
              "      <td>Well the general price is  &amp;lt;#&amp;gt; /oz, let ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5963</th>\n",
              "      <td>Download to get an exclusive bonus, the super ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5728</th>\n",
              "      <td>50k-2M  is the offer just inquire  now get it ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6068</th>\n",
              "      <td>Keep safe and let me assist you to have a CÀSH...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4016</th>\n",
              "      <td>You will be receiving this week's Triple Echo ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df366f4f-85dc-4aea-98e6-6b59984b90de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df366f4f-85dc-4aea-98e6-6b59984b90de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df366f4f-85dc-4aea-98e6-6b59984b90de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 Results:** As expected increasing number of epochs slightly improved the f1 score and accuracy. Running it on 3 epochs seemed like a good threshold as the loss function kept decresing but the accuracy stopped improving. We're getting pretty good results with only 18 text messages that got missclassfied from the test."
      ],
      "metadata": {
        "id": "jWSfz5EA9gkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze layers\n",
        "pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)"
      ],
      "metadata": {
        "id": "BlSsZB1z7TXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0499d8c-0006-4c82-f6a8-6e9ce6690bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  class_weight = class_weight, \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=3) "
      ],
      "metadata": {
        "id": "7E1tsBon7nDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5721bce-fd03-422e-c864-d1719cca4f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_6/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_6/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 43s 59ms/step - loss: 0.1414 - accuracy: 0.9431 - val_loss: 0.0768 - val_accuracy: 0.9795\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 33s 54ms/step - loss: 0.0554 - accuracy: 0.9849 - val_loss: 0.0800 - val_accuracy: 0.9820\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 33s 55ms/step - loss: 0.0346 - accuracy: 0.9914 - val_loss: 0.0501 - val_accuracy: 0.9894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "_OpcuEbyAuIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model_unfreeze.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "IsfZJw01A0jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "wENCXkfaBQQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ddb86a16-5921-4a7b-dae3-4ff67a649825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3f42e11950>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "4joh3aupBQwG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b41d9fb2-ab5f-47f4-8dff-e975d523521f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3e384b4c90>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "print_metrics('BERT 3e + FCN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "id": "WRs8lu0JA76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd76b2d-2bbe-49b8-cb91-8aef25698fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, train data: : accuracy = 0.9990, precision = 0.9971, recall = 0.9980, f1 = 0.9975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "print_metrics('BERT 3e + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "JBB3uuD3AqUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e795547d-f43b-478b-e152-f92e6fed1d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, test data: : accuracy = 0.9894, precision = 0.9699, recall = 0.9810, f1 = 0.9754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "id": "_F0aKI--BZ7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "94542e8a-da00-4057-dc6a-4dad2230ea72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "3044        Your bill at 3 is £33.65 so thats not bad!\n",
              "           0\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "1260  We have sent JD for Customer Service cum Accou...           0\n",
              "718   Book which lesson? then you msg me... I will c...           0\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "5581                                                N/a           1\n",
              "2680  New Tones This week include: 1)McFly-All Ab..,...           1\n",
              "4330  1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...           0\n",
              "925   Actually i deleted my old website..now i m blo...           0\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c725da6-59d6-492b-a5ef-31ae3bdf65b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3044</th>\n",
              "      <td>Your bill at 3 is £33.65 so thats not bad!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>Book which lesson? then you msg me... I will c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4330</th>\n",
              "      <td>1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>Actually i deleted my old website..now i m blo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c725da6-59d6-492b-a5ef-31ae3bdf65b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c725da6-59d6-492b-a5ef-31ae3bdf65b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c725da6-59d6-492b-a5ef-31ae3bdf65b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 Results:** Unfreezing the BERT model layers helped with increasing the F1 score to 0.9745 on running the model for 3 epochs. The performance on the training set was excellent which may mean that we're slightly overfitting. \n",
        "\n",
        "Because the performance kept improving we may try to run on a couple more epochs to see if overfitting becomes worse and see if we will hit lower performance on the validation set."
      ],
      "metadata": {
        "id": "7l9OgX4CCA8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze layers\n",
        "pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOcZs6nZCwYq",
        "outputId": "a97c0a6f-c8d3-4ce6-d425-7caa53a64bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change to 5 epochs\n",
        "pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  class_weight = class_weight, \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sSSN7ULC1es",
        "outputId": "956fdcc6-0a5b-48b1-ee12-2af12e4805f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_7/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_7/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 43s 61ms/step - loss: 0.1227 - accuracy: 0.9560 - val_loss: 0.1033 - val_accuracy: 0.9681\n",
            "Epoch 2/5\n",
            "611/611 [==============================] - 34s 56ms/step - loss: 0.0483 - accuracy: 0.9859 - val_loss: 0.0495 - val_accuracy: 0.9869\n",
            "Epoch 3/5\n",
            "611/611 [==============================] - 34s 55ms/step - loss: 0.0254 - accuracy: 0.9939 - val_loss: 0.0736 - val_accuracy: 0.9836\n",
            "Epoch 4/5\n",
            "611/611 [==============================] - 34s 56ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0617 - val_accuracy: 0.9861\n",
            "Epoch 5/5\n",
            "611/611 [==============================] - 34s 56ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0668 - val_accuracy: 0.9885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "_EkvhANcE1R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model_unfreeze.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "F3HqKj74EcdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "5TwzjWs8EM2w",
        "outputId": "e2436d8e-cefe-4c4c-ef21-5c6964411377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "3044        Your bill at 3 is £33.65 so thats not bad!\n",
              "           0\n",
              "5738  Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst & eà...           1\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "714   Save yourself the stress. If the person has a ...           0\n",
              "718   Book which lesson? then you msg me... I will c...           0\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "5581                                                N/a           1\n",
              "2680  New Tones This week include: 1)McFly-All Ab..,...           1\n",
              "334   Any chance you might have had with me evaporat...           0\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b08924e4-50b1-49ff-80d0-5015a682d755\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3044</th>\n",
              "      <td>Your bill at 3 is £33.65 so thats not bad!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst &amp; eà...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>Save yourself the stress. If the person has a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>Book which lesson? then you msg me... I will c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>Any chance you might have had with me evaporat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b08924e4-50b1-49ff-80d0-5015a682d755')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b08924e4-50b1-49ff-80d0-5015a682d755 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b08924e4-50b1-49ff-80d0-5015a682d755');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "print_metrics('BERT 5e + FCN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "# test\n",
        "print_metrics('test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP-dGTD6ExBx",
        "outputId": "830d0a6b-a25f-4da3-d753-7b76daca2462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 5e + FCN, train data: : accuracy = 1.0000, precision = 1.0000, recall = 1.0000, f1 = 1.0000\n",
            "test data: : accuracy = 0.9885, precision = 0.9734, recall = 0.9734, f1 = 0.9734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 Results:** Increasing the number of epochs to 5 has resulted in some overfitting, we see a degraded performance on the test set in F1 score and increase in the number of misclassified examples. As a result of this experiment BERT model with unfrozen layers and 3 epochs proved to produce really good results. \n",
        "\n",
        "Original untuned model test performance:\n",
        "accuracy = 0.9828, precision = 0.9797, recall = 0.9377, f1 = 0.9583\n",
        "\n",
        "\n",
        "Tuned model test performance:\n",
        "accuracy = 0.9893, precision = 0.9841, recall = 0.9650, f1 = 0.9745\n"
      ],
      "metadata": {
        "id": "MLkuzmXNFO08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT + CNN tuning"
      ],
      "metadata": {
        "id": "1CIcslSTOgOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1:** Increase number of epochs and unfreeze BERT layers, not much improvement."
      ],
      "metadata": {
        "id": "rJdcEHPfQ3nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1)\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            class_weight = class_weight, \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsaCz6dnPDgO",
        "outputId": "b049ee94-aa6b-423f-fb8b-feba216040f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 47s 66ms/step - loss: 0.0989 - accuracy: 0.9668 - val_loss: 0.0619 - val_accuracy: 0.9836\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 37s 61ms/step - loss: 0.0430 - accuracy: 0.9879 - val_loss: 0.0944 - val_accuracy: 0.9697\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 37s 61ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0558 - val_accuracy: 0.9869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "TP7lfF9UQvQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdvlFabDQcSH",
        "outputId": "926a4bb7-beff-4873-acd6-d02597abf4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9977, precision = 0.9903, recall = 0.9990, f1 = 0.9946\n",
            "BERT + CNN, test data: : accuracy = 0.9869, precision = 0.9625, recall = 0.9772, f1 = 0.9698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2:** Change kernel sizes, from lit review Roy et al. used the following kernel sizes. Kernel sizes improved the model. But now it overfits given that we're running it on 3 epochs."
      ],
      "metadata": {
        "id": "hPHddgjfRCcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            class_weight = class_weight, \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVMinOwPPxU4",
        "outputId": "3a527158-4775-489a-9822-676fa8e5b064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_9/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_9/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 48s 68ms/step - loss: 0.1088 - accuracy: 0.9648 - val_loss: 0.0470 - val_accuracy: 0.9853\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 37s 61ms/step - loss: 0.0514 - accuracy: 0.9859 - val_loss: 0.0606 - val_accuracy: 0.9804\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 37s 61ms/step - loss: 0.0253 - accuracy: 0.9947 - val_loss: 0.0468 - val_accuracy: 0.9902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "JpLxOK_yRSOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN kernel, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PALsjyI1RS5a",
        "outputId": "7305df56-870c-46a7-b39e-7888c97fcf86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN kernel, train data: : accuracy = 0.9996, precision = 1.0000, recall = 0.9980, f1 = 0.9990\n",
            "test data: : accuracy = 0.9902, precision = 0.9808, recall = 0.9734, f1 = 0.9771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 3:** Decrease the number of filters to offset overfitting and possibly increase performance"
      ],
      "metadata": {
        "id": "VnaafpFDThAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5],\n",
        "                                       num_filters = [32,64,128])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            class_weight = class_weight, \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy32_mv7TMm7",
        "outputId": "1afd2919-b935-453f-bae4-fc821a836c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_10/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_10/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 47s 66ms/step - loss: 0.1003 - accuracy: 0.9658 - val_loss: 0.0483 - val_accuracy: 0.9861\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 37s 60ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.0667 - val_accuracy: 0.9853\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 36s 60ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0592 - val_accuracy: 0.9894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)\n",
        "\n",
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "sVf6Q3ZBUGSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbdc5d56-3e0b-473f-fbe4-10eb3ef3659a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9984, precision = 0.9941, recall = 0.9980, f1 = 0.9961\n",
            "BERT + CNN, test data: : accuracy = 0.9894, precision = 0.9735, recall = 0.9772, f1 = 0.9753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HdBV-7BtXLbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation"
      ],
      "metadata": {
        "id": "_suEHlIKjKat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X)"
      ],
      "metadata": {
        "id": "R8k87gioltGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352aff18-c62f-4870-eb54-2a1c4e4d8fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4885"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X[:977])\n",
        "len(train_X[977:1954])\n",
        "len(train_X[1954:2931])\n",
        "len(train_X[2931:3908])\n",
        "len(train_X[3908:4885])"
      ],
      "metadata": {
        "id": "ySIcuBlBk4jN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9b4255-2370-4350-c5fb-d32ac66eca6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "977"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first fold\n",
        "len(train_X[977:4885]) + len(train_X[:977])"
      ],
      "metadata": {
        "id": "QdRE1Ot2mer5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1e80d6-8436-4455-9fef-628123eaf98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4885"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_val = 5\n",
        "# FOLD_SIZE = 977\n",
        "# for i in range(cross_val):\n",
        "#   test_1 = train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]\n",
        "#   test_2 = train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)]\n"
      ],
      "metadata": {
        "id": "0vdErCr6xAgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CROSS_VAL = 5\n",
        "FOLD_SIZE = 977\n",
        "\n",
        "for i in range(CROSS_VAL):\n",
        "  max_length = 100\n",
        "  #max_length = 160                  # set max_length\n",
        "\n",
        "  all_train_examples = list(train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]])\n",
        "  all_val_examples = list(train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)])\n",
        "  all_test_examples = list(test_X)\n",
        "\n",
        "  x_train = bert_tokenizer(all_train_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_train = tf.convert_to_tensor(list(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]))\n",
        "\n",
        "  x_test = bert_tokenizer(all_test_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_test = tf.convert_to_tensor(list(test_y))\n",
        "\n",
        "  x_val = bert_tokenizer(all_val_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_val = tf.convert_to_tensor(list(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)]))\n",
        "\n",
        "  # unfreeze layers\n",
        "  pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)\n",
        "\n",
        "  # change to 5 epochs\n",
        "  pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                    y_train,   \n",
        "                                                    validation_data=([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask], y_val),    \n",
        "                                                    class_weight = class_weight, \n",
        "                                                    batch_size=8, \n",
        "                                                    epochs=5) \n",
        "\n",
        "  train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "  train_y_predict = train_predict_labels.round(0)\n",
        "\n",
        "  val_predict_labels = pooled_bert_model_unfreeze.predict([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask])\n",
        "  val_y_predict = val_predict_labels.round(0)\n",
        "\n",
        "  # train\n",
        "  print_metrics('BERT 5e + FCN, train', np.array(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]], int), train_y_predict)\n",
        "  # validation\n",
        "  print_metrics('BERT 5e + FCN, validation', np.array(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)], int), val_y_predict)"
      ],
      "metadata": {
        "id": "gYyW1APYkiaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fad35f9-d5b1-4783-efd6-048f23f6df7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "489/489 [==============================] - 69s 105ms/step - loss: 0.1646 - accuracy: 0.9465 - val_loss: 0.1828 - val_accuracy: 0.9468\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 48s 98ms/step - loss: 0.0838 - accuracy: 0.9811 - val_loss: 0.0482 - val_accuracy: 0.9898\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 48s 98ms/step - loss: 0.1156 - accuracy: 0.9816 - val_loss: 0.0445 - val_accuracy: 0.9887\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 48s 98ms/step - loss: 0.1421 - accuracy: 0.9634 - val_loss: 0.1335 - val_accuracy: 0.9744\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 48s 98ms/step - loss: 0.1399 - accuracy: 0.9846 - val_loss: 0.0961 - val_accuracy: 0.9846\n",
            "BERT 5e + FCN, train: accuracy = 0.9869, precision = 0.9974, recall = 0.9399, f1 = 0.9678\n",
            "BERT 5e + FCN, validation: accuracy = 0.9846, precision = 0.9895, recall = 0.9356, f1 = 0.9618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_12/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_12/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 37s 62ms/step - loss: 0.1526 - accuracy: 0.9396 - val_loss: 0.0414 - val_accuracy: 0.9877\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0591 - accuracy: 0.9834 - val_loss: 0.0383 - val_accuracy: 0.9846\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0325 - accuracy: 0.9903 - val_loss: 0.0305 - val_accuracy: 0.9908\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 28s 56ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0254 - val_accuracy: 0.9939\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 28s 56ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.0267 - val_accuracy: 0.9949\n",
            "BERT 5e + FCN, train: accuracy = 0.9997, precision = 0.9988, recall = 1.0000, f1 = 0.9994\n",
            "BERT 5e + FCN, validation: accuracy = 0.9949, precision = 0.9901, recall = 0.9852, f1 = 0.9877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_13/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_13/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 37s 63ms/step - loss: 0.1353 - accuracy: 0.9511 - val_loss: 0.0482 - val_accuracy: 0.9836\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 0.0497 - val_accuracy: 0.9826\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0213 - accuracy: 0.9959 - val_loss: 0.0541 - val_accuracy: 0.9806\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0580 - val_accuracy: 0.9846\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0664 - val_accuracy: 0.9857\n",
            "BERT 5e + FCN, train: accuracy = 0.9992, precision = 0.9975, recall = 0.9988, f1 = 0.9982\n",
            "BERT 5e + FCN, validation: accuracy = 0.9857, precision = 0.9660, recall = 0.9660, f1 = 0.9660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_14/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_14/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_14/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_14/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_14/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_14/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_14/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_14/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 39s 63ms/step - loss: 0.1506 - accuracy: 0.9460 - val_loss: 0.0792 - val_accuracy: 0.9754\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0566 - accuracy: 0.9887 - val_loss: 0.0481 - val_accuracy: 0.9867\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0475 - accuracy: 0.9867 - val_loss: 0.0312 - val_accuracy: 0.9877\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0307 - accuracy: 0.9926 - val_loss: 0.0294 - val_accuracy: 0.9877\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0800 - val_accuracy: 0.9744\n",
            "BERT 5e + FCN, train: accuracy = 0.9862, precision = 0.9390, recall = 0.9975, f1 = 0.9674\n",
            "BERT 5e + FCN, validation: accuracy = 0.9744, precision = 0.8987, recall = 0.9953, f1 = 0.9446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_15/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_15/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_15/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_15/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_15/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_15/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_15/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_15/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 37s 63ms/step - loss: 0.1396 - accuracy: 0.9470 - val_loss: 0.1594 - val_accuracy: 0.9386\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0524 - accuracy: 0.9852 - val_loss: 0.0503 - val_accuracy: 0.9816\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 0.0295 - val_accuracy: 0.9918\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 28s 58ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0327 - val_accuracy: 0.9887\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 28s 58ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.0250 - val_accuracy: 0.9949\n",
            "BERT 5e + FCN, train: accuracy = 0.9995, precision = 1.0000, recall = 0.9976, f1 = 0.9988\n",
            "BERT 5e + FCN, validation: accuracy = 0.9949, precision = 1.0000, recall = 0.9740, f1 = 0.9868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy = 0.9846, precision = 0.9895, recall = 0.9356, f1 = 0.9618\n",
        "\n",
        "accuracy = 0.9949, precision = 0.9901, recall = 0.9852, f1 = 0.9877\n",
        "\n",
        "accuracy = 0.9857, precision = 0.9660, recall = 0.9660, f1 = 0.9660\n",
        "\n",
        "accuracy = 0.9744, precision = 0.8987, recall = 0.9953, f1 = 0.9446\n",
        "\n",
        "accuracy = 0.9949, precision = 1.0000, recall = 0.9740, f1 = 0.9868"
      ],
      "metadata": {
        "id": "t4hScVQZ4NAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation results\n",
        "import numpy as np\n",
        "cross_val_acc = [0.9846, 0.9949, 0.9857,0.9744,0.9949]\n",
        "cross_val_precision = [0.9895,0.9901,0.9660,0.8987,1.0000]\n",
        "cross_val_recall = []\n",
        "cross_val_f1 = [0.9618, 0.9877, 0.9660, 0.9446, 0.9868]\n",
        "\n",
        "print(\"mean accuracy\", np.mean(cross_val_acc))\n",
        "print(\"mean f1\", np.mean(cross_val_f1))\n",
        "\n",
        "print(\"st dev accuracy\", np.std(cross_val_acc))\n",
        "print(\"se dev f1\", np.std(cross_val_f1))"
      ],
      "metadata": {
        "id": "_pn9z7wQpwEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd21fab2-4a07-4b7a-b959-449b218c7412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy 0.9869000000000001\n",
            "mean f1 0.9693799999999999\n",
            "st dev accuracy 0.007628630283347057\n",
            "se dev f1 0.016260430498606128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RmExkj8Z9G03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CROSS_VAL = 5\n",
        "FOLD_SIZE = 977\n",
        "\n",
        "for i in range(CROSS_VAL):\n",
        "  max_length = 100\n",
        "  #max_length = 160                  # set max_length\n",
        "\n",
        "  all_train_examples = list(train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]])\n",
        "  all_val_examples = list(train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)])\n",
        "  all_test_examples = list(test_X)\n",
        "\n",
        "  x_train = bert_tokenizer(all_train_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_train = tf.convert_to_tensor(list(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]))\n",
        "\n",
        "  x_test = bert_tokenizer(all_test_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_test = tf.convert_to_tensor(list(test_y))\n",
        "\n",
        "  x_val = bert_tokenizer(all_val_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_val = tf.convert_to_tensor(list(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)]))\n",
        "\n",
        "  cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "  cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            class_weight = class_weight, \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)\n",
        "\n",
        "\n",
        "\n",
        "  train_predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "  train_y_predict = train_predict_labels.round(0)\n",
        "\n",
        "  val_predict_labels = cnn_bert_model.predict([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask])\n",
        "  val_y_predict = val_predict_labels.round(0)\n",
        "\n",
        "  # train\n",
        "  print_metrics('BERT 3e + CNN kernel un, train', np.array(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]], int), train_y_predict)\n",
        "  # validation\n",
        "  print_metrics('validation', np.array(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)], int), val_y_predict)"
      ],
      "metadata": {
        "id": "cbUWBxG6hkCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b9cf92-fc29-4c72-8ad4-94ee20e2d6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_16/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_16/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 41s 69ms/step - loss: 0.1233 - accuracy: 0.9539 - val_loss: 0.0469 - val_accuracy: 0.9861\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 30s 62ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.1476 - val_accuracy: 0.9444\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 31s 63ms/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.0430 - val_accuracy: 0.9894\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9995, precision = 0.9976, recall = 1.0000, f1 = 0.9988\n",
            "validation: accuracy = 0.9939, precision = 0.9900, recall = 0.9802, f1 = 0.9851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_17/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_17/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_17/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_17/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_17/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_17/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_17/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_17/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 42s 69ms/step - loss: 0.1348 - accuracy: 0.9557 - val_loss: 0.1111 - val_accuracy: 0.9591\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 31s 63ms/step - loss: 0.0541 - accuracy: 0.9831 - val_loss: 0.0564 - val_accuracy: 0.9812\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 31s 63ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 0.0543 - val_accuracy: 0.9869\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9980, precision = 0.9915, recall = 0.9988, f1 = 0.9951\n",
            "validation: accuracy = 0.9918, precision = 0.9899, recall = 0.9704, f1 = 0.9801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_18/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_18/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_18/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_18/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_18/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_18/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_18/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_18/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 41s 69ms/step - loss: 0.1185 - accuracy: 0.9583 - val_loss: 0.1308 - val_accuracy: 0.9542\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 31s 63ms/step - loss: 0.0483 - accuracy: 0.9869 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 31s 64ms/step - loss: 0.0278 - accuracy: 0.9923 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9990, precision = 0.9975, recall = 0.9975, f1 = 0.9975\n",
            "validation: accuracy = 0.9836, precision = 0.9567, recall = 0.9660, f1 = 0.9614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_19/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_19/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_19/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_19/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_19/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_19/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_19/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_19/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 42s 71ms/step - loss: 0.1285 - accuracy: 0.9547 - val_loss: 0.0750 - val_accuracy: 0.9795\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 31s 64ms/step - loss: 0.0596 - accuracy: 0.9829 - val_loss: 0.0509 - val_accuracy: 0.9894\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 31s 64ms/step - loss: 0.0337 - accuracy: 0.9900 - val_loss: 0.0505 - val_accuracy: 0.9861\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9987, precision = 1.0000, recall = 0.9938, f1 = 0.9969\n",
            "validation: accuracy = 0.9887, precision = 0.9951, recall = 0.9533, f1 = 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_20/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_20/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_20/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_20/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_20/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_20/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_20/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_20/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 41s 70ms/step - loss: 0.1190 - accuracy: 0.9588 - val_loss: 0.0690 - val_accuracy: 0.9771\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 31s 64ms/step - loss: 0.0477 - accuracy: 0.9887 - val_loss: 0.0672 - val_accuracy: 0.9820\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 31s 64ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.0586 - val_accuracy: 0.9877\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9987, precision = 0.9988, recall = 0.9952, f1 = 0.9970\n",
            "validation: accuracy = 0.9928, precision = 0.9843, recall = 0.9792, f1 = 0.9817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy = 0.9939, precision = 0.9900, recall = 0.9802, f1 = 0.9851\n",
        "\n",
        "accuracy = 0.9918, precision = 0.9899, recall = 0.9704, f1 = 0.9801\n",
        "\n",
        "accuracy = 0.9836, precision = 0.9567, recall = 0.9660, f1 = 0.9614\n",
        "\n",
        "accuracy = 0.9887, precision = 0.9951, recall = 0.9533, f1 = 0.9737\n",
        "\n",
        "accuracy = 0.9928, precision = 0.9843, recall = 0.9792, f1 = 0.9817\n"
      ],
      "metadata": {
        "id": "4ZPhvf8ozQTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation results\n",
        "cross_val_acc = [0.9939, 0.9918, 0.9836, 0.9887, 0.9928]\n",
        "cross_val_precision = []\n",
        "cross_val_recall = []\n",
        "cross_val_f1 = [0.9851, 0.9801, 0.9614, 0.9737, 0.9817]\n",
        "\n",
        "print(\"mean accuracy\", np.mean(cross_val_acc))\n",
        "print(\"mean f1\", np.mean(cross_val_f1))\n",
        "\n",
        "print(\"st dev accuracy\", np.std(cross_val_acc))\n",
        "print(\"se dev f1\", np.std(cross_val_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENs2yinEzV64",
        "outputId": "3ee8b514-8bed-4d54-84b2-700b1fc16093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy 0.99016\n",
            "mean f1 0.9763999999999999\n",
            "st dev accuracy 0.003709770882413083\n",
            "se dev f1 0.008363731224758463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CROSS_VAL = 5\n",
        "FOLD_SIZE = 977\n",
        "\n",
        "for i in range(CROSS_VAL):\n",
        "  #max_length = 100\n",
        "  max_length = 160                  # set max_length\n",
        "\n",
        "  all_train_examples = list(train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]])\n",
        "  all_val_examples = list(train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)])\n",
        "  all_test_examples = list(test_X)\n",
        "\n",
        "  x_train = bert_tokenizer(all_train_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_train = tf.convert_to_tensor(list(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]))\n",
        "\n",
        "  x_test = bert_tokenizer(all_test_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_test = tf.convert_to_tensor(list(test_y))\n",
        "\n",
        "  x_val = bert_tokenizer(all_val_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_val = tf.convert_to_tensor(list(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)]))\n",
        "\n",
        "  cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "  cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            class_weight = class_weight, \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)\n",
        "\n",
        "\n",
        "\n",
        "  train_predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "  train_y_predict = train_predict_labels.round(0)\n",
        "\n",
        "  val_predict_labels = cnn_bert_model.predict([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask])\n",
        "  val_y_predict = val_predict_labels.round(0)\n",
        "\n",
        "  # train\n",
        "  print_metrics('BERT 3e + CNN kernel un 160, train', np.array(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]], int), train_y_predict)\n",
        "  # validation\n",
        "  print_metrics('validation', np.array(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)], int), val_y_predict)"
      ],
      "metadata": {
        "id": "E_niVw1piMlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e57a65-735a-4c10-f153-23a2a25236c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_21/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_21/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_21/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_21/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_21/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_21/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_21/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_21/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 49s 86ms/step - loss: 0.1207 - accuracy: 0.9550 - val_loss: 0.0540 - val_accuracy: 0.9836\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 39s 80ms/step - loss: 0.0477 - accuracy: 0.9841 - val_loss: 0.0464 - val_accuracy: 0.9861\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 39s 79ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0610 - val_accuracy: 0.9828\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9969, precision = 0.9855, recall = 1.0000, f1 = 0.9927\n",
            "validation: accuracy = 0.9846, precision = 0.9474, recall = 0.9802, f1 = 0.9635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_22/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_22/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_22/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_22/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_22/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_22/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_22/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_22/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 50s 86ms/step - loss: 0.1282 - accuracy: 0.9547 - val_loss: 0.0458 - val_accuracy: 0.9869\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 39s 80ms/step - loss: 0.0474 - accuracy: 0.9844 - val_loss: 0.0683 - val_accuracy: 0.9795\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 39s 80ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0427 - val_accuracy: 0.9861\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9990, precision = 1.0000, recall = 0.9951, f1 = 0.9975\n",
            "validation: accuracy = 0.9939, precision = 1.0000, recall = 0.9704, f1 = 0.9850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_23/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_23/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_23/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_23/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_23/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_23/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_23/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_23/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 49s 86ms/step - loss: 0.1387 - accuracy: 0.9575 - val_loss: 0.0515 - val_accuracy: 0.9828\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 39s 80ms/step - loss: 0.0436 - accuracy: 0.9869 - val_loss: 0.0474 - val_accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 39s 80ms/step - loss: 0.0319 - accuracy: 0.9926 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9987, precision = 1.0000, recall = 0.9938, f1 = 0.9969\n",
            "validation: accuracy = 0.9898, precision = 0.9949, recall = 0.9563, f1 = 0.9752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_24/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_24/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_24/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_24/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_24/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_24/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_24/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_24/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_24/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_24/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_24/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 50s 87ms/step - loss: 0.1102 - accuracy: 0.9614 - val_loss: 0.0532 - val_accuracy: 0.9836\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 39s 80ms/step - loss: 0.0513 - accuracy: 0.9875 - val_loss: 0.0518 - val_accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 39s 81ms/step - loss: 0.0298 - accuracy: 0.9931 - val_loss: 0.0658 - val_accuracy: 0.9845\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9982, precision = 1.0000, recall = 0.9913, f1 = 0.9956\n",
            "validation: accuracy = 0.9857, precision = 0.9854, recall = 0.9486, f1 = 0.9667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_25/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_25/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_25/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_25/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_25/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_25/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_25/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_25/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_25/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_25/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_25/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 50s 86ms/step - loss: 0.1200 - accuracy: 0.9601 - val_loss: 0.0689 - val_accuracy: 0.9804\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 40s 81ms/step - loss: 0.0509 - accuracy: 0.9867 - val_loss: 0.0551 - val_accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 40s 81ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.0629 - val_accuracy: 0.9877\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9987, precision = 0.9952, recall = 0.9988, f1 = 0.9970\n",
            "validation: accuracy = 0.9918, precision = 0.9694, recall = 0.9896, f1 = 0.9794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy = 0.9898, precision = 0.9800, recall = 0.9703, f1 = 0.9751\n",
        "\n",
        "accuracy = 0.9939, precision = 0.9950, recall = 0.9754, f1 = 0.9851\n",
        "\n",
        "accuracy = 0.9877, precision = 0.9899, recall = 0.9515, f1 = 0.9703\n",
        "\n",
        "accuracy = 0.9908, precision = 0.9952, recall = 0.9626, f1 = 0.9786\n",
        "\n",
        "accuracy = 0.9928, precision = 0.9843, recall = 0.9792, f1 = 0.9817"
      ],
      "metadata": {
        "id": "RuO_LeMw0oG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation results\n",
        "cross_val_acc = [0.9898,0.9939,0.9877,0.9908,0.9928]\n",
        "cross_val_precision = [0.9800, 0.9950, 0.9899, 0.9952,0.9843]\n",
        "cross_val_recall = [0.9703,0.9754,0.9515,0.9626,0.9792]\n",
        "cross_val_f1 = [0.9751, 0.9851, 0.9703, 0.9786, 0.9817]\n",
        "\n",
        "print(\"mean accuracy\", np.mean(cross_val_acc))\n",
        "print(\"mean f1\", np.mean(cross_val_f1))\n",
        "\n",
        "print(\"st dev accuracy\", np.std(cross_val_acc))\n",
        "print(\"se dev f1\", np.std(cross_val_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sPFw0Xv0Cwf",
        "outputId": "5a161ecc-f81b-4260-caa8-75e6509bc8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy 0.991\n",
            "mean f1 0.9781600000000001\n",
            "st dev accuracy 0.0021918029108475927\n",
            "se dev f1 0.005138715792880537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Count unknown tokens"
      ],
      "metadata": {
        "id": "gThMPxB9_HjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for sms in data['english']:\n",
        "  if ('[UNK]' in bert_tokenizer.tokenize(sms)):\n",
        "    count += 1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "id": "mvnw49FrDD0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa6d188-bd65-4630-b1b5-dad0a6516ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for sms in data[data['crowd'] == 1]['english']:\n",
        "  if ('[UNK]' in bert_tokenizer.tokenize(sms)):\n",
        "    count += 1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "id": "jNgvXDu7_sGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1dd7d1e-9d24-44df-bb27-38efc2ab6325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for sms in data[data['crowd'] == 0]['english']:\n",
        "  if ('[UNK]' in bert_tokenizer.tokenize(sms)):\n",
        "    count += 1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "id": "jnpYrfDEE-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333aa585-9dfd-424d-f913-14d6a8feb5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n6gNssCaEjZf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}