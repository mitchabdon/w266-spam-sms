{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W266: UCI + PH Dataset SMS Spam Detection Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c188d57d4e1470bbdf34493318d3fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d94a3714f6b42c6a48ad359abde3bdf",
              "IPY_MODEL_1fe3abfb62334ea581a86c8ea8b8dc8d",
              "IPY_MODEL_904934d43d87430a825721cce6cd037c"
            ],
            "layout": "IPY_MODEL_ec88cdbdad2a4597a5c05182426ee5a7"
          }
        },
        "0d94a3714f6b42c6a48ad359abde3bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f8d6ef4509460ab435fea88665a3c8",
            "placeholder": "​",
            "style": "IPY_MODEL_22d0791c9e6d4b83be156312fcd078bc",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "1fe3abfb62334ea581a86c8ea8b8dc8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e975b999a0945c684c487de46d87226",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6da2367d50ac426bb0f95a1146783c07",
            "value": 213450
          }
        },
        "904934d43d87430a825721cce6cd037c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f261c1408742529f0d2de12757629e",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1e401c8acd42c1a2766d7406b9e399",
            "value": " 208k/208k [00:00&lt;00:00, 259kB/s]"
          }
        },
        "ec88cdbdad2a4597a5c05182426ee5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f8d6ef4509460ab435fea88665a3c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22d0791c9e6d4b83be156312fcd078bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e975b999a0945c684c487de46d87226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6da2367d50ac426bb0f95a1146783c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64f261c1408742529f0d2de12757629e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1e401c8acd42c1a2766d7406b9e399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "230b9d48bf9448ff8cf20e28a9d48f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1b12aad94d34c11acdb5e5901e17134",
              "IPY_MODEL_5caf805a9b9c41aeb11283c8d0c41bf0",
              "IPY_MODEL_dc9c807359de428dbd84ae222d9ba016"
            ],
            "layout": "IPY_MODEL_b23b453bfc604fc7bacbe405ce1d37c3"
          }
        },
        "d1b12aad94d34c11acdb5e5901e17134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36292353e51444408e24096c54ac3af2",
            "placeholder": "​",
            "style": "IPY_MODEL_348f03afc2d94b62a52d2d528e9b7656",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "5caf805a9b9c41aeb11283c8d0c41bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6430e36894a447a1944176d0e639c613",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7b7578ca32e4b8698a38756b5e20aea",
            "value": 29
          }
        },
        "dc9c807359de428dbd84ae222d9ba016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c854c6c1968f434398681aca1d6f6edb",
            "placeholder": "​",
            "style": "IPY_MODEL_aff022c326344f7e995067b3554e82e2",
            "value": " 29.0/29.0 [00:00&lt;00:00, 719B/s]"
          }
        },
        "b23b453bfc604fc7bacbe405ce1d37c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36292353e51444408e24096c54ac3af2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348f03afc2d94b62a52d2d528e9b7656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6430e36894a447a1944176d0e639c613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b7578ca32e4b8698a38756b5e20aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c854c6c1968f434398681aca1d6f6edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff022c326344f7e995067b3554e82e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e327df3b508d431f81eb7e7b234cde44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31b0322fd32a4f288279b2da14228fc6",
              "IPY_MODEL_c37c003010f147d8937258fad0035d74",
              "IPY_MODEL_d80faa4f0019476e83638f99d153d01f"
            ],
            "layout": "IPY_MODEL_201e1e111be14e04b85f3b1e0d180bb7"
          }
        },
        "31b0322fd32a4f288279b2da14228fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3462fced66141beb56aea71272afb74",
            "placeholder": "​",
            "style": "IPY_MODEL_803616b93e9043259adcb0a1e9ba5ec6",
            "value": "Downloading config.json: 100%"
          }
        },
        "c37c003010f147d8937258fad0035d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44cc0c6edab44248adb0ccd88292839a",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69241fa373864aebbdae3810d79e1cb1",
            "value": 570
          }
        },
        "d80faa4f0019476e83638f99d153d01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cfb39c639ad40b6b2294d94b92c45be",
            "placeholder": "​",
            "style": "IPY_MODEL_0532d10f487b4ed181b87d90f7da4e63",
            "value": " 570/570 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "201e1e111be14e04b85f3b1e0d180bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3462fced66141beb56aea71272afb74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803616b93e9043259adcb0a1e9ba5ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44cc0c6edab44248adb0ccd88292839a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69241fa373864aebbdae3810d79e1cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cfb39c639ad40b6b2294d94b92c45be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0532d10f487b4ed181b87d90f7da4e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "613ba2a425d549f99ec75422095ddf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61dc7840714045d8af6848db9bf2a507",
              "IPY_MODEL_97daf78394014d85a13f11f8b96828da",
              "IPY_MODEL_7bcfafaa7ff84d399a2b612008d707fe"
            ],
            "layout": "IPY_MODEL_d1482f81be4641cabe33c20bce252235"
          }
        },
        "61dc7840714045d8af6848db9bf2a507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30718d9461da4a558c7726d96541b077",
            "placeholder": "​",
            "style": "IPY_MODEL_ed20d26c90b243f1ad02d00259ccb32b",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "97daf78394014d85a13f11f8b96828da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601ecd14def14daf9c4d0c1a6759892d",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19cc5a8fb26849d6a5627eb7e20ea1ba",
            "value": 526681800
          }
        },
        "7bcfafaa7ff84d399a2b612008d707fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f99422cee4b14302998ebe25d8d4690f",
            "placeholder": "​",
            "style": "IPY_MODEL_8d809711851e4fbdbb5865511db3dc47",
            "value": " 502M/502M [00:09&lt;00:00, 60.9MB/s]"
          }
        },
        "d1482f81be4641cabe33c20bce252235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30718d9461da4a558c7726d96541b077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed20d26c90b243f1ad02d00259ccb32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "601ecd14def14daf9c4d0c1a6759892d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19cc5a8fb26849d6a5627eb7e20ea1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f99422cee4b14302998ebe25d8d4690f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d809711851e4fbdbb5865511db3dc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Table of content and model results\n",
        "\n"
      ],
      "metadata": {
        "id": "zL6g1T8Jeyi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline\n",
        "W2V + CNN, \n",
        ">train data: accuracy = 0.9316, precision = 0.8450, recall = 0.8442, f1 = 0.8446\n",
        ">\n",
        ">test data: accuracy = 0.8936, precision = 0.7473, recall = 0.8046, f1 = 0.7749\n",
        "\n",
        "W2V + LSTM\n",
        ">train data: : accuracy = 0.9099, precision = 0.8210, recall = 0.7554, f1 = 0.7869\n",
        ">\n",
        ">test data: : accuracy = 0.8945, precision = 0.7893, recall = 0.7318, f1 = 0.7594\n",
        "\n",
        "BERT + FCN, \n",
        ">train data: : accuracy = 0.9875, precision = 0.9535, recall = 0.9882, f1 = 0.9705\n",
        ">\n",
        ">test data: : accuracy = 0.9763, precision = 0.9179, recall = 0.9772, f1 = 0.9466\n",
        "\n",
        "**BERT + CNN** (Best baseline)\n",
        ">train data: : accuracy = 0.9894, precision = 0.9707, recall = 0.9784, f1 = 0.9745\n",
        ">\n",
        ">test data: : accuracy = 0.9787, precision = 0.9405, recall = 0.9620, f1 = 0.9511\n",
        "\n",
        "### Tuning\n",
        "\n",
        "BERT 3e + FCN\n",
        ">train data: : accuracy = 0.9953, precision = 0.9892, recall = 0.9882, f1 = 0.9887\n",
        ">\n",
        ">test data: : accuracy = 0.9869, precision = 0.9625, recall = 0.9772, f1 = 0.9698\n",
        "\n",
        "BERT 3e + FCN unfreeze\n",
        ">train data: : accuracy = 0.9953, precision = 1.0000, recall = 0.9774, f1 = 0.9886\n",
        ">\n",
        ">test data: : accuracy = 0.9828, precision = 0.9840, recall = 0.9354, f1 = 0.9591\n",
        "\n",
        "BERT 5e + FCN unfreeze\n",
        ">train data: : accuracy = 0.9998, precision = 1.0000, recall = 0.9990, f1 = 0.9995\n",
        ">\n",
        ">test data: : accuracy = 0.9910, precision = 0.9773, recall = 0.9810, f1 = 0.9791\n",
        "\n",
        "BERT 3e + CNN unfreeze\n",
        ">train data: : accuracy = 0.9986, precision = 1.0000, recall = 0.9931, f1 = 0.9965\n",
        ">\n",
        ">test data: : accuracy = 0.9861, precision = 0.9767, recall = 0.9582, f1 = 0.9674\n",
        "\n",
        "**BERT + CNN unfreeze kernel** (Best model)\n",
        ">train data: : accuracy = 0.9986, precision = 1.0000, recall = 0.9931, f1 = 0.9965\n",
        ">\n",
        ">test data: : accuracy = 0.9918, precision = 0.9884, recall = 0.9734, f1 = 0.9808\n",
        "\n",
        "BERT + CNN unfreeze filters\n",
        "\n",
        ">train data: : accuracy = 0.9982, precision = 1.0000, recall = 0.9912, f1 = 0.9956\n",
        ">\n",
        ">test data: : accuracy = 0.9877, precision = 0.9844, recall = 0.9582, f1 = 0.9711"
      ],
      "metadata": {
        "id": "zewIcVHferk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "AitRMbM6R_23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.8.3 --quiet"
      ],
      "metadata": {
        "id": "uFMQmofaT2x_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e450c991-8c1d-49d3-bbb2-b9877bc78ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "id": "ZepWG26Pb36a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8927ed4a-3e53-4206-e249-d873d1955ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.7 MB 29.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 55.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 74.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-text==2.8.2 --quiet"
      ],
      "metadata": {
        "id": "LBz57saHcLid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994a32f4-6ae2-4353-9f31-500ca9ef79d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 33.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# misc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)\n",
        "\n",
        "# report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# word2vec\n",
        "import nltk\n",
        "import gensim\n",
        "from nltk.data import find\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "# BERT\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "metadata": {
        "id": "EvPhbSW1rrdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYU51GnwRSs_",
        "outputId": "e5970c16-25d5-412b-929a-d90cabfe9039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and clean data"
      ],
      "metadata": {
        "id": "U6oStQMXSEyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename uci data to just data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/W266: SMS Spam Detection Final Project/data/data_clean_trans.csv\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "E2RqNNQxKuVT",
        "outputId": "1e509de4-24d7-4b9a-f9ac-2328dcd8943c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  spam                                               text  \\\n",
              "0              0     0  Go until jurong point, crazy.. Available only ...   \n",
              "1              1     0                    Ok lar... Joking wif u oni...\\n   \n",
              "2              2     1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3              3     0  U dun say so early hor... U c already then say...   \n",
              "4              4     0  Nah I don't think he goes to usf, he lives aro...   \n",
              "...          ...   ...                                                ...   \n",
              "6102        6102     1  You have passed the official certification onl...   \n",
              "6103        6103     1  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...   \n",
              "6104        6104     1  Hi, I'm a Shopee Hiring Manager and I'm curren...   \n",
              "6105        6105     1  4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...   \n",
              "6106        6106     1  Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...   \n",
              "\n",
              "      crowd                                            spanish language  \\\n",
              "0         0  Vaya hasta Jurong Point, loco ... disponible s...       en   \n",
              "1         0               Ok lar ... bromeando wif u oni ...\\n       en   \n",
              "2         0  Entrada gratuita en 2 una compensación de wkly...       en   \n",
              "3         0    No digo tan temprano hor ... ya c ya digo ...\\n       en   \n",
              "4         0  No, no creo que vaya a la USF, aunque vive por...       en   \n",
              "...     ...                                                ...      ...   \n",
              "6102      1  Ha aprobado la certificación oficial de la aud...       en   \n",
              "6103      1  ¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...       en   \n",
              "6104      1  Hola, soy un gerente de contratación de Shopee...       en   \n",
              "6105      1  ¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...      fil   \n",
              "6106      1  Sissy, solo 1p por apuesta para Cutt.ly/BingOp...      fil   \n",
              "\n",
              "                                                english  \n",
              "0     Go until jurong point, crazy.. Available only ...  \n",
              "1                       Ok lar... Joking wif u oni...\\n  \n",
              "2     Free entry in 2 a wkly comp to win FA Cup fina...  \n",
              "3     U dun say so early hor... U c already then say...  \n",
              "4     Nah I don't think he goes to usf, he lives aro...  \n",
              "...                                                 ...  \n",
              "6102  You have passed the official certification onl...  \n",
              "6103  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...  \n",
              "6104  Hi, I'm a Shopee Hiring Manager and I'm curren...  \n",
              "6105  4 pcs solar lights for only 1,499!\\nMost cheap...  \n",
              "6106  Sissy, just 1p per bet for cutt.ly/bingoplus-p...  \n",
              "\n",
              "[6107 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed39a0b8-4379-4f1a-a3fd-9ff0552a681a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>spam</th>\n",
              "      <th>text</th>\n",
              "      <th>crowd</th>\n",
              "      <th>spanish</th>\n",
              "      <th>language</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Vaya hasta Jurong Point, loco ... disponible s...</td>\n",
              "      <td>en</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar ... bromeando wif u oni ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>0</td>\n",
              "      <td>Entrada gratuita en 2 una compensación de wkly...</td>\n",
              "      <td>en</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "      <td>No digo tan temprano hor ... ya c ya digo ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "      <td>No, no creo que vaya a la USF, aunque vive por...</td>\n",
              "      <td>en</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6102</th>\n",
              "      <td>6102</td>\n",
              "      <td>1</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "      <td>1</td>\n",
              "      <td>Ha aprobado la certificación oficial de la aud...</td>\n",
              "      <td>en</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6103</th>\n",
              "      <td>6103</td>\n",
              "      <td>1</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...</td>\n",
              "      <td>en</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6104</th>\n",
              "      <td>6104</td>\n",
              "      <td>1</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "      <td>1</td>\n",
              "      <td>Hola, soy un gerente de contratación de Shopee...</td>\n",
              "      <td>en</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6105</th>\n",
              "      <td>6105</td>\n",
              "      <td>1</td>\n",
              "      <td>4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...</td>\n",
              "      <td>fil</td>\n",
              "      <td>4 pcs solar lights for only 1,499!\\nMost cheap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6106</th>\n",
              "      <td>6106</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, solo 1p por apuesta para Cutt.ly/BingOp...</td>\n",
              "      <td>fil</td>\n",
              "      <td>Sissy, just 1p per bet for cutt.ly/bingoplus-p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6107 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed39a0b8-4379-4f1a-a3fd-9ff0552a681a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed39a0b8-4379-4f1a-a3fd-9ff0552a681a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed39a0b8-4379-4f1a-a3fd-9ff0552a681a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.convert_dtypes()\n",
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47UovwLKgvce",
        "outputId": "10254269-6cc1-4df0-b3da-40569c3dc8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0     Int64\n",
              "spam           Int64\n",
              "text          string\n",
              "crowd          Int64\n",
              "spanish       string\n",
              "language      string\n",
              "english       string\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "0RuqEtIVSOkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(data[\"spam\"] == 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6pRHRdg8MoI",
        "outputId": "770f8edd-8ed5-4fde-979f-86436de17f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1280"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(data[\"spam\"] == 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKlzqlpy8u1Y",
        "outputId": "8a19ee33-c9a0-40f2-b46f-eadece6cbd31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4827"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data"
      ],
      "metadata": {
        "id": "GmTIZRghbCkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: data is unbalanced we may need to fix it\n",
        "X, y = data['text'], data['spam']\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)"
      ],
      "metadata": {
        "id": "KlJMJlhpVtnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "VVX5ga_ODFrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(test_name, y_true, y_pred):\n",
        "    print('%s: accuracy = %.4f, precision = %.4f, recall = %.4f, f1 = %.4f'\n",
        "          % (test_name,\n",
        "             metrics.accuracy_score(y_true, y_pred),\n",
        "             metrics.precision_score(y_true, y_pred),\n",
        "             metrics.recall_score(y_true, y_pred),\n",
        "             metrics.f1_score(y_true, y_pred)))"
      ],
      "metadata": {
        "id": "rYG1iASIDEj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base models\n",
        "\n",
        "- Word2Vec embeddings\n",
        "  - CNN\n",
        "  - LSTM\n",
        "\n",
        "- BERT embeddings\n",
        "  - Fully connected network\n",
        "  - CNN\n"
      ],
      "metadata": {
        "id": "K0oBtsKoSTEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Word2Vec embeddings"
      ],
      "metadata": {
        "id": "MySc4TsBTRdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('word2vec_sample')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BFkjykfSUQy",
        "outputId": "00d4226f-eeb5-40af-b50d-5e0675abb0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))"
      ],
      "metadata": {
        "id": "Gz7wtvLeXJb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
      ],
      "metadata": {
        "id": "uY2qQt3oTxpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a Word2Vec embedding\n",
        "EMBEDDING_DIM = len(model['university'])      # we know... it's 300\n",
        "\n",
        "# initialize embedding matrix and word-to-id map:\n",
        "embedding_matrix = np.zeros((len(model.vocab.keys()) + 1, EMBEDDING_DIM))       \n",
        "vocab_dict = {}\n",
        "\n",
        "# build the embedding matrix and the word-to-id map:\n",
        "for i, word in enumerate(model.vocab.keys()):\n",
        "    embedding_vector = model[word]\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        vocab_dict[word] = i\n",
        "\n"
      ],
      "metadata": {
        "id": "LJwX14iJWwvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "train_tokens = tokenizer.tokenize(train_X)\n",
        "test_tokens = tokenizer.tokenize(test_X)"
      ],
      "metadata": {
        "id": "hlQF33RqYvfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SvpFHLNZVJb",
        "outputId": "29f31977-3612-4874-b310-6a80de01f0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(18,), dtype=string, numpy=\n",
              "array([b\"You've\", b'won', b'tkts', b'to', b'the', b'EURO2004', b'CUP',\n",
              "       b'FINAL', b'or', b'\\xc2\\xa3800', b'CASH,', b'to', b'collect',\n",
              "       b'CALL', b'09058099801', b'b4190604,', b'POBOX', b'7876150ppm'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: make sure this is tuned\n",
        "MAX_SEQUENCE_LENGTH = 5"
      ],
      "metadata": {
        "id": "FTR331lLZi8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sents_to_ids(token_list_list, label_list, num_examples=100000000):\n",
        "    \"\"\"\n",
        "    converting a list of strings to a list of lists of word ids\n",
        "    \"\"\"\n",
        "    text_ids = []\n",
        "    text_labels = []\n",
        "    example_count = 0\n",
        "    use_token_list_list = token_list_list[:num_examples]\n",
        "    for i, token_list in enumerate(use_token_list_list):\n",
        "        if i < num_examples:\n",
        "            try:\n",
        "                example = []\n",
        "                for token in list(token_list.numpy()):\n",
        "                    decoded = token.decode('utf-8').replace('.','').replace(',','').replace('!','')\n",
        "                    try:\n",
        "                        example.append(vocab_dict[decoded])\n",
        "                        \n",
        "                    except:\n",
        "                        example.append(43981)\n",
        "                if len(example) >= MAX_SEQUENCE_LENGTH:\n",
        "                    text_ids.append(example[:MAX_SEQUENCE_LENGTH])\n",
        "                    text_labels.append(label_list[i])\n",
        "                    if example_count % 5000 == 0:\n",
        "                        print('Examples processed: ', example_count)\n",
        "                    example_count += 1\n",
        "                else:\n",
        "                    pass\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    \n",
        "    print('Number of examples retained: ', example_count) \n",
        "    return (np.array(text_ids),   np.array(text_labels)) "
      ],
      "metadata": {
        "id": "ohRUVRzOZmi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to tensor\n",
        "y_train = tf.convert_to_tensor(list(train_y))\n",
        "y_test = tf.convert_to_tensor(list(test_y))"
      ],
      "metadata": {
        "id": "WsNjF9JlZzl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input, train_input_labels = sents_to_ids(train_tokens, y_train)\n",
        "test_input, test_input_labels = sents_to_ids(test_tokens, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJrOVPu2Zniw",
        "outputId": "90f26213-bc37-4715-f3c3-77230f33e3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples processed:  0\n",
            "Number of examples retained:  4605\n",
            "Examples processed:  0\n",
            "Number of examples retained:  1147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN"
      ],
      "metadata": {
        "id": "HCn1BoEaPA6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                            embedding_matrix.shape[1],\n",
        "                            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "metadata": {
        "id": "hypVVE0gVWFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify model hyperparameters.\n",
        "epochs = 10\n",
        "num_filters = [3, 2, 1]\n",
        "kernel_sizes = [2, 4, 5]\n",
        "dense_layer_dims = [100, 30]\n",
        "dropout_rate = 0.5"
      ],
      "metadata": {
        "id": "eQ6kHgIYV4Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')"
      ],
      "metadata": {
        "id": "g3uG2-WBV_qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_embeddings = cnn_embedding_layer(cnn_input_layer)\n",
        "\n",
        "h = cnn_embeddings"
      ],
      "metadata": {
        "id": "5-JgitXCWAEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layers_for_all_kernel_sizes = []\n",
        "for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "    conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
        "    conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "    conv_layers_for_all_kernel_sizes.append(conv_layer)"
      ],
      "metadata": {
        "id": "pIlpLN0GWCOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)"
      ],
      "metadata": {
        "id": "u1Nv8GblWHoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = keras.layers.Dropout(rate=dropout_rate)(h)"
      ],
      "metadata": {
        "id": "28nx55AtWJCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dense_layer_dim in dense_layer_dims:  \n",
        "    h = keras.layers.Dense(dense_layer_dim, activation='relu')(h)"
      ],
      "metadata": {
        "id": "tbUQSErWWLbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_prediction = keras.layers.Dense(1, activation='sigmoid')(h)"
      ],
      "metadata": {
        "id": "D_RnD91QWMeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = keras.Model(inputs=cnn_input_layer, outputs=cnn_prediction)\n",
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # From information theory notebooks.\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Wnq2VzMtWRv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOuRrsY_WUqs",
        "outputId": "170530f7-6f51-4e9a-e5c5-5dabd868a6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 5, 300)       13194600    ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 4, 3)         1803        ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 2, 2)         2402        ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 1, 1)         1501        ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_7 (Global  (None, 3)           0           ['conv1d_7[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " global_max_pooling1d_8 (Global  (None, 2)           0           ['conv1d_8[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " global_max_pooling1d_9 (Global  (None, 1)           0           ['conv1d_9[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 6)            0           ['global_max_pooling1d_7[0][0]', \n",
            "                                                                  'global_max_pooling1d_8[0][0]', \n",
            "                                                                  'global_max_pooling1d_9[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_152 (Dropout)          (None, 6)            0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 100)          700         ['dropout_152[0][0]']            \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 30)           3030        ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            31          ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,204,067\n",
            "Trainable params: 9,467\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_history = cnn_model.fit(train_input,\n",
        "             np.array(train_input_labels),\n",
        "             validation_data=(test_input, np.array(test_input_labels)),\n",
        "             batch_size=32,\n",
        "             epochs=5\n",
        "             )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpYEf_jcWX5h",
        "outputId": "97ca524e-9876-4441-9bdd-d07107f40399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "144/144 [==============================] - 2s 7ms/step - loss: 0.4915 - accuracy: 0.7768 - val_loss: 0.4079 - val_accuracy: 0.7724\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.3671 - accuracy: 0.8182 - val_loss: 0.3209 - val_accuracy: 0.8692\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.3177 - accuracy: 0.8656 - val_loss: 0.3052 - val_accuracy: 0.8997\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.2858 - accuracy: 0.8808 - val_loss: 0.2876 - val_accuracy: 0.8893\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.2729 - accuracy: 0.8866 - val_loss: 0.2763 - val_accuracy: 0.8936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "Ms5WvFFmxfVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_pred = cnn_model.predict(train_input)"
      ],
      "metadata": {
        "id": "7CaQHMQ0njBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = cnn_model.predict(test_input)"
      ],
      "metadata": {
        "id": "OdKTBCbhx_Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_input_labels), np.round(dev_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "VaVtHFQfmEWM",
        "outputId": "0055d717-20a7-4b35-8e4d-d5bf1b7a30c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + CNN, train data', np.array(train_input_labels), np.round(dev_pred,0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOF95pmvmJZD",
        "outputId": "a3ba2bec-1cb2-46a5-d8cd-69cb9d0d67bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + CNN, train data: accuracy = 0.9316, precision = 0.8450, recall = 0.8442, f1 = 0.8446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO can't analyze because some texts were discarded during conversion to ids\n",
        "\n",
        "train_y = train_input_labels\n",
        "train_y_predict = np.round(dev_pred,0)"
      ],
      "metadata": {
        "id": "xt42pkNS_093"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "-omYmQGZxieV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_input_labels), np.round(test_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "7LD-s2MtyKjA",
        "outputId": "5e95db14-de8f-437f-8cb5-9ffb97f9cecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + CNN, test data', np.array(test_input_labels), np.round(test_pred,0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGiiWFj0yRms",
        "outputId": "bf092232-4999-454c-b634-5d5cbc5d8ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + CNN, test data: accuracy = 0.8936, precision = 0.7473, recall = 0.8046, f1 = 0.7749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM"
      ],
      "metadata": {
        "id": "JqfIxHLRPFqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                                embedding_matrix.shape[1],\n",
        "                                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False)"
      ],
      "metadata": {
        "id": "Cy47mRpm5SIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classificaiton_rnn_model(rnn_dim):\n",
        "  \"\"\"\n",
        "  max_length:         maximum input length\n",
        "  rnn_dim:            dimension of the rnn \n",
        "  return_sequences:   should the output vectors get returned?  \n",
        "  return_state:       should the final cell states get returned?\n",
        "  \"\"\"\n",
        "  \n",
        "  rnn_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
        "\n",
        "  rnn_embeddings = rnn_embedding_layer(rnn_input_layer)\n",
        "\n",
        "  # only return the last output from the RNN calculation \n",
        "  rnn_output = tf.keras.layers.LSTM(rnn_dim, return_sequences=False, return_state=False, name='LSTM')\\\n",
        "              (rnn_embeddings)\n",
        "\n",
        "  rnn_hidden = tf.keras.layers.Dense(100, activation='relu', name='rnn_hidden')(rnn_output)\n",
        "\n",
        "\n",
        "  rnn_classification = tf.keras.layers.Dense(1, \n",
        "                                            activation='sigmoid', \n",
        "                                            name='rnn_classification')(rnn_hidden)\n",
        "\n",
        "  # model definition\n",
        "\n",
        "  rnn_model = tf.keras.models.Model(inputs=rnn_input_layer, outputs=[rnn_classification])\n",
        "\n",
        "  rnn_model.compile(loss='binary_crossentropy',\n",
        "                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,\n",
        "                                                  beta_1=0.9,\n",
        "                                                  beta_2=0.999,\n",
        "                                                  epsilon=1e-07,\n",
        "                                                  amsgrad=False,\n",
        "                                                  name='Adam'),\n",
        "                  metrics='accuracy')\n",
        "    \n",
        "  return rnn_model"
      ],
      "metadata": {
        "id": "hK3YxuI8eKTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = build_classificaiton_rnn_model(rnn_dim=3)"
      ],
      "metadata": {
        "id": "OHrHxtyk4cKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_history = rnn_model.fit(train_input,\n",
        "             np.array(train_input_labels),\n",
        "             validation_data=(test_input, np.array(test_input_labels)),\n",
        "             batch_size=32,\n",
        "              epochs=5\n",
        "             )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AUPvbpc6RuU",
        "outputId": "ba15e1fd-9f27-4120-e579-d84b8249cdff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "144/144 [==============================] - 3s 8ms/step - loss: 0.5128 - accuracy: 0.7748 - val_loss: 0.4166 - val_accuracy: 0.7724\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.3345 - accuracy: 0.8595 - val_loss: 0.2933 - val_accuracy: 0.8867\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.2797 - accuracy: 0.8901 - val_loss: 0.2733 - val_accuracy: 0.8849\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.2593 - accuracy: 0.9010 - val_loss: 0.2594 - val_accuracy: 0.8884\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.2454 - accuracy: 0.9060 - val_loss: 0.2546 - val_accuracy: 0.8945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_pred = rnn_model.predict(train_input)\n",
        "test_pred = rnn_model.predict(test_input)"
      ],
      "metadata": {
        "id": "ZwSlWRFUGk0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "2kbcOSmlzXPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_input_labels), np.round(dev_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NGhe9NTTz56f",
        "outputId": "841d96b6-8e30-4b72-9661-b60886615b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + LSTM model, train data: ', np.array(train_input_labels), np.round(dev_pred,0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V86vJljoFz78",
        "outputId": "b3f1bcc3-a157-4cf9-b85f-5215ebbfec6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + LSTM model, train data: : accuracy = 0.9099, precision = 0.8210, recall = 0.7554, f1 = 0.7869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "d9bCMLtwzbdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_input_labels), np.round(test_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "x0AkRHhiz9ac",
        "outputId": "b19c501c-8c93-4ae3-cc07-a0e74b4e111d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + LSTM model, test data: ', np.array(test_input_labels), np.round(test_pred,0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcGDGWK3zgtL",
        "outputId": "33c81134-cc65-4640-f530-4ba7c45d8746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + LSTM model, test data: : accuracy = 0.8945, precision = 0.7893, recall = 0.7318, f1 = 0.7594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT"
      ],
      "metadata": {
        "id": "w1IBwZ6ibHQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: have to split data again after W2V?\n",
        "X, y = data['text'], data['spam']\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)"
      ],
      "metadata": {
        "id": "FbbwrxBeU4m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: remove this?\n",
        "# convert to tensor\n",
        "# y_train = tf.convert_to_tensor(list(train_y))\n",
        "# y_test = tf.convert_to_tensor(list(test_y))"
      ],
      "metadata": {
        "id": "TGrWr5pBUWLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "2c188d57d4e1470bbdf34493318d3fba",
            "0d94a3714f6b42c6a48ad359abde3bdf",
            "1fe3abfb62334ea581a86c8ea8b8dc8d",
            "904934d43d87430a825721cce6cd037c",
            "ec88cdbdad2a4597a5c05182426ee5a7",
            "92f8d6ef4509460ab435fea88665a3c8",
            "22d0791c9e6d4b83be156312fcd078bc",
            "1e975b999a0945c684c487de46d87226",
            "6da2367d50ac426bb0f95a1146783c07",
            "64f261c1408742529f0d2de12757629e",
            "ad1e401c8acd42c1a2766d7406b9e399",
            "230b9d48bf9448ff8cf20e28a9d48f78",
            "d1b12aad94d34c11acdb5e5901e17134",
            "5caf805a9b9c41aeb11283c8d0c41bf0",
            "dc9c807359de428dbd84ae222d9ba016",
            "b23b453bfc604fc7bacbe405ce1d37c3",
            "36292353e51444408e24096c54ac3af2",
            "348f03afc2d94b62a52d2d528e9b7656",
            "6430e36894a447a1944176d0e639c613",
            "d7b7578ca32e4b8698a38756b5e20aea",
            "c854c6c1968f434398681aca1d6f6edb",
            "aff022c326344f7e995067b3554e82e2",
            "e327df3b508d431f81eb7e7b234cde44",
            "31b0322fd32a4f288279b2da14228fc6",
            "c37c003010f147d8937258fad0035d74",
            "d80faa4f0019476e83638f99d153d01f",
            "201e1e111be14e04b85f3b1e0d180bb7",
            "f3462fced66141beb56aea71272afb74",
            "803616b93e9043259adcb0a1e9ba5ec6",
            "44cc0c6edab44248adb0ccd88292839a",
            "69241fa373864aebbdae3810d79e1cb1",
            "1cfb39c639ad40b6b2294d94b92c45be",
            "0532d10f487b4ed181b87d90f7da4e63",
            "613ba2a425d549f99ec75422095ddf44",
            "61dc7840714045d8af6848db9bf2a507",
            "97daf78394014d85a13f11f8b96828da",
            "7bcfafaa7ff84d399a2b612008d707fe",
            "d1482f81be4641cabe33c20bce252235",
            "30718d9461da4a558c7726d96541b077",
            "ed20d26c90b243f1ad02d00259ccb32b",
            "601ecd14def14daf9c4d0c1a6759892d",
            "19cc5a8fb26849d6a5627eb7e20ea1ba",
            "f99422cee4b14302998ebe25d8d4690f",
            "8d809711851e4fbdbb5865511db3dc47"
          ]
        },
        "id": "rXye48IxccJx",
        "outputId": "a1ec623a-cd53-4671-bb9c-973b5f7c81fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c188d57d4e1470bbdf34493318d3fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "230b9d48bf9448ff8cf20e28a9d48f78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e327df3b508d431f81eb7e7b234cde44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "613ba2a425d549f99ec75422095ddf44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 100\n",
        "#max_length = 160                  # set max_length\n",
        "\n",
        "\n",
        "all_train_examples = list(train_X)\n",
        "all_test_examples = list(test_X)\n",
        "\n",
        "\n",
        "x_train = bert_tokenizer(all_train_examples, \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train = tf.convert_to_tensor(list(train_y))\n",
        "\n",
        "x_test = bert_tokenizer(all_test_examples, \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test = tf.convert_to_tensor(list(test_y))"
      ],
      "metadata": {
        "id": "Tz3kbAVobIh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bert_pooled_model(train_layers=-1,\n",
        "                          hidden_size = 100, \n",
        "                          dropout=0.3,\n",
        "                          learning_rate=0.00005):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the Pooled Ouutput for classification purposes\n",
        "    \"\"\"\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # TO-DO: play around with restricting and not restricting BERT layers\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "\n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') #--SOLUTION--\n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    ##bert_inputs = {'input_ids': input_ids,\n",
        "    #              'token_type_ids': token_type_ids,\n",
        "    #              'attention_mask': attention_mask\n",
        "    #               }\n",
        "\n",
        "    #bert_out = bert_model([input_ids, token_type_ids, attention_mask])\n",
        "\n",
        "    \n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                   'token_type_ids': token_type_ids,\n",
        "                   'attention_mask': attention_mask}         \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    pooled_token = bert_out[1]\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(pooled_token)\n",
        "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
        "\n",
        "    \n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy') \n",
        "\n",
        "\n",
        "    \n",
        "    return classification_model"
      ],
      "metadata": {
        "id": "P38CSU4MdCuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model = create_bert_pooled_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-EjxbRtdbjc",
        "outputId": "56af2546-26d6-4ce4-a4c4-9e28a7e3ba63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 100, 768), dtype=tf.float32, name=None), name='tf_bert_model_2/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model_history = pooled_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=1)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2H4_W9TddnM",
        "outputId": "4e5e956d-c00a-4489-b89a-a0e44a10c1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "611/611 [==============================] - 148s 203ms/step - loss: 0.0862 - accuracy: 0.9734 - val_loss: 0.0653 - val_accuracy: 0.9763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3K2UBrszEDyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "SQvNSj_Ihzt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "tITeF3S-mNhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "ZuDpR0Db0q3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "t7sl94GmpB44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9cfb96dc-7e0f-4a2b-ac00-a42c52cfa00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1fa42a2150>"
            ]
          },
          "metadata": {},
          "execution_count": 166
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + FCN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "id": "6DPLZ7TMq5Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e155cf-c27f-4f09-d58b-ed78849402ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + FCN, train data: : accuracy = 0.9875, precision = 0.9535, recall = 0.9882, f1 = 0.9705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "GSnDZLuR0uec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "fkVzGDvO0w_X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1c9bbfe0-37f5-4917-8516-0288d99b7a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1fa4287310>"
            ]
          },
          "metadata": {},
          "execution_count": 168
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAS4UlEQVR4nO3de5Re873H8fc3JkFCLlSEJCQISq1ScWmjp4rjXtGjSqsVbWpKyXFJXaptLJZzjktLsbRNKiq0kqpLE4dyKmhxiEtZbnEZt2SmcW0ubjnMPL/zx2wxSGaekcn88uy8X9Ze8+zLs5/fZGV98vXdv2fvSCkhSep+PXIPQJJWVQawJGViAEtSJgawJGViAEtSJnUr+gPee+05p1noY9YesmvuIWgltHjxnFjec3Qmc3p+apPl/rzlYQUsSZms8ApYkrpVpSX3CKpmAEsql5bm3COomgEsqVRSquQeQtUMYEnlUjGAJSkPK2BJysSLcJKUiRWwJOWRnAUhSZl4EU6SMrEFIUmZeBFOkjKxApakTLwIJ0mZeBFOkvJIyR6wJOVhD1iSMrEFIUmZWAFLUiYt7+UeQdUMYEnlYgtCkjKxBSFJmVgBS1ImBrAk5ZG8CCdJmdgDlqRMbEFIUiY1VAH3yD0ASepSlUr1Swci4oSIeDwiHouIqRGxRkQMj4hZEdEQEX+IiF7FsasX6w3F/mEdnd8AllQuqVL90o6IGAz8OzAypfQZYDXgUOAc4IKU0mbAfGBs8ZaxwPxi+wXFce0ygCWVS3Nz9UvH6oA1I6IO6A3MA3YDrin2TwEOLF6PLtYp9u8eEdHeyQ1gSeXSiQo4Iuoj4oE2S/2S06TUBPwMmENr8C4EHgQWpJTeT+9GYHDxejAwt3hvc3H8uu0N1YtwksqlE7MgUkqTgElL2xcRA2itaocDC4A/Ant3wQiXsAKWVC5d1AMG9gCeTym9mlJ6D7gOGAX0L1oSAEOApuJ1EzAUoNjfD3i9vQ8wgCWVS9fNgpgD7BwRvYte7u7AE8DtwNeKY8YA04vXM4p1iv23pZRSex9gC0JSuXTRPOCU0qyIuAb4O9AMPERru+JGYFpEnFVsm1y8ZTJwZUQ0AP+kdcZEuwxgSeVS3eyGqqSUTgdO/8jm54Adl3LsYuDgzpzfAJZULu3/X/9KxQCWVC7eC0KSMjGAJSmTGroZjwEsqVxaWnKPoGoGsKRysQUhSZkYwJKUiT1gScojVZwHLEl52IKQpEycBSFJmVgBS1ImBvCq6cqr/8S1M24mpcTXDtibbx/yVS6edAW33XUPPaIH6wzox3/8eDwD12t9Ssl9f3+Ecy6cSHNzMwP69+XyS87L/BtoRRsyZAMmT76AgQPXI6XE5MlXcckll3H66ePZf/89qVQqvPrq6xx55HjmzXs593BrUw3djCc6uF/wcnvvtedq509jOTzz3AucNOFspl76C3rW9eSo8T9hwknjWGdAP9bq0weA3/1xOs8+P4fTTx7Hojfe5FtHncjEn5/FBoMG8vr8Baw7oH/m36L7rD1k19xDyGLQoIEMGjSQhx9+jLXW6sM999zIwQcfSVPTPN54400AfvCD7/DpT49g3LjTMo+2+y1ePKfdh1hW4+3zj6w6c3qf+Jvl/rzl4RMxushzL8xlm623YM011qCubjVGbrsNt/717iXhC/DOO4t5/xmpN/3lDvb40ig2GDQQYJUK31XZSy+9wsMPPwbAm2++xZNPNjB48KAl4QvQp09vVnRhVGqVVP2SWYctiIjYktYH073/5M8mYEZKafaKHFit2WyTjblo0hQWLFzE6qv34s577mfrLUcAcOHEy5lx80zW7tOHyy4+G4AX5jTS3NLCEceezNtvv8NhB49m9D575PwV1M023ngI2267Nffd9xAAZ5xxEocddhALF77BXnsdknl0NayGZkG0WwFHxCnANCCA+4olgKkRcWo771vyqOdLr5jaleNdaW06bCO+e9jB1J/wY4468adsMWITevRo/eM97vtHMPP6K9lvzy9z1bU3ANDSUuGJJ5/hl+edycTzz2Li5VN5YU5jzl9B3ahPn95MnTqRH/7wjCXV7+mnn8dmm+3MtGl/4uijj8g7wBqWKpWql9w6akGMBXZIKZ2dUvpdsZxN6+M4xi7rTSmlSSmlkSmlkd87/BtdOd6V2kFf2YurL7uYKb88j75rr82wjYZ8aP/+e36ZW++4G4D1B36KL+y0Pb3XXIMB/fux/baf4amG53MMW92srq6OadMmMm3a9UyffvPH9k+bdj0HHrhPhpGVRA21IDoK4Aqw4VK2b1DsUxuvz18AwLyXXmHmX+9m33/dlRfnNi3Zf9ud9zB849ZQ/vIXd+ahRx6nubmFdxYv5tHHn2KTYUOzjFvda+LE83jyyQYuuujSJds23XTYktf7778nTz31bIaRlUTXPZZ+heuoB3w8MDMingHmFts2AjYDjl2RA6tFJ5x2FgsWLaKuro4fj/8Bfddeiwn/9QtemNNI9Ag2HDSQCSeNA1pbFqN2Gsm/jTmaHtGDg76yFyM2GZb3F9AK94Uv7MBhhx3Eo4/OZtasPwMwYcK5HHHEIWy++aZUKhXmzGli3LgfZR5pDVsJKttqdTgNLSJ60NpyaHsR7v6UUlWd7lVlGpo6Z1Wdhqb2dcU0tLcmHFp15vQ5c1rWaWgdzoJIKVWAe7thLJK0/FaC1kK1/CacpHKpoRaEASypVFaG6WXVMoAllYsVsCRlYgBLUiY19FVkA1hSqfhMOEnKxQCWpEycBSFJmVgBS1ImBrAk5ZFabEFIUh5WwJKUh9PQJCkXA1iSMqmdFrCPpZdULqm5UvXSkYjoHxHXRMSTETE7Ij4fEetExF8i4pni54Di2IiIiyKiISIeiYjPdXR+A1hSuVQ6sXTsQuDmlNKWwGeB2cCpwMyU0ghgZrEOsA8woljqgV91dHIDWFKppEqqemlPRPQD/gWYDJBSejeltAAYDUwpDpsCHFi8Hg1ckVrdC/SPiA3a+wwDWFK5dKICjoj6iHigzVLf5kzDgVeB30bEQxFxaUT0AdZPKc0rjnkJWL94PZgPHl4M0MgHz9JcKi/CSSqVzkxDSylNAiYtY3cd8DlgXEppVkRcyAfthvffnyLiE0+7sAKWVC5d1wNuBBpTSrOK9WtoDeSX328tFD9fKfY3AUPbvH9IsW2ZDGBJpZKaq1/aPU9KLwFzI2KLYtPuwBPADGBMsW0MML14PQM4vJgNsTOwsE2rYqlsQUgqlS5+Kv044PcR0Qt4DvgOrYXr1RExFngR+Hpx7E3AvkAD8HZxbLsMYEnl0oUBnFJ6GBi5lF27L+XYBBzTmfMbwJJKpYsr4BXKAJZUKgawJGWSWiL3EKpmAEsqFStgScokVayAJSkLK2BJyiQlK2BJysIKWJIyqTgLQpLy8CKcJGViAEtSJql2HopsAEsqFytgScrEaWiSlEmLsyAkKQ8rYEnKxB6wJGXiLAhJysQKWJIyaanUzsPeDWBJpWILQpIyqTgLQpLycBqaJGViC6KNNTf84or+CNWg+g1H5R6CSsoWhCRl4iwIScqkhjoQBrCkcrEFIUmZOAtCkjKpoYciG8CSyiVhBSxJWTTbgpCkPKyAJSkTe8CSlIkVsCRlYgUsSZm0WAFLUh419EQiaueuFZJUhQpR9VKNiFgtIh6KiP8u1odHxKyIaIiIP0REr2L76sV6Q7F/WEfnNoAllUrqxFKl44DZbdbPAS5IKW0GzAfGFtvHAvOL7RcUx7XLAJZUKpVOLB2JiCHAfsClxXoAuwHXFIdMAQ4sXo8u1in2714cv0wGsKRSqURUvUREfUQ80Gap/8jpfgGczAd5vS6wIKXUXKw3AoOL14OBuQDF/oXF8cvkRThJpdLSiWNTSpOASUvbFxH7A6+klB6MiF27YmwfZQBLKpUunAUxCjggIvYF1gD6AhcC/SOirqhyhwBNxfFNwFCgMSLqgH7A6+19gC0ISaXSVbMgUko/SikNSSkNAw4FbkspHQbcDnytOGwMML14PaNYp9h/W0rtPyLUAJZUKitgFsRHnQKcGBENtPZ4JxfbJwPrFttPBE7t6ES2ICSVyor4IkZK6Q7gjuL1c8COSzlmMXBwZ85rAEsqFe8FIUmZtNTQV5ENYEmlYgUsSZkYwJKUSQ09Es4AllQuVsCSlElnvoqcmwEsqVRq6YbsBrCkUrEFIUmZGMCSlMly3OOh2xnAkkrFHrAkZeIsCEnKpFJDTQgDWFKpeBFOkjKpnfrXAJZUMlbAkpRJc9RODWwASyqV2olfA1hSydiCkKRMnIYmSZnUTvwawJJKxhaEJGXSUkM1sAEsqVSsgCUpk2QFLEl5WAHrY/r168ukiT9j6623IKXEkUeO595ZD+YellawARusy5jzj2HtT/UnpcTdU2/l9t/+mf2OP5hRh+7OG/9cBMCMc6fy+B0PscPoXdjj+wcsef/gLTfi7P1PofGJF3P9CjXHaWj6mAvOP5NbbrmdQw6tp2fPnvTuvWbuIakbtDS3cO1ZVzL38edZvc8anHrD2cy+8xEAbpt8I7f+5oYPHX//9Lu4f/pdAGy4xVC+P+kkw7eTaid+DeBu0bfv2nxxl5347tjjAXjvvfdYuPC9zKNSd1j06gIWvboAgP97azEvPdtE/0HrVPXekQfswoM3/O+KHF4pNddQBPfIPYBVwfDhG/Haa68z+dILuP++W5j46/OsgFdB6wxZj6FbDeeFhxsA+NKYvfjxn8/jW+cezZp9+3zs+O33/zz3z7i7u4dZ81In/svtEwdwRHynnX31EfFARDxQqbz1ST+iNOpWW43tttuGiROvYIcd9+Ktt97mlJOPzT0sdaPVe69O/a/Gc82Zl7P4zXf42+/+hwn/Mo7/3PdkFr0yn4N+cviHjh+27Wa8+867zHt6bqYR165KJ5bclqcCPmNZO1JKk1JKI1NKI3v0+Pi/7KuaxqZ5NDbO4777HwLguutuZLttt8k8KnWXHnWrceSvx3Pfn+7k4VvuA+CN1xaSKomUEndNm8mwz276ofds/5VRPGD1+4nUUgXcbg84Ih5Z1i5g/a4fTjm9/PKrNDb+g80335Snn36W3Xbbhdmzn849LHWTb59zFC81NHHb5BuXbOu7Xv8lveFt99qRf7SpdCOC7ff7PD8/eEK3j7UMVobKtlodXYRbH9gLmP+R7QF4daATjjvhp1wx5WJ69erJ88/PYez3Tsw9JHWDTUduwU4HfYmm2S/yo5vOBVqnnI08YBRDthoGKfF646tcddqkJe/ZbKdPM3/ea7w+95VMo65tLSl/ZVutSO0MNiImA79NKd21lH1XpZS+2dEH1PUaXDt/Guo29RuOyj0ErYR++cLVsbzn+ObGX606c6568frl/rzl0W4FnFIa286+DsNXkrrbytDbrZbT0CSVSlfNgoiIoRFxe0Q8ERGPR8RxxfZ1IuIvEfFM8XNAsT0i4qKIaIiIRyLicx2N1QCWVCoVUtVLB5qB8SmlrYCdgWMiYivgVGBmSmkEMLNYB9gHGFEs9cCvOvoAA1hSqXTVNLSU0ryU0t+L128As4HBwGhgSnHYFODA4vVo4IrU6l6gf0Rs0N5nGMCSSqUlpaqXtl8aK5b6pZ0zIoYB2wGzgPVTSvOKXS/xwZTcwUDbb840FtuWyXtBSCqVztwNLaU0CZjU3jERsRZwLXB8SmlRxAcTJ1JKKSI+8VU/K2BJpdKVX0WOiJ60hu/vU0rXFZtffr+1UPx8f8J2EzC0zduHFNuWyQCWVCpd1QOO1lJ3MjA7pXR+m10zgDHF6zHA9DbbDy9mQ+wMLGzTqlgqWxCSSqULb8g+Cvg28GhEPFxsOw04G7g6IsYCLwJfL/bdBOwLNABvA8u8Ydn7DGBJpdLet3s7eZ67aL3twtLsvpTjE3BMZz7DAJZUKj6WXpIy8ZlwkpRJV7UguoMBLKlUrIAlKZNauhuaASypVGrphuwGsKRSsQUhSZkYwJKUibMgJCkTK2BJysRZEJKUSUuq5kaTKwcDWFKp2AOWpEzsAUtSJvaAJSmTii0IScrDCliSMnEWhCRlYgtCkjKxBSFJmVgBS1ImVsCSlElLask9hKoZwJJKxa8iS1ImfhVZkjKxApakTJwFIUmZOAtCkjLxq8iSlIk9YEnKxB6wJGViBSxJmTgPWJIysQKWpEycBSFJmXgRTpIysQUhSZn4TThJysQKWJIyqaUecNTSvxa1LiLqU0qTco9DKxf/Xqy6euQewCqmPvcAtFLy78UqygCWpEwMYEnKxADuXvb5tDT+vVhFeRFOkjKxApakTAxgScrEAO4mEbF3RDwVEQ0RcWru8Si/iLgsIl6JiMdyj0V5GMDdICJWAy4B9gG2Ar4REVvlHZVWApcDe+cehPIxgLvHjkBDSum5lNK7wDRgdOYxKbOU0t+Af+Yeh/IxgLvHYGBum/XGYpukVZgBLEmZGMDdowkY2mZ9SLFN0irMAO4e9wMjImJ4RPQCDgVmZB6TpMwM4G6QUmoGjgVuAWYDV6eUHs87KuUWEVOBe4AtIqIxIsbmHpO6l19FlqRMrIAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKZP/B8zCF9T5XXJ3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "AJTkYBdb0xZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf855d35-8def-4d10-920f-41d0cf98c779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + FCN, test data: : accuracy = 0.9763, precision = 0.9179, recall = 0.9772, f1 = 0.9466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT Analysis"
      ],
      "metadata": {
        "id": "nvR_4nFjOZ8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_predict = train_y_predict.ravel()"
      ],
      "metadata": {
        "id": "r9GIj68vnXge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spam examples\n",
        "data['text'][data[\"spam\"] == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDIZfakXgsOC",
        "outputId": "b7901b31-6643-4074-eb95-da7f91a623e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "5       FreeMsg Hey there darling it's been 3 week's n...\n",
              "8       WINNER!! As a valued network customer you have...\n",
              "9       Had your mobile 11 months or more? U R entitle...\n",
              "11      SIX chances to win CASH! From 100 to 20,000 po...\n",
              "                              ...                        \n",
              "6102    You have passed the official certification onl...\n",
              "6103    Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...\n",
              "6104    Hi, I'm a Shopee Hiring Manager and I'm curren...\n",
              "6105    4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\n",
              "Pinaka mur...\n",
              "6106    Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...\n",
              "Name: text, Length: 1280, dtype: string"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missclassified_text = train_X[train_y != train_y_predict]\n",
        "missclassified_label = train_y[train_y != train_y_predict]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'missclassified_true_label': missclassified_label})\n",
        "\n",
        "#df_report['missclassified_true_label'].value_counts()\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zhz2qnZqJHdX",
        "outputId": "c01a4dd3-6af5-4508-dfc1-20717fe45c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  \\\n",
              "3249         Also track down any lighters you can find\n",
              "   \n",
              "5291  Hey! Congrats 2u2. id luv 2 but ive had 2 go h...   \n",
              "3729  The search 4 happiness is 1 of d main sources ...   \n",
              "5148  Oh unintentionally not bad timing. Great. Fing...   \n",
              "2647  Em, its olowoyey@ usc.edu have a great time in...   \n",
              "...                                                 ...   \n",
              "5046  We have sent JD for Customer Service cum Accou...   \n",
              "1235  \"Hello-/@drivby-:0quit edrunk sorry iff pthis ...   \n",
              "3539  We are pleased to inform that your application...   \n",
              "2009              See the forwarding message for proof\n",
              "   \n",
              "1246  Hello which the site to download songs its urg...   \n",
              "\n",
              "      missclassified_true_label  \n",
              "3249                          0  \n",
              "5291                          0  \n",
              "3729                          0  \n",
              "5148                          0  \n",
              "2647                          0  \n",
              "...                         ...  \n",
              "5046                          0  \n",
              "1235                          0  \n",
              "3539                          0  \n",
              "2009                          0  \n",
              "1246                          0  \n",
              "\n",
              "[61 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0fcaeba-86a8-4a2e-a4a4-6221c98bf327\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>missclassified_true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3249</th>\n",
              "      <td>Also track down any lighters you can find</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5291</th>\n",
              "      <td>Hey! Congrats 2u2. id luv 2 but ive had 2 go h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3729</th>\n",
              "      <td>The search 4 happiness is 1 of d main sources ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5148</th>\n",
              "      <td>Oh unintentionally not bad timing. Great. Fing...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2647</th>\n",
              "      <td>Em, its olowoyey@ usc.edu have a great time in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5046</th>\n",
              "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>\"Hello-/@drivby-:0quit edrunk sorry iff pthis ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3539</th>\n",
              "      <td>We are pleased to inform that your application...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009</th>\n",
              "      <td>See the forwarding message for proof</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>Hello which the site to download songs its urg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0fcaeba-86a8-4a2e-a4a4-6221c98bf327')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0fcaeba-86a8-4a2e-a4a4-6221c98bf327 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0fcaeba-86a8-4a2e-a4a4-6221c98bf327');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_X[train_y != train_y_predict].loc[1460]"
      ],
      "metadata": {
        "id": "NS5sFIWen1xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_report.loc[2965]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg1gvY-gKQXr",
        "outputId": "65b1e197-c491-44ef-8cb6-8c54b57ebb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "missclassified_text          Do you ever notice that when you're driving, a...\n",
              "missclassified_true_label                                                    1\n",
              "Name: 2965, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Baseline BERT observations\n",
        "-----------------------------\n",
        "\n",
        "As expected more text messages that were SPAM got classified as HAM because HAM is the majority class in our dataset.\n",
        "\n",
        "I looked at a couple examples of texts that got misclassified as HAM and they're tricky to tell if it's a ham or spam messages. The 2 examples contained generic sayings that even a human could mistakenly classify as spam.\n",
        "\n",
        "\n",
        "*Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur Soul Ur Guide And U Will Never loose in world....gnun - Sent via WAY2SMS.COM*\n",
        "\n",
        "*1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cancer. 1Lemon/Day=No Fat. 1Cup Milk/day=No Bone Problms 3 Litres Watr/Day=No Diseases Snd ths 2 Whom U Care..:-)*\n",
        "\n",
        "\n",
        "In general the misclassified messages are hard to tell for certain that they are ham or spam.\n"
      ],
      "metadata": {
        "id": "8skK76XCHeC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT + CNN"
      ],
      "metadata": {
        "id": "wcXX9CM28l71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bert_cnn_model(train_layers=-1,\n",
        "                          hidden_size = 100, \n",
        "                          learning_rate=0.00005,\n",
        "                          num_filters = [100, 100, 50, 25],\n",
        "                          kernel_sizes = [3, 5, 10, 20],\n",
        "                          dense_layer_dims = 100,\n",
        "                          dropout = 0.3):\n",
        "    \"\"\"\n",
        "    Build a  classification model with BERT, where you apply CNN layers  to the BERT output\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # TO-DO: play around with restricting and not restricting BERT layers\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "    \n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') \n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    # bert_inputs = {'input_ids': input_ids} \n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                'token_type_ids': token_type_ids,\n",
        "                'attention_mask': attention_mask}      \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    pooled_token = bert_out[0][:, 1:-1]\n",
        "\n",
        "    # CNN -----\n",
        "\n",
        "    conv_layers_for_all_kernel_sizes = []\n",
        "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "        conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(pooled_token)\n",
        "        conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "        conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
        "\n",
        "    h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
        "    #h = keras.layers.Dropout(rate=dropout)(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(dense_layer_dims, activation='relu')(h)\n",
        "    h = tf.keras.layers.Dropout(rate=dropout)(h) \n",
        "\n",
        "    # -----\n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(h)\n",
        "\n",
        "    # classification_model = tf.keras.Model(inputs=[input_ids], outputs=[classification])\n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy')\n",
        "\n",
        "\n",
        "    ### END YOUR CODE\n",
        "    \n",
        "    return classification_model"
      ],
      "metadata": {
        "id": "jKXuto0I8pNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model()\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=1)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkQ5v7lI9Ppr",
        "outputId": "dfa16280-a48d-4294-8da2-b5eca02538e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 160s 216ms/step - loss: 0.0771 - accuracy: 0.9769 - val_loss: 0.0931 - val_accuracy: 0.9787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "zw3v5VG0BAjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ORW4C-bR3Z_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "5Gp9o1HI2tC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "IW32_54PCpg1",
        "outputId": "8b072623-9c65-418d-cbca-e0846a193159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1fafbb5210>"
            ]
          },
          "metadata": {},
          "execution_count": 179
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msQ5VDvRCrpQ",
        "outputId": "cce0641a-b163-4f0c-b430-6f8881b36ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9894, precision = 0.9707, recall = 0.9784, f1 = 0.9745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "4OnfDJiJ3khq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "3Yvu9Rsk4Dd-",
        "outputId": "3d66a660-5e5d-4b6f-85ea-1853ad13eaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1fae263890>"
            ]
          },
          "metadata": {},
          "execution_count": 181
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASv0lEQVR4nO3debRXZbnA8e8jR0DtxgzKkGKQLquVFdecrfReh0LsGi6zK6TchXOZVpKmrcibYzl0TQMRgRScKqEsB8ypjCSxHLhdCadzAgEFTA2B83vvH2eLR4NzfkcO5+W3+X5ae7Gn394PLXp61rPfvd9IKSFJ6nhb5Q5AkrZUJmBJysQELEmZmIAlKRMTsCRlUrepb7Bm2UKHWeifbNt/v9whaDO0ZnVDbPQ12pBztu6980bfb2NYAUtSJpu8ApakDlVpzB1B1UzAksqlcW3uCKpmApZUKilVcodQNROwpHKpmIAlKQ8rYEnKxIdwkpSJFbAk5ZEcBSFJmfgQTpIysQUhSZn4EE6SMrEClqRMfAgnSZn4EE6S8kjJHrAk5WEPWJIysQUhSZlYAUtSJo1rckdQNROwpHKxBSFJmdiCkKRMrIAlKRMTsCTlkXwIJ0mZ2AOWpExsQUhSJlbAkpSJFbAkZVJDFfBWuQOQpHa1dm31Sysi4qsR8WREPBER0yOia0QMjog5EbEgIm6KiM7FuV2K7QXF8Z1au74JWFK5pEr1SwsiYgDwZWBYSulDQCfgaOAi4LKU0hBgOTCm+MkYYHmx/7LivBaZgCWVS6VS/dK6OmCbiKgDtgUWAZ8Gbi2OTwGOKNZHFNsUxw+MiGjp4iZgSeXShgo4IsZGxNxmy9h1l0mpAbgUeJ6mxLsS+COwIqX0Zv+iHhhQrA8AXih+u7Y4v1dLofoQTlK5tGEUREppAjBhfcciogdNVe1gYAVwC3BIO0S4jhWwpHJppx4wcBDwTEppaUppDfBTYB+ge9GSABgINBTrDcAggOJ4N+Cllm5gApZULu03CuJ5YM+I2Lbo5R4IPAX8Bvh8cc5o4PZifWaxTXH83pRSaukGtiAklUvLOa8Nl0lzIuJW4FFgLTCPpnbFL4EZEXF+sW9S8ZNJwLSIWAC8TNOIiRaZgCWVSzu+CZdS+jbw7XfsXgjssZ5zVwEj23J9E7CkcvFVZEnKpIZeRTYBSyqXxsbcEVTNBCypXGxBSFImJmBJysQesCTlkSrtMw64I5iAJZWLLQhJysRREJKUiRWwJGVSQwnYr6G1o2k3/5wj/vNERnzxBKbd9LO3Hbt++m18aJ9DWb5iJQD3Pvgwnxt1EkeOPoWjjv8yj/7piRwhq4NNnPB9Gur/xLx5s9+2/5STj+Pxx+/nscfu5YILzskUXUmkVP2SmRVwO3l64bPcNvPXTL/2crau25oTz/wWB+zzCd43sD+LXlzK7/7wKDv067vu/D0/vjuf2ndPIoK/LHiGr537PWZNn5jxb6COMGXqzfzoR5O5bvIV6/YdcMDeDB9+MB//+L+xevVq+vRpcRIFtcYKeMuz8NkX+PAHd2Gbrl2pq+vEsN0/zD33/xaAi6/8MWecPIbms0Ntu+02vDld1D9WrYKWp45SSTz00BxeXr7ibftOOGEUF19yFatXrwZg6dIWv+Gt1lRS9UtmrVbAEbErTdNyvDnvUQMwM6U0f1MGVmuG7LwjV06YwoqVr9ClS2cefPgRPrjrUO598GH69unNrkN3/qff3HP/b7nimut5afkKfnTp+AxRa3PwgaE7s+++e/Dd8d9g1ao3OOus7zL3j3/KHVbtqqFREC1WwBFxFjADCOAPxRLA9IgY18Lv1k10d+3U6e0Z72br/Tu9j+O/OJKxXz2HE884l12G7szqNWuYOPUmTv2vY9f7m4MO2IdZ0ydy5YXn8T8Tp3ZwxNpcdKrrRM8e3dln3+GMG3c+N954Te6QalqqVKpecmutAh4DfLCYD2mdiPgB8CRw4fp+1HyiuzXLFuav8zvIkcMP5sjhBwNw+TXX06tnd+594GGOHH0yAC8uXcbI409jxsTL6d2r57rfDdv9w9T/bTHLV6ykR/duWWJXPg31i/jZz38FwCNzH6NSqdC7d0+WLXs5c2Q1ajNoLVSrtR5wBei/nv07FMfUzEtFb2/R4iXMvv+3jDj0IB745Qzuum0Kd902hX59enPLdT+kd6+ePF//N96cLuqpvyxg9eo1dO/23pzhK5OZM+/kk5/cG4ChQ3emc+fOJt+N0X6Tcm5yrVXApwOzI+JpivnugfcBQ4BTN2VgteirZ5/Pildeoa6ujnPOPJn3/st7Nnju3fc9xMxfzaauro6uXTpz6fhx6x7KqbymTbuKA/bfi969e/LMwrmMH38pk6+fwbUTv8+8ebNZs3oNx485PXeYta2GKuBoZdJOImIrmuY/av4Q7pGUUlWd7i2pBaHqbdt/v9whaDO0ZnXDRlchr513dNU5Z7vxM7JWPa2OgkgpVYDfd0AskrTxNoPWQrV8EUNSudRQC8IELKlUNofhZdUyAUsqFytgScrEBCxJmdTQq8gmYEml4pxwkpSLCViSMnEUhCRlYgUsSZmYgCUpj9RoC0KS8rAClqQ8HIYmSbmYgCUpk9ppAZuAJZVLWls7Gbi1OeEkqbZU2rC0IiK6R8StEfG/ETE/IvaKiJ4RcXdEPF382aM4NyLiyohYEBF/joiPtXZ9E7CkUkmVVPVShSuAX6eUdgU+AswHxgGzU0pDgdnFNsChwNBiGQtc3drFTcCSyqWdKuCI6AbsD0wCSCmtTimtAEYAU4rTpgBHFOsjgKmpye+B7hGxQ0v3MAFLKpW2VMARMTYi5jZbxja71GBgKTA5IuZFxLURsR3QL6W0qDhnMdCvWB/AW7PHA9Tz1mTG6+VDOEnl0oZncCmlCcCEDRyuAz4GnJZSmhMRV/BWu+HN36eIeNfj3qyAJZVKWlv90op6oD6lNKfYvpWmhPzim62F4s8lxfEGYFCz3w8s9m2QCVhSqaRK9UuL10lpMfBCROxS7DoQeAqYCYwu9o0Gbi/WZwKjitEQewIrm7Uq1ssWhKRyad9hwKcBN0REZ2AhcBxNhevNETEGeA44qjj3DuAwYAHwenFui0zAkkqltcq2TddK6TFg2HoOHbiecxNwSluubwKWVCrtmYA3NROwpFJJjZE7hKqZgCWVihWwJGWSKlbAkpSFFbAkZZKSFbAkZWEFLEmZVBwFIUl5+BBOkjIxAUtSJql2JkU2AUsqFytgScrEYWiSlEmjoyAkKQ8rYEnKxB6wJGXiKAhJysQKWJIyaazUzlzDJmBJpWILQpIyqTgKQpLycBiaJGViC6KZbfrvt6lvoRp0XP+9c4egkrIFIUmZOApCkjKpoQ6ECVhSudiCkKRMHAUhSZnU0KTIJmBJ5ZKwApakLNbagpCkPKyAJSkTe8CSlIkVsCRlYgUsSZk0WgFLUh41NCORCVhSuVRqqAKunc8GSVIVUhuWakREp4iYFxG/KLYHR8SciFgQETdFROdif5die0FxfKfWrm0CllQqlTYsVfoKML/Z9kXAZSmlIcByYEyxfwywvNh/WXFei0zAkkqlElH10pqIGAh8Bri22A7g08CtxSlTgCOK9RHFNsXxA4vzN8gELKlUGtuwRMTYiJjbbBn7jstdDnyDtwrmXsCKlNLaYrseGFCsDwBeACiOryzO3yAfwkkqlbaMgkgpTQAmrO9YRHwWWJJS+mNEfLJdgnsHE7CkUmnHURD7AIdHxGFAV+C9wBVA94ioK6rcgUBDcX4DMAioj4g6oBvwUks3sAUhqVTaaxRESumbKaWBKaWdgKOBe1NKXwR+A3y+OG00cHuxPrPYpjh+b0otz9FsApZUKpWofnmXzgLOiIgFNPV4JxX7JwG9iv1nAONau5AtCEmlsim+BZFSug+4r1hfCOyxnnNWASPbcl0TsKRSaaydF+FMwJLKxa+hSVImJmBJyqSGpoQzAUsqFytgScqkMXcAbWACllQqfpBdkjKxBSFJmZiAJSmTame62ByYgCWVij1gScrEURCSlEmlhpoQJmBJpeJDOEnKpHbqXxOwpJKxApakTNZG7dTAJmBJpVI76dcELKlkbEFIUiYOQ5OkTGon/ZqAJZWMLQhJyqSxhmpgE7CkUrEClqRMkhWwJOVhBSwmTvg+nznsIJYsXcbuHz0QgB49ujP9hqvZccdBPPfcCxx9zImsWLEyc6TalHrs0Ivjf3Aq7+3dHVLigen3MHvyHQw/fST7HX0Qr778CgA/vfhGnrhvHjt9ZAijLjih6ccBsy6/hXl3/iHj36D21NIwtEhp0wZb13lA7fy30Y722/cTvPrqa0yefMW6BHzhBefw8ssruPiSq/jG10+hR49ufPPs72WONI/j+u+dO4QO0a1Pd7r17cHzTz5Dl+26cu6si7hq7CUM++xevPHaKu6aOOtt53fu2pm1a9ZSaazQrU93zvvVpXz9E2OpNNZSXffuTXz2lo3+nPpJOx1Vdc65+tmbs36+faucNy+zBx+aw8vLV7xt3/DhBzN12i0ATJ12C4cffkiO0NSBVi5dwfNPPgPAG6+tYtFfG+i+fc8Nnr961ep1yXbrLp1hExdIZbSWVPWSmy2IDtSvb28WL14CwOLFS+jXt3fmiNSReg3sw6DdBvPMY08zZNgufGr0Iez1Hwfw7ON/5Zbzp/L6K68BMHj3IXzp4pPpOaAP153xwy2m+m0vtfQQ7l1XwBFxXAvHxkbE3IiYW6m89m5vUXqbuv2jzUeXbbty0tVf46bxk1n16j+47yd3cfb+pzH+sK+zcskKRn5r1Lpzn3lsAd/+9zP478PHcehJn6Ouy9YZI689lTYsuW1MC+I7GzqQUpqQUhqWUhq21VbbbcQtyuXFJcvYfvu+AGy/fV+WLH0pc0TqCJ3qOnHSNWcy5+cPrnug9vdlK0mVCiklHpxxD4M/MuSffrf4rw288foqBnxgUEeHXNNSG/6TW4sJOCL+vIHlcaBfB8VYGr+YdRejjh0JwKhjRzJr1p2ZI1JHGH3RSSxa0MDdk36xbl+3Pt3XrX/04D1o+L8XAOg9sC9bdWr6n2XPAb3Z/v39eal+accGXONqqQJurQfcDzgYWP6O/QH8bpNEVBI/mXYVB+y/F7179+TZhXP5zvhLueiSq5hx4zUc96Uv8Pzz9Rx9zIm5w9QmNmTYrux15AHUz3+O8+64BGgacrbH4fsyaLedICWW1S/lJ2f/uOn8f92VQ086gsa1jVQqFW4491peXf73jH+D2tNYQ629FoehRcQkYHJK6aH1HLsxpXRMazfYUoehqWVbyjA0tU17DEM7ZsfPVZ1zbnzuZ1mHobVYAaeUxrRwrNXkK0kdbXPo7VbLYWiSSmVz6O1WyxcxJJVKhVT10pKIGBQRv4mIpyLiyYj4SrG/Z0TcHRFPF3/2KPZHRFwZEQuKwQofay1WE7CkUmnHYWhrgTNTSrsBewKnRMRuwDhgdkppKDC72AY4FBhaLGOBq1u7gQlYUqk0plT10pKU0qKU0qPF+t+B+cAAYAQwpThtCnBEsT4CmJqa/B7oHhE7tHQPe8CSSmVTfA0tInYCPgrMAfqllBYVhxbz1jsRA4AXmv2svti3iA2wApZUKm15EaP5ZxOKZew7rxcR7wFuA05PKb3S/FhqGsf7rjO+FbCkUmnLMLSU0gRgwoaOR8TWNCXfG1JKPy12vxgRO6SUFhUthiXF/gag+XvjA4t9G2QFLKlU2nEURACTgPkppR80OzQTGF2sjwZub7Z/VDEaYk9gZbNWxXpZAUsqlXb8yuA+wLHA4xHxWLHvbOBC4OaIGAM8BxxVHLsDOAxYALwObPCLkW8yAUsqlfaalr74BMOGXlU+cD3nJ+CUttzDBCypVGppTjgTsKRSqaWJDkzAkkrFCliSMvFraJKUSS19kN0ELKlUbEFIUiYmYEnKxFEQkpSJFbAkZeIoCEnKpDHVzqxwJmBJpWIPWJIysQcsSZnYA5akTCq2ICQpDytgScrEURCSlIktCEnKxBaEJGViBSxJmVgBS1ImjakxdwhVMwFLKhVfRZakTHwVWZIysQKWpEwcBSFJmTgKQpIy8VVkScrEHrAkZWIPWJIysQKWpEwcByxJmVgBS1ImjoKQpEx8CCdJmdiCkKRMfBNOkjKxApakTGqpBxy19P8WtS4ixqaUJuSOQ5sX/11subbKHcAWZmzuALRZ8t/FFsoELEmZmIAlKRMTcMeyz6f18d/FFsqHcJKUiRWwJGViApakTEzAHSQiDomIv0TEgogYlzse5RcR10XEkoh4IncsysME3AEiohNwFXAosBvwhYjYLW9U2gxcDxySOwjlYwLuGHsAC1JKC1NKq4EZwIjMMSmzlNIDwMu541A+JuCOMQB4odl2fbFP0hbMBCxJmZiAO0YDMKjZ9sBin6QtmAm4YzwCDI2IwRHRGTgamJk5JkmZmYA7QEppLXAqcCcwH7g5pfRk3qiUW0RMBx4GdomI+ogYkzsmdSxfRZakTKyAJSkTE7AkZWIClqRMTMCSlIkJWJIyMQFLUiYmYEnK5P8BOhcYbCkPN4oAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lQNG1Oz3o7M",
        "outputId": "a4080b6c-1da3-48f9-b5ee-85d104347ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, test data: : accuracy = 0.9787, precision = 0.9405, recall = 0.9620, f1 = 0.9511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train\n",
        "\n",
        "  - Word2Vec embeddings\n",
        "    - CNN  |  accuracy = 0.9336, precision = 0.8344, recall = 0.8700, f1 = 0.8519\n",
        "    - LSTM  |  accuracy = 0.9172, precision = 0.8217, recall = 0.7956, f1 = 0.8085\n",
        "\n",
        "  - BERT with\n",
        "    - Fully connected network  |  accuracy = 0.9873, precision = 0.9827, recall = 0.9555, f1 = 0.9689\n",
        "    - CNN  |  accuracy = 0.9865, precision = 1.0000, recall = 0.9348, f1 = 0.9663\n",
        "\n",
        "- Test\n",
        "\n",
        "  - Word2Vec embeddings\n",
        "    - W2V + CNN, test data: : accuracy = 0.8949, precision = 0.7567, recall = 0.7773, f1 = 0.7669\n",
        "    - W2V + LSTM model, test data: : accuracy = 0.8897, precision = 0.7452, recall = 0.7656, f1 = 0.7553\n",
        "\n",
        "  - BERT with\n",
        "    - BERT + FCN, test data: : accuracy = 0.9885, precision = 0.9841, recall = 0.9611, f1 = 0.9724\n",
        "    - BERT + CNN, test data: : accuracy = 0.9828, precision = 0.9958, recall = 0.9222, f1 = 0.9576\n"
      ],
      "metadata": {
        "id": "1feUh1bIDy5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuned models"
      ],
      "metadata": {
        "id": "NlfXqmUi8a3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT tuning"
      ],
      "metadata": {
        "id": "scIsHg775HLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1:** Increase the number of epochs because the training kept on improving in the first epoch and we may want to have a couple passes through the model in order to find the most optimal weights for this classification task. Also tune if freezing or unfreezing BERT layers will improve performance. I assume that unfreezing the layers may introduce too many parameters and the model will overfit. But we're expecting the number of epochs to increase performance."
      ],
      "metadata": {
        "id": "TBGWQOpC56YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model = create_bert_pooled_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSut37Sb5ZXj",
        "outputId": "5d979929-95ba-4490-d4ca-859155faa1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model_history = pooled_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=3)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5xRcuyI5xJY",
        "outputId": "46f570f0-3941-422a-bc62-c8e3105be61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "611/611 [==============================] - 141s 204ms/step - loss: 0.0900 - accuracy: 0.9722 - val_loss: 0.0849 - val_accuracy: 0.9779\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 122s 199ms/step - loss: 0.0545 - accuracy: 0.9865 - val_loss: 0.0702 - val_accuracy: 0.9820\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 122s 199ms/step - loss: 0.0596 - accuracy: 0.9842 - val_loss: 0.0739 - val_accuracy: 0.9869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "i1Zhlh2l8PWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "SmBMa6qr8VSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_fwXVGMy8hgd",
        "outputId": "52a34250-6ffe-42bb-8085-ca97aff06a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1e2e8ea250>"
            ]
          },
          "metadata": {},
          "execution_count": 187
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ujsahj568sx0",
        "outputId": "457151ce-2f75-4792-bef1-e311f3a36df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1e2e8fa310>"
            ]
          },
          "metadata": {},
          "execution_count": 188
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "print_metrics('BERT 3e + FCN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MZXVo-w82-X",
        "outputId": "3dce3364-7bdc-40a1-9822-4b76a5aebac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, train data: : accuracy = 0.9953, precision = 0.9892, recall = 0.9882, f1 = 0.9887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "print_metrics('BERT 3e + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe85CHhs86_7",
        "outputId": "3cc12543-3038-4f1a-fb5a-15b8e178078a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, test data: : accuracy = 0.9869, precision = 0.9625, recall = 0.9772, f1 = 0.9698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "missclassified_text = train_X[train_y != train_y_predict.reshape(-1)]\n",
        "missclassified_label = train_y[train_y != train_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "dOsSKjxl_-Hs",
        "outputId": "7031e80a-2d2a-42d1-f5f5-964e83f25430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "2783  Well at this right I'm gonna have to get up an...           0\n",
              "1290  Hey...Great deal...Farm tour 9am to 5pm $95/pa...           0\n",
              "5767     Stay a while 'cause somethings always cooking.           1\n",
              "4249  accordingly. I repeat, just text the word ok o...           1\n",
              "1766  Hi this is yijue... It's regarding the 3230 te...           0\n",
              "2965  Do you ever notice that when you're driving, a...           1\n",
              "5768          Come on in, feel free to do some looking.           1\n",
              "5771  My Grandfather smoked his whole life. I was ab...           1\n",
              "68    Did you hear about the new \"Divorce Barbie\"? I...           1\n",
              "136             I only haf msn. It's yijue@hotmail.com\n",
              "           0\n",
              "5769  Excuse me? I find vaping to be one of the best...           1\n",
              "1724  Hi Jon, Pete here, Ive bin 2 Spain recently & ...           0\n",
              "5773               Budget for all your needs, type yes            1\n",
              "4252  Omg Joanna is freaking me out. She's looked th...           0\n",
              "5226  \"OH FUCK. JUSWOKE UP IN A BED ON A BOATIN THE ...           0\n",
              "955          Filthy stories and GIRLS waiting for your\n",
              "           1\n",
              "1875  Would you like to see my XXX pics they are so ...           1\n",
              "751   Do you realize that in about 40 years, we'll h...           1\n",
              "2379  Hi, Mobile no.  &lt;#&gt;  has added you in th...           0\n",
              "5046  We have sent JD for Customer Service cum Accou...           0\n",
              "5451  Latest News! Police station toilet stolen, cop...           1\n",
              "1235  \"Hello-/@drivby-:0quit edrunk sorry iff pthis ...           0\n",
              "3539  We are pleased to inform that your application...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c1e684a-0747-4f7a-b9a5-6f711705de38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2783</th>\n",
              "      <td>Well at this right I'm gonna have to get up an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>Hey...Great deal...Farm tour 9am to 5pm $95/pa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5767</th>\n",
              "      <td>Stay a while 'cause somethings always cooking.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4249</th>\n",
              "      <td>accordingly. I repeat, just text the word ok o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1766</th>\n",
              "      <td>Hi this is yijue... It's regarding the 3230 te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>Do you ever notice that when you're driving, a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5768</th>\n",
              "      <td>Come on in, feel free to do some looking.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5771</th>\n",
              "      <td>My Grandfather smoked his whole life. I was ab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Did you hear about the new \"Divorce Barbie\"? I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>I only haf msn. It's yijue@hotmail.com</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5769</th>\n",
              "      <td>Excuse me? I find vaping to be one of the best...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724</th>\n",
              "      <td>Hi Jon, Pete here, Ive bin 2 Spain recently &amp; ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5773</th>\n",
              "      <td>Budget for all your needs, type yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4252</th>\n",
              "      <td>Omg Joanna is freaking me out. She's looked th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5226</th>\n",
              "      <td>\"OH FUCK. JUSWOKE UP IN A BED ON A BOATIN THE ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>Filthy stories and GIRLS waiting for your</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1875</th>\n",
              "      <td>Would you like to see my XXX pics they are so ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>Do you realize that in about 40 years, we'll h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>Hi, Mobile no.  &amp;lt;#&amp;gt;  has added you in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5046</th>\n",
              "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5451</th>\n",
              "      <td>Latest News! Police station toilet stolen, cop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>\"Hello-/@drivby-:0quit edrunk sorry iff pthis ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3539</th>\n",
              "      <td>We are pleased to inform that your application...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c1e684a-0747-4f7a-b9a5-6f711705de38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c1e684a-0747-4f7a-b9a5-6f711705de38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c1e684a-0747-4f7a-b9a5-6f711705de38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "Cw3hwJzD-GIl",
        "outputId": "4a8fe95d-2d34-4629-f194-9062437c904b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "5738  Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst & eà...           1\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "1260  We have sent JD for Customer Service cum Accou...           0\n",
              "718   Book which lesson? then you msg me... I will c...           0\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "4873  Hi dis is yijue i would be happy to work wif ü...           0\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "5581                                                N/a           1\n",
              "4141  Leave it wif me lar... Ü wan to carry meh so h...           0\n",
              "4330  1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...           0\n",
              "925   Actually i deleted my old website..now i m blo...           0\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "4773  Hi, Mobile no.  &lt;#&gt;  has added you in th...           0\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fd6d0d2-a3de-4d7b-8b72-87dcfbfc5f32\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst &amp; eà...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>Book which lesson? then you msg me... I will c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4873</th>\n",
              "      <td>Hi dis is yijue i would be happy to work wif ü...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4141</th>\n",
              "      <td>Leave it wif me lar... Ü wan to carry meh so h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4330</th>\n",
              "      <td>1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>Actually i deleted my old website..now i m blo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4773</th>\n",
              "      <td>Hi, Mobile no.  &amp;lt;#&amp;gt;  has added you in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fd6d0d2-a3de-4d7b-8b72-87dcfbfc5f32')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fd6d0d2-a3de-4d7b-8b72-87dcfbfc5f32 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fd6d0d2-a3de-4d7b-8b72-87dcfbfc5f32');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 Results:** As expected increasing number of epochs slightly improved the f1 score and accuracy. Running it on 3 epochs seemed like a good threshold as the loss function kept decresing but the accuracy stopped improving. We're getting pretty good results with only 18 text messages that got missclassfied from the test."
      ],
      "metadata": {
        "id": "jWSfz5EA9gkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze layers\n",
        "pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlSsZB1z7TXY",
        "outputId": "095bf455-69c4-4637-c99c-d9fdbe3d263c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=3) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E1tsBon7nDo",
        "outputId": "a1938dee-dc1e-475b-918a-60454828c04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_10/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_10/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 69s 103ms/step - loss: 0.0942 - accuracy: 0.9679 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 58s 95ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.0602 - val_accuracy: 0.9885\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 59s 96ms/step - loss: 0.0204 - accuracy: 0.9947 - val_loss: 0.0865 - val_accuracy: 0.9828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "_OpcuEbyAuIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model_unfreeze.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "IsfZJw01A0jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wENCXkfaBQQC",
        "outputId": "a00e4861-ebc0-4e58-c0cb-4704c79baa7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1fc80e5610>"
            ]
          },
          "metadata": {},
          "execution_count": 197
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "4joh3aupBQwG",
        "outputId": "19a08c11-5aec-4138-cc4e-6cab127d1a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1f4e882fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 198
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "print_metrics('BERT 3e + FCN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRs8lu0JA76b",
        "outputId": "36bc8ce3-63ab-4301-b04a-fcfac76ac010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, train data: : accuracy = 0.9953, precision = 1.0000, recall = 0.9774, f1 = 0.9886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "print_metrics('BERT 3e + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBB3uuD3AqUR",
        "outputId": "cce690c2-b3a6-42b1-d9d9-2a3e7f7293fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, test data: : accuracy = 0.9828, precision = 0.9840, recall = 0.9354, f1 = 0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "_F0aKI--BZ7o",
        "outputId": "9b35660d-b6a0-437a-dad8-351a76d51c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "5667  Keep safe and let me assist you to have a CÀSH...           1\n",
              "5738  Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst & eà...           1\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "718   Book which lesson? then you msg me... I will c...           0\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "5615  Did you know that people in cluttered homes ar...           1\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "4931  Hi, the SEXYCHAT girls are waiting for you to ...           1\n",
              "5581                                                N/a           1\n",
              "2680  New Tones This week include: 1)McFly-All Ab..,...           1\n",
              "1518  Our brand new mobile music service is now live...           1\n",
              "6008  Daghang salamat sa suporta ug pagsalig nga iny...           1\n",
              "3422  Welcome! Please reply with your AGE and GENDER...           1\n",
              "1500  SMS. ac JSco: Energy is high, but u may not kn...           1\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "5963  Download to get an exclusive bonus, the super ...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "6068  Keep safe and let me assist you to have a CÀSH...           1\n",
              "5709  Need additional funds? We process bank cashloa...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91401920-f467-4f7c-948b-cf52131d2067\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5667</th>\n",
              "      <td>Keep safe and let me assist you to have a CÀSH...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst &amp; eà...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>Book which lesson? then you msg me... I will c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5615</th>\n",
              "      <td>Did you know that people in cluttered homes ar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4931</th>\n",
              "      <td>Hi, the SEXYCHAT girls are waiting for you to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>Our brand new mobile music service is now live...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6008</th>\n",
              "      <td>Daghang salamat sa suporta ug pagsalig nga iny...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3422</th>\n",
              "      <td>Welcome! Please reply with your AGE and GENDER...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>SMS. ac JSco: Energy is high, but u may not kn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5963</th>\n",
              "      <td>Download to get an exclusive bonus, the super ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6068</th>\n",
              "      <td>Keep safe and let me assist you to have a CÀSH...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5709</th>\n",
              "      <td>Need additional funds? We process bank cashloa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91401920-f467-4f7c-948b-cf52131d2067')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91401920-f467-4f7c-948b-cf52131d2067 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91401920-f467-4f7c-948b-cf52131d2067');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 Results:** Unfreezing the BERT model layers helped with increasing the F1 score to 0.9745 on running the model for 3 epochs. The performance on the training set was excellent which may mean that we're slightly overfitting. \n",
        "\n",
        "Because the performance kept improving we may try to run on a couple more epochs to see if overfitting becomes worse and see if we will hit lower performance on the validation set."
      ],
      "metadata": {
        "id": "7l9OgX4CCA8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze layers\n",
        "pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOcZs6nZCwYq",
        "outputId": "e94f09ca-879b-4925-e05e-db5686d24bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change to 5 epochs\n",
        "pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sSSN7ULC1es",
        "outputId": "9348c559-9aca-4d7f-ec17-41db7c773cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_16/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_16/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 68s 100ms/step - loss: 0.0868 - accuracy: 0.9720 - val_loss: 0.0528 - val_accuracy: 0.9869\n",
            "Epoch 2/5\n",
            "611/611 [==============================] - 65s 106ms/step - loss: 0.0352 - accuracy: 0.9896 - val_loss: 0.0472 - val_accuracy: 0.9902\n",
            "Epoch 3/5\n",
            "611/611 [==============================] - 58s 95ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0500 - val_accuracy: 0.9910\n",
            "Epoch 4/5\n",
            "611/611 [==============================] - 59s 96ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0607 - val_accuracy: 0.9918\n",
            "Epoch 5/5\n",
            "611/611 [==============================] - 62s 102ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "_EkvhANcE1R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model_unfreeze.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "F3HqKj74EcdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "5TwzjWs8EM2w",
        "outputId": "7a70532e-4ba0-42ea-af3c-9a4d43ce3aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "714   Save yourself the stress. If the person has a ...           0\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "5581                                                N/a           1\n",
              "2680  New Tones This week include: 1)McFly-All Ab..,...           1\n",
              "4141  Leave it wif me lar... Ü wan to carry meh so h...           0\n",
              "4330  1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...           0\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b9764fc-d128-48a0-920b-e84acd24327e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>Save yourself the stress. If the person has a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4141</th>\n",
              "      <td>Leave it wif me lar... Ü wan to carry meh so h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4330</th>\n",
              "      <td>1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b9764fc-d128-48a0-920b-e84acd24327e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b9764fc-d128-48a0-920b-e84acd24327e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b9764fc-d128-48a0-920b-e84acd24327e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "print_metrics('BERT 5e + FCN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "# test\n",
        "print_metrics('BERT 5e + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP-dGTD6ExBx",
        "outputId": "77620e68-ad24-448d-acb0-e27f8e01e404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, train data: : accuracy = 0.9998, precision = 1.0000, recall = 0.9990, f1 = 0.9995\n",
            "BERT 3e + FCN, test data: : accuracy = 0.9910, precision = 0.9773, recall = 0.9810, f1 = 0.9791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 Results:** Increasing the number of epochs to 5 has resulted in some overfitting, we see a degraded performance on the test set in F1 score and increase in the number of misclassified examples. As a result of this experiment BERT model with unfrozen layers and 3 epochs proved to produce really good results. \n",
        "\n",
        "Original untuned model test performance:\n",
        "accuracy = 0.9828, precision = 0.9797, recall = 0.9377, f1 = 0.9583\n",
        "\n",
        "\n",
        "Tuned model test performance:\n",
        "accuracy = 0.9893, precision = 0.9841, recall = 0.9650, f1 = 0.9745\n"
      ],
      "metadata": {
        "id": "MLkuzmXNFO08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT + CNN tuning"
      ],
      "metadata": {
        "id": "1CIcslSTOgOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1:** Increase number of epochs and unfreeze BERT layers, not much improvement."
      ],
      "metadata": {
        "id": "rJdcEHPfQ3nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1)\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsaCz6dnPDgO",
        "outputId": "5b830b7e-98a9-4670-ac15-a61e6f86b36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_12/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_12/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 72s 106ms/step - loss: 0.0749 - accuracy: 0.9752 - val_loss: 0.0658 - val_accuracy: 0.9861\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 61s 101ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.0539 - val_accuracy: 0.9861\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 62s 101ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0538 - val_accuracy: 0.9861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "TP7lfF9UQvQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdvlFabDQcSH",
        "outputId": "1549004f-85d8-4907-8d8e-ab0141f1d413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9986, precision = 1.0000, recall = 0.9931, f1 = 0.9965\n",
            "BERT + CNN, test data: : accuracy = 0.9861, precision = 0.9767, recall = 0.9582, f1 = 0.9674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2:** Change kernel sizes, from lit review Roy et al. used the following kernel sizes. Kernel sizes improved the model. But now it overfits given that we're running it on 3 epochs."
      ],
      "metadata": {
        "id": "hPHddgjfRCcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVMinOwPPxU4",
        "outputId": "71481b63-24ea-413b-da2d-0212f16f17c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_13/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_13/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 72s 107ms/step - loss: 0.0800 - accuracy: 0.9718 - val_loss: 0.0471 - val_accuracy: 0.9894\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 61s 99ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.0531 - val_accuracy: 0.9885\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 61s 100ms/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 0.0484 - val_accuracy: 0.9918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "JpLxOK_yRSOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN kernel, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('BERT + CNN kernel, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PALsjyI1RS5a",
        "outputId": "7502119f-a47a-4db5-86be-f35243ea570a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9986, precision = 1.0000, recall = 0.9931, f1 = 0.9965\n",
            "BERT + CNN, test data: : accuracy = 0.9918, precision = 0.9884, recall = 0.9734, f1 = 0.9808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 3:** Decrease the number of filters to offset overfitting and possibly increase performance"
      ],
      "metadata": {
        "id": "VnaafpFDThAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5],\n",
        "                                       num_filters = [32,64,128])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy32_mv7TMm7",
        "outputId": "9e451a9f-0c45-4564-e3a4-9e89823f4106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 76s 103ms/step - loss: 0.0742 - accuracy: 0.9760 - val_loss: 0.0517 - val_accuracy: 0.9853\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 60s 98ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.0578 - val_accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 61s 100ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0566 - val_accuracy: 0.9877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)\n",
        "\n",
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "sVf6Q3ZBUGSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f6adfc-1ce8-45f7-d7d2-fc5fc14d171e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9982, precision = 1.0000, recall = 0.9912, f1 = 0.9956\n",
            "BERT + CNN, test data: : accuracy = 0.9877, precision = 0.9844, recall = 0.9582, f1 = 0.9711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HdBV-7BtXLbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation"
      ],
      "metadata": {
        "id": "_suEHlIKjKat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8k87gioltGR",
        "outputId": "58322168-435b-440f-87b3-ab1573032f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4885"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X[:977])\n",
        "len(train_X[977:1954])\n",
        "len(train_X[1954:2931])\n",
        "len(train_X[2931:3908])\n",
        "len(train_X[3908:4885])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySIcuBlBk4jN",
        "outputId": "17f41689-218a-45b7-b632-3e57118d05e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "977"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first fold\n",
        "len(train_X[977:4885]) + len(train_X[:977])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdRE1Ot2mer5",
        "outputId": "684268d5-a0ec-4ced-e65f-cb9b967c5c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4885"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_val = 5\n",
        "# FOLD_SIZE = 977\n",
        "# for i in range(cross_val):\n",
        "#   test_1 = train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]\n",
        "#   test_2 = train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)]\n"
      ],
      "metadata": {
        "id": "0vdErCr6xAgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CROSS_VAL = 5\n",
        "FOLD_SIZE = 977\n",
        "\n",
        "for i in range(CROSS_VAL):\n",
        "  max_length = 100\n",
        "  #max_length = 160                  # set max_length\n",
        "\n",
        "  all_train_examples = list(train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]])\n",
        "  all_val_examples = list(train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)])\n",
        "  all_test_examples = list(test_X)\n",
        "\n",
        "  x_train = bert_tokenizer(all_train_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_train = tf.convert_to_tensor(list(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]))\n",
        "\n",
        "  x_test = bert_tokenizer(all_test_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_test = tf.convert_to_tensor(list(test_y))\n",
        "\n",
        "  x_val = bert_tokenizer(all_val_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_val = tf.convert_to_tensor(list(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)]))\n",
        "\n",
        "  # unfreeze layers\n",
        "  pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)\n",
        "\n",
        "  # change to 5 epochs\n",
        "  pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                    y_train,   \n",
        "                                                    validation_data=([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask], y_val),    \n",
        "                                                    batch_size=8, \n",
        "                                                    epochs=1) \n",
        "\n",
        "  train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "  train_y_predict = train_predict_labels.round(0)\n",
        "\n",
        "  val_predict_labels = pooled_bert_model_unfreeze.predict([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask])\n",
        "  val_y_predict = val_predict_labels.round(0)\n",
        "\n",
        "  # train\n",
        "  print_metrics('BERT 5e + FCN, train', np.array(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]], int), train_y_predict)\n",
        "  # validation\n",
        "  print_metrics('BERT 5e + FCN, validation', np.array(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)], int), val_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYyW1APYkiaK",
        "outputId": "5e22a2dc-c55e-44f5-ee26-b0d7ace0d71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "489/489 [==============================] - 57s 103ms/step - loss: 0.1052 - accuracy: 0.9624 - val_loss: 0.0428 - val_accuracy: 0.9887\n",
            "BERT 5e + FCN, train: accuracy = 0.9895, precision = 0.9974, recall = 0.9521, f1 = 0.9743\n",
            "BERT 5e + FCN, validation: accuracy = 0.9887, precision = 1.0000, recall = 0.9455, f1 = 0.9720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "489/489 [==============================] - 58s 105ms/step - loss: 0.0972 - accuracy: 0.9665 - val_loss: 0.0299 - val_accuracy: 0.9928\n",
            "BERT 5e + FCN, train: accuracy = 0.9918, precision = 0.9803, recall = 0.9803, f1 = 0.9803\n",
            "BERT 5e + FCN, validation: accuracy = 0.9928, precision = 0.9900, recall = 0.9754, f1 = 0.9826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_6/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_6/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_6/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_6/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "489/489 [==============================] - 61s 112ms/step - loss: 0.0995 - accuracy: 0.9655 - val_loss: 0.0705 - val_accuracy: 0.9785\n",
            "BERT 5e + FCN, train: accuracy = 0.9895, precision = 0.9639, recall = 0.9864, f1 = 0.9750\n",
            "BERT 5e + FCN, validation: accuracy = 0.9785, precision = 0.9302, recall = 0.9709, f1 = 0.9501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_7/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_7/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_7/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_7/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "489/489 [==============================] - 67s 124ms/step - loss: 0.0956 - accuracy: 0.9678 - val_loss: 0.0485 - val_accuracy: 0.9846\n",
            "BERT 5e + FCN, train: accuracy = 0.9908, precision = 0.9873, recall = 0.9676, f1 = 0.9774\n",
            "BERT 5e + FCN, validation: accuracy = 0.9846, precision = 0.9761, recall = 0.9533, f1 = 0.9645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "489/489 [==============================] - 57s 103ms/step - loss: 0.0970 - accuracy: 0.9672 - val_loss: 0.0277 - val_accuracy: 0.9908\n",
            "BERT 5e + FCN, train: accuracy = 0.9900, precision = 0.9950, recall = 0.9576, f1 = 0.9759\n",
            "BERT 5e + FCN, validation: accuracy = 0.9908, precision = 0.9893, recall = 0.9635, f1 = 0.9763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy = 0.9887, precision = 1.0000, recall = 0.9455, f1 = 0.9720\n",
        "\n",
        "accuracy = 0.9928, precision = 0.9900, recall = 0.9754, f1 = 0.9826\n",
        "\n",
        "accuracy = 0.9785, precision = 0.9302, recall = 0.9709, f1 = 0.9501\n",
        "\n",
        "accuracy = 0.9846, precision = 0.9761, recall = 0.9533, f1 = 0.9645\n",
        "\n",
        "accuracy = 0.9908, precision = 0.9893, recall = 0.9635, f1 = 0.9763"
      ],
      "metadata": {
        "id": "t4hScVQZ4NAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation results\n",
        "cross_val_acc = [0.9887, 0.9928, 0.9785, 0.9846, 0.9908]\n",
        "cross_val_precision = [1, 0.9900, 0.9302, 0.9761, 0.9893]\n",
        "cross_val_recall = [0.9455, 0.9754, 0.9709, 0.9533, 0.9635]\n",
        "cross_val_f1 = [0.9720, 0.9826, 0.9501, 0.9645, 0.9763]\n",
        "\n",
        "print(\"mean accuracy\", np.mean(cross_val_acc))\n",
        "print(\"mean f1\", np.mean(cross_val_f1))\n",
        "\n",
        "print(\"st dev accuracy\", np.std(cross_val_acc))\n",
        "print(\"se dev f1\", np.std(cross_val_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pn9z7wQpwEa",
        "outputId": "642f3dde-7fb7-4d45-a383-a9ceaa9ab727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy 0.98708\n",
            "mean f1 0.9691000000000001\n",
            "mean accuracy 0.005078346187490561\n",
            "mean f1 0.011177298421353898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RmExkj8Z9G03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Count unknown tokens"
      ],
      "metadata": {
        "id": "gThMPxB9_HjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for sms in data['text']:\n",
        "  if ('[UNK]' in bert_tokenizer.tokenize(sms)):\n",
        "    count += 1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvnw49FrDD0-",
        "outputId": "9ab09a15-753b-49ae-bf2a-48731f6afa32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for sms in data[data['crowd'] == 1]['text']:\n",
        "  if ('[UNK]' in bert_tokenizer.tokenize(sms)):\n",
        "    count += 1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNgvXDu7_sGW",
        "outputId": "5d2aa847-e001-4e69-85a1-b82ee9e88b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for sms in data[data['crowd'] == 0]['text']:\n",
        "  if ('[UNK]' in bert_tokenizer.tokenize(sms)):\n",
        "    count += 1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnpYrfDEE-f_",
        "outputId": "cb06cac5-0fbe-42ec-fae2-9cb111c3dc58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13 text with unknown tokens in the data and most of them came from crowdsourced data. 12 unknown tokens in the crowdsourced data."
      ],
      "metadata": {
        "id": "Wd3IKYr-EseO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CLS based BERT model"
      ],
      "metadata": {
        "id": "XI4vbLZF7pdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bert_cls_model(train_layers=-1,\n",
        "                          hidden_size = 100, \n",
        "                          dropout=0.3,\n",
        "                          learning_rate=0.00005):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the Pooled Ouutput for classification purposes\n",
        "    \"\"\"\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "\n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer')\n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                   'token_type_ids': token_type_ids,\n",
        "                   'attention_mask': attention_mask}         \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    cls_token = bert_out[0][:, 0]\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_token)\n",
        "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
        "\n",
        "    \n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy') \n",
        "\n",
        "\n",
        "    \n",
        "    return classification_model"
      ],
      "metadata": {
        "id": "n6gNssCaEjZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze layers\n",
        "pooled_bert_cls_model_unfreeze = create_bert_cls_model(train_layers=1)\n",
        "\n",
        "# change to 5 epochs\n",
        "cls_bert_model_history = pooled_bert_cls_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j1WCQst79SF",
        "outputId": "2bbd9ee8-d3e5-43ee-8deb-756ef317bee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "611/611 [==============================] - 69s 100ms/step - loss: 0.0789 - accuracy: 0.9730 - val_loss: 0.0657 - val_accuracy: 0.9828\n",
            "Epoch 2/5\n",
            "611/611 [==============================] - 59s 96ms/step - loss: 0.0293 - accuracy: 0.9918 - val_loss: 0.0736 - val_accuracy: 0.9836\n",
            "Epoch 3/5\n",
            "611/611 [==============================] - 58s 95ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0685 - val_accuracy: 0.9902\n",
            "Epoch 4/5\n",
            "611/611 [==============================] - 58s 95ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0579 - val_accuracy: 0.9885\n",
            "Epoch 5/5\n",
            "611/611 [==============================] - 58s 95ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0760 - val_accuracy: 0.9902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = pooled_bert_cls_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = pooled_bert_cls_model_unfreeze.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)\n",
        "\n",
        "print_metrics('BERT CLS + FCN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXAR_cgC8T72",
        "outputId": "72b36b06-7b17-4dbc-c7ff-999591be80c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT CLS + FCN, train data: : accuracy = 0.9998, precision = 1.0000, recall = 0.9990, f1 = 0.9995\n",
            "test data: : accuracy = 0.9902, precision = 0.9846, recall = 0.9696, f1 = 0.9770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ku-yXZ-9-2uz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}