{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W266: UCI + PH Translated Dataset SMS Spam Detection Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MySc4TsBTRdT",
        "HCn1BoEaPA6E",
        "JqfIxHLRPFqv",
        "nvR_4nFjOZ8W"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12683f4d190a420e94c1d20bee5c1fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_849eef67193245559c5169a150ff89f4",
              "IPY_MODEL_732e4d9c8afd4549a2f1b8ed7feae694",
              "IPY_MODEL_c19ab1066d924f97b2876412dd5cf355"
            ],
            "layout": "IPY_MODEL_3fcec71a462e430196d681727ee74859"
          }
        },
        "849eef67193245559c5169a150ff89f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc0af81b4a64405c9381ea20c9aacf0c",
            "placeholder": "​",
            "style": "IPY_MODEL_fa73d38b67e740ecb55fd4e079ae3fde",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "732e4d9c8afd4549a2f1b8ed7feae694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd746a65d30482bb5c7fb73562b0444",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13d3e10088c146fd93bee5ebe32d9d7e",
            "value": 213450
          }
        },
        "c19ab1066d924f97b2876412dd5cf355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8777133cb93b4f58abd7ca3b20769b58",
            "placeholder": "​",
            "style": "IPY_MODEL_1bd0dd9e3a7545f09c1b943208c6b8c6",
            "value": " 208k/208k [00:00&lt;00:00, 334kB/s]"
          }
        },
        "3fcec71a462e430196d681727ee74859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc0af81b4a64405c9381ea20c9aacf0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa73d38b67e740ecb55fd4e079ae3fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbd746a65d30482bb5c7fb73562b0444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13d3e10088c146fd93bee5ebe32d9d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8777133cb93b4f58abd7ca3b20769b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bd0dd9e3a7545f09c1b943208c6b8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c35cc7ea104f4894b9f0eb902cd9c19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f3d502d012144e08901076d3d1e0c02",
              "IPY_MODEL_f179587c71c848ffa553bb1a4d101bd1",
              "IPY_MODEL_900ff25546f9431aad60695d0ba770f9"
            ],
            "layout": "IPY_MODEL_d519574bbe57492e8f9ea18a7c20369e"
          }
        },
        "2f3d502d012144e08901076d3d1e0c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e868cd55b5467cb9081cfb2e636628",
            "placeholder": "​",
            "style": "IPY_MODEL_95468b45c9684bc39b0e8a8d07a97267",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "f179587c71c848ffa553bb1a4d101bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e74d61f92c44065a963beb0161247dd",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_540afbd9d3ce42be9e67754d21ca1a5b",
            "value": 29
          }
        },
        "900ff25546f9431aad60695d0ba770f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_445fabbf0067475f9bfc52159aaebdf4",
            "placeholder": "​",
            "style": "IPY_MODEL_694e1f99f3364decb0bdd314da2ae9a1",
            "value": " 29.0/29.0 [00:00&lt;00:00, 329B/s]"
          }
        },
        "d519574bbe57492e8f9ea18a7c20369e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02e868cd55b5467cb9081cfb2e636628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95468b45c9684bc39b0e8a8d07a97267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e74d61f92c44065a963beb0161247dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "540afbd9d3ce42be9e67754d21ca1a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "445fabbf0067475f9bfc52159aaebdf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694e1f99f3364decb0bdd314da2ae9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be87f999bd6e40d49685355337ea7903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02439c633f624ce7bf25fa4a91be5c96",
              "IPY_MODEL_b1a21c7f18374e44bfaf934d7c3bfbd2",
              "IPY_MODEL_9ab6fccd077c4c57b9fda66f09bc53a4"
            ],
            "layout": "IPY_MODEL_b922c98f0b944edfb60407951f30b62c"
          }
        },
        "02439c633f624ce7bf25fa4a91be5c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29cc29f4d2b438b9bba1a9c7f09d408",
            "placeholder": "​",
            "style": "IPY_MODEL_8b3d5373f0b4489eb5287d1686c0f834",
            "value": "Downloading config.json: 100%"
          }
        },
        "b1a21c7f18374e44bfaf934d7c3bfbd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d9bbfb1a5b42b48f2fe21cf6606051",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79ee1f88080f43a381d6376797012f87",
            "value": 570
          }
        },
        "9ab6fccd077c4c57b9fda66f09bc53a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0385514add24d339372ad087c7c6579",
            "placeholder": "​",
            "style": "IPY_MODEL_cef3cc29a7614b408becf1e3711d6baf",
            "value": " 570/570 [00:00&lt;00:00, 5.64kB/s]"
          }
        },
        "b922c98f0b944edfb60407951f30b62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a29cc29f4d2b438b9bba1a9c7f09d408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3d5373f0b4489eb5287d1686c0f834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38d9bbfb1a5b42b48f2fe21cf6606051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ee1f88080f43a381d6376797012f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0385514add24d339372ad087c7c6579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cef3cc29a7614b408becf1e3711d6baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeca78e97c8c4a51b7d2b000590a9dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3aa4038b35214fbaaf9d41e83ec83d17",
              "IPY_MODEL_031e7750705e43c18197c8057a348f4b",
              "IPY_MODEL_3b6f651f4ecf4b338b89fbdc40e72ae6"
            ],
            "layout": "IPY_MODEL_06e8826c48b64f5eafcfd7dcab96e596"
          }
        },
        "3aa4038b35214fbaaf9d41e83ec83d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55efcc482e64957a621798549407d4c",
            "placeholder": "​",
            "style": "IPY_MODEL_7f299bd5917f41ac8408702f4380cab0",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "031e7750705e43c18197c8057a348f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee391ac35074fd292f4c3a536fa7e2f",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2dd98028a24b44d6bffbc55e9db537b1",
            "value": 526681800
          }
        },
        "3b6f651f4ecf4b338b89fbdc40e72ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89aad114413b4666bd8f341d2dd10e05",
            "placeholder": "​",
            "style": "IPY_MODEL_8c1108acae334f5c9686d75b7b9923e4",
            "value": " 502M/502M [00:14&lt;00:00, 56.2MB/s]"
          }
        },
        "06e8826c48b64f5eafcfd7dcab96e596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c55efcc482e64957a621798549407d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f299bd5917f41ac8408702f4380cab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aee391ac35074fd292f4c3a536fa7e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dd98028a24b44d6bffbc55e9db537b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89aad114413b4666bd8f341d2dd10e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1108acae334f5c9686d75b7b9923e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Table of content and model results\n",
        "\n"
      ],
      "metadata": {
        "id": "zL6g1T8Jeyi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zewIcVHferk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "AitRMbM6R_23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.8.3 --quiet"
      ],
      "metadata": {
        "id": "uFMQmofaT2x_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cfa8b3-7c62-4a49-81fa-33811c89317e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 24.2 MB 18.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "id": "ZepWG26Pb36a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b90da44-e2e2-4219-ec57-c4c044258f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 55.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 70.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 6.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-text==2.8.2 --quiet"
      ],
      "metadata": {
        "id": "LBz57saHcLid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269d58ba-1105-455f-bfd1-144df4d2e8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# misc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)\n",
        "\n",
        "# report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# word2vec\n",
        "import nltk\n",
        "import gensim\n",
        "from nltk.data import find\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "# BERT\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "metadata": {
        "id": "EvPhbSW1rrdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LYU51GnwRSs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc793c7-a4cc-464d-875f-eae553901034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and clean data"
      ],
      "metadata": {
        "id": "U6oStQMXSEyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename uci data to just data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/W266: SMS Spam Detection Final Project/data/data_clean_trans.csv\")\n",
        "#data = pd.read_csv(\"/content/drive/MyDrive/W266/data/data_clean_trans.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "E2RqNNQxKuVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "58a90332-b5ff-4e50-ef11-09e4f5d29aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  spam                                               text  \\\n",
              "0              0     0  Go until jurong point, crazy.. Available only ...   \n",
              "1              1     0                    Ok lar... Joking wif u oni...\\n   \n",
              "2              2     1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3              3     0  U dun say so early hor... U c already then say...   \n",
              "4              4     0  Nah I don't think he goes to usf, he lives aro...   \n",
              "...          ...   ...                                                ...   \n",
              "6102        6102     1  You have passed the official certification onl...   \n",
              "6103        6103     1  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...   \n",
              "6104        6104     1  Hi, I'm a Shopee Hiring Manager and I'm curren...   \n",
              "6105        6105     1  4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...   \n",
              "6106        6106     1  Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...   \n",
              "\n",
              "      crowd                                            spanish language  \\\n",
              "0         0  Vaya hasta Jurong Point, loco ... disponible s...       en   \n",
              "1         0               Ok lar ... bromeando wif u oni ...\\n       en   \n",
              "2         0  Entrada gratuita en 2 una compensación de wkly...       en   \n",
              "3         0    No digo tan temprano hor ... ya c ya digo ...\\n       en   \n",
              "4         0  No, no creo que vaya a la USF, aunque vive por...       en   \n",
              "...     ...                                                ...      ...   \n",
              "6102      1  Ha aprobado la certificación oficial de la aud...       en   \n",
              "6103      1  ¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...       en   \n",
              "6104      1  Hola, soy un gerente de contratación de Shopee...       en   \n",
              "6105      1  ¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...      fil   \n",
              "6106      1  Sissy, solo 1p por apuesta para Cutt.ly/BingOp...      fil   \n",
              "\n",
              "                                                english  \n",
              "0     Go until jurong point, crazy.. Available only ...  \n",
              "1                       Ok lar... Joking wif u oni...\\n  \n",
              "2     Free entry in 2 a wkly comp to win FA Cup fina...  \n",
              "3     U dun say so early hor... U c already then say...  \n",
              "4     Nah I don't think he goes to usf, he lives aro...  \n",
              "...                                                 ...  \n",
              "6102  You have passed the official certification onl...  \n",
              "6103  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...  \n",
              "6104  Hi, I'm a Shopee Hiring Manager and I'm curren...  \n",
              "6105  4 pcs solar lights for only 1,499!\\nMost cheap...  \n",
              "6106  Sissy, just 1p per bet for cutt.ly/bingoplus-p...  \n",
              "\n",
              "[6107 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a77a640-fece-40dc-bcd1-cc98cc3436ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>spam</th>\n",
              "      <th>text</th>\n",
              "      <th>crowd</th>\n",
              "      <th>spanish</th>\n",
              "      <th>language</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Vaya hasta Jurong Point, loco ... disponible s...</td>\n",
              "      <td>en</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar ... bromeando wif u oni ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>0</td>\n",
              "      <td>Entrada gratuita en 2 una compensación de wkly...</td>\n",
              "      <td>en</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "      <td>No digo tan temprano hor ... ya c ya digo ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "      <td>No, no creo que vaya a la USF, aunque vive por...</td>\n",
              "      <td>en</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6102</th>\n",
              "      <td>6102</td>\n",
              "      <td>1</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "      <td>1</td>\n",
              "      <td>Ha aprobado la certificación oficial de la aud...</td>\n",
              "      <td>en</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6103</th>\n",
              "      <td>6103</td>\n",
              "      <td>1</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...</td>\n",
              "      <td>en</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6104</th>\n",
              "      <td>6104</td>\n",
              "      <td>1</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "      <td>1</td>\n",
              "      <td>Hola, soy un gerente de contratación de Shopee...</td>\n",
              "      <td>en</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6105</th>\n",
              "      <td>6105</td>\n",
              "      <td>1</td>\n",
              "      <td>4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...</td>\n",
              "      <td>fil</td>\n",
              "      <td>4 pcs solar lights for only 1,499!\\nMost cheap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6106</th>\n",
              "      <td>6106</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, solo 1p por apuesta para Cutt.ly/BingOp...</td>\n",
              "      <td>fil</td>\n",
              "      <td>Sissy, just 1p per bet for cutt.ly/bingoplus-p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6107 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a77a640-fece-40dc-bcd1-cc98cc3436ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a77a640-fece-40dc-bcd1-cc98cc3436ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a77a640-fece-40dc-bcd1-cc98cc3436ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.convert_dtypes()\n",
        "data.dtypes"
      ],
      "metadata": {
        "id": "47UovwLKgvce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a372a5-670a-42f6-ba52-d6e10fef7bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0     Int64\n",
              "spam           Int64\n",
              "text          string\n",
              "crowd          Int64\n",
              "spanish       string\n",
              "language      string\n",
              "english       string\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "0RuqEtIVSOkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(data[\"spam\"] == 1)"
      ],
      "metadata": {
        "id": "n6pRHRdg8MoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a52c775-9b69-4bf7-e3f1-ddfc4891e520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1280"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(data[\"spam\"] == 0)"
      ],
      "metadata": {
        "id": "DKlzqlpy8u1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31556072-33de-4f27-ef13-8802f8ebf82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4827"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data"
      ],
      "metadata": {
        "id": "GmTIZRghbCkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data['english'], data['spam']\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)"
      ],
      "metadata": {
        "id": "KlJMJlhpVtnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "VVX5ga_ODFrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(test_name, y_true, y_pred):\n",
        "    print('%s: accuracy = %.4f, precision = %.4f, recall = %.4f, f1 = %.4f'\n",
        "          % (test_name,\n",
        "             metrics.accuracy_score(y_true, y_pred),\n",
        "             metrics.precision_score(y_true, y_pred),\n",
        "             metrics.recall_score(y_true, y_pred),\n",
        "             metrics.f1_score(y_true, y_pred)))"
      ],
      "metadata": {
        "id": "rYG1iASIDEj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base models\n",
        "\n",
        "- Word2Vec embeddings\n",
        "  - CNN\n",
        "  - LSTM\n",
        "\n",
        "- BERT embeddings\n",
        "  - Fully connected network\n",
        "  - CNN\n"
      ],
      "metadata": {
        "id": "K0oBtsKoSTEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Word2Vec embeddings"
      ],
      "metadata": {
        "id": "MySc4TsBTRdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('word2vec_sample')"
      ],
      "metadata": {
        "id": "7BFkjykfSUQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602ed0a0-0272-4ea2-df02-f18f320abd64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Unzipping models/word2vec_sample.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))"
      ],
      "metadata": {
        "id": "Gz7wtvLeXJb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
      ],
      "metadata": {
        "id": "uY2qQt3oTxpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a Word2Vec embedding\n",
        "EMBEDDING_DIM = len(model['university'])      # we know... it's 300\n",
        "\n",
        "# initialize embedding matrix and word-to-id map:\n",
        "embedding_matrix = np.zeros((len(model.vocab.keys()) + 1, EMBEDDING_DIM))       \n",
        "vocab_dict = {}\n",
        "\n",
        "# build the embedding matrix and the word-to-id map:\n",
        "for i, word in enumerate(model.vocab.keys()):\n",
        "    embedding_vector = model[word]\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        vocab_dict[word] = i\n",
        "\n"
      ],
      "metadata": {
        "id": "LJwX14iJWwvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "train_tokens = tokenizer.tokenize(train_X)\n",
        "test_tokens = tokenizer.tokenize(test_X)"
      ],
      "metadata": {
        "id": "hlQF33RqYvfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens[0]"
      ],
      "metadata": {
        "id": "5SvpFHLNZVJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747428cb-26f4-4bb0-94a7-7fc7ef0a4eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(18,), dtype=string, numpy=\n",
              "array([b\"You've\", b'won', b'tkts', b'to', b'the', b'EURO2004', b'CUP',\n",
              "       b'FINAL', b'or', b'\\xc2\\xa3800', b'CASH,', b'to', b'collect',\n",
              "       b'CALL', b'09058099801', b'b4190604,', b'POBOX', b'7876150ppm'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: make sure this is tuned\n",
        "MAX_SEQUENCE_LENGTH = 5"
      ],
      "metadata": {
        "id": "FTR331lLZi8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sents_to_ids(token_list_list, label_list, num_examples=100000000):\n",
        "    \"\"\"\n",
        "    converting a list of strings to a list of lists of word ids\n",
        "    \"\"\"\n",
        "    text_ids = []\n",
        "    text_labels = []\n",
        "    example_count = 0\n",
        "    use_token_list_list = token_list_list[:num_examples]\n",
        "    for i, token_list in enumerate(use_token_list_list):\n",
        "        if i < num_examples:\n",
        "            try:\n",
        "                example = []\n",
        "                for token in list(token_list.numpy()):\n",
        "                    decoded = token.decode('utf-8').replace('.','').replace(',','').replace('!','')\n",
        "                    try:\n",
        "                        example.append(vocab_dict[decoded])\n",
        "                        \n",
        "                    except:\n",
        "                        example.append(43981)\n",
        "                if len(example) >= MAX_SEQUENCE_LENGTH:\n",
        "                    text_ids.append(example[:MAX_SEQUENCE_LENGTH])\n",
        "                    text_labels.append(label_list[i])\n",
        "                    if example_count % 5000 == 0:\n",
        "                        print('Examples processed: ', example_count)\n",
        "                    example_count += 1\n",
        "                else:\n",
        "                    pass\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    \n",
        "    print('Number of examples retained: ', example_count) \n",
        "    return (np.array(text_ids),   np.array(text_labels)) "
      ],
      "metadata": {
        "id": "ohRUVRzOZmi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to tensor\n",
        "y_train = tf.convert_to_tensor(list(train_y))\n",
        "y_test = tf.convert_to_tensor(list(test_y))"
      ],
      "metadata": {
        "id": "WsNjF9JlZzl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input, train_input_labels = sents_to_ids(train_tokens, y_train)\n",
        "test_input, test_input_labels = sents_to_ids(test_tokens, y_test)"
      ],
      "metadata": {
        "id": "RJrOVPu2Zniw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e135620-0796-4c1d-a3d0-93903e3cd810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples processed:  0\n",
            "Number of examples retained:  4605\n",
            "Examples processed:  0\n",
            "Number of examples retained:  1147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN"
      ],
      "metadata": {
        "id": "HCn1BoEaPA6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                            embedding_matrix.shape[1],\n",
        "                            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "metadata": {
        "id": "hypVVE0gVWFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify model hyperparameters.\n",
        "epochs = 10\n",
        "num_filters = [3, 2, 1]\n",
        "kernel_sizes = [2, 4, 5]\n",
        "dense_layer_dims = [100, 30]\n",
        "dropout_rate = 0.5"
      ],
      "metadata": {
        "id": "eQ6kHgIYV4Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')"
      ],
      "metadata": {
        "id": "g3uG2-WBV_qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_embeddings = cnn_embedding_layer(cnn_input_layer)\n",
        "\n",
        "h = cnn_embeddings"
      ],
      "metadata": {
        "id": "5-JgitXCWAEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layers_for_all_kernel_sizes = []\n",
        "for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "    conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
        "    conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "    conv_layers_for_all_kernel_sizes.append(conv_layer)"
      ],
      "metadata": {
        "id": "pIlpLN0GWCOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)"
      ],
      "metadata": {
        "id": "u1Nv8GblWHoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = keras.layers.Dropout(rate=dropout_rate)(h)"
      ],
      "metadata": {
        "id": "28nx55AtWJCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dense_layer_dim in dense_layer_dims:  \n",
        "    h = keras.layers.Dense(dense_layer_dim, activation='relu')(h)"
      ],
      "metadata": {
        "id": "tbUQSErWWLbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_prediction = keras.layers.Dense(1, activation='sigmoid')(h)"
      ],
      "metadata": {
        "id": "D_RnD91QWMeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = keras.Model(inputs=cnn_input_layer, outputs=cnn_prediction)\n",
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # From information theory notebooks.\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Wnq2VzMtWRv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "JOuRrsY_WUqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9deafd70-9ee6-40b7-d261-1bb12d6552ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 5, 300)       13194600    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 4, 3)         1803        ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 2, 2)         2402        ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 1, 1)         1501        ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 3)           0           ['conv1d[0][0]']                 \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 2)           0           ['conv1d_1[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 1)           0           ['conv1d_2[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6)            0           ['global_max_pooling1d[0][0]',   \n",
            "                                                                  'global_max_pooling1d_1[0][0]', \n",
            "                                                                  'global_max_pooling1d_2[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 6)            0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 100)          700         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 30)           3030        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            31          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,204,067\n",
            "Trainable params: 9,467\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_history = cnn_model.fit(train_input,\n",
        "             np.array(train_input_labels),\n",
        "             validation_data=(test_input, np.array(test_input_labels)),\n",
        "             batch_size=32,\n",
        "             epochs=5\n",
        "             )"
      ],
      "metadata": {
        "id": "tpYEf_jcWX5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74bba95f-a7d0-4bf1-d87d-c43e9f01ea83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "144/144 [==============================] - 11s 6ms/step - loss: 0.4677 - accuracy: 0.7798 - val_loss: 0.3992 - val_accuracy: 0.7724\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.3741 - accuracy: 0.8111 - val_loss: 0.3403 - val_accuracy: 0.8779\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.8597 - val_loss: 0.2869 - val_accuracy: 0.8928\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.2999 - accuracy: 0.8723 - val_loss: 0.2667 - val_accuracy: 0.9032\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.2799 - accuracy: 0.8847 - val_loss: 0.2629 - val_accuracy: 0.9015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "Ms5WvFFmxfVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_pred = cnn_model.predict(train_input)"
      ],
      "metadata": {
        "id": "7CaQHMQ0njBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = cnn_model.predict(test_input)"
      ],
      "metadata": {
        "id": "OdKTBCbhx_Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_input_labels), np.round(dev_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "VaVtHFQfmEWM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d3eb5d76-8886-417f-90b7-9b3bd065712e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW30lEQVR4nO3de5RV5X3/8feHQUCjRq2WEqTVXySxahQVEeulXhGIEY3GYC5SgxkbsdHGmJjYVRMiLrPUeIsax4ABfhFC6o1ajEFrvaRewATQEZURNTCOaASjRrnMOd/+MRs86MyZM3KY88z282I9a/b+7ttzlPWdL89+9j6KCMzMLC29at0BMzP7ICdnM7MEOTmbmSXIydnMLEFOzmZmCeq9uS+w7k9LPR3EPmDLTxxa6y5YglrXNmtTz9GVnLPFjv9vk6+3ubhyNjNL0GavnM3MulWxUOseVIWTs5nlS6G11j2oCidnM8uViGKtu1AVTs5mli9FJ2czs/S4cjYzS5BvCJqZJciVs5lZesKzNczMEuQbgmZmCfKwhplZgnxD0MwsQa6czcwS5BuCZmYJ8g1BM7P0RHjM2cwsPR5zNjNLkIc1zMwS5MrZzCxBhXW17kFVODmbWb54WMPMLEEe1jAzS5ArZzOzBDk5m5mlJ3xD0MwsQR5zNjNLUE6GNXrVugNmZlUVxcpbGZL6SXpc0kJJjZJ+mMV3lfSYpCZJv5LUJ4v3zdabsu27lJzre1n8WUnHVvIxnJzNLF+KxcpbeWuAIyNiH2AIMFLScODHwJURsRuwChif7T8eWJXFr8z2Q9IewFhgT2AkcL2kus4u7uRsZvlSpco52rydrW6RtQCOBP4ji08FTsiWx2TrZNuPkqQsPjMi1kTEC0ATMKyzj+HkbGb50tpacZNUL2l+SasvPZWkOkkLgFeBucDzwBsRsf6N/suBgdnyQGAZQLb9z8BflcbbOaZDviFoZvnShdkaEdEANJTZXgCGSNoOuB3YfZP7VyEnZzPLl80wWyMi3pB0P3AQsJ2k3ll1vDPQnO3WDAwClkvqDXwceL0kvl7pMR3ysIaZ5Uv1ZmvslFXMSNoSOAZYDNwPnJztNg64M1uena2Tbf/viIgsPjabzbErMBh4vLOP4crZzPKlepXzAGBqNrOiFzArIu6S9DQwU9LFwB+Aydn+k4HpkpqAlbTN0CAiGiXNAp4GWoEJUcF3aTk5m1m+VOkJwYhYBOzbTnwp7cy2iIjVwBc6ONckYFJXru/kbGb50tra+T49gJOzmeVLRK17UBVOzmaWLzl5t4aTs5nli5OzmVmC/MpQM7MEFTqdpdYjODmbWb54WMPMLEFOzmZmCfKYs5lZeqLoec5mZunxsIaZWYI8W8PMLEGunM3MEpST5OyX7W+CNWvWMvaMc/j8uLMY8+Uz+enPp2+0/ZIrb+CAo0/csP7jq2/kpHETOGncBD479gwOOvbkjfZ/+y9/4agTvsKkK67vlv5b97ip4QpeXr6QBX+4b0PspJOOY+GC/2bt6mXsv9/eG+Knnnoi8+f9dkNbu3oZ++yzZy263XNFVN4S5sp5E/TpswVTrrmUrbbaknWtrZz2jW9z6PCh7LPX3/PU4ud48623N9r/u+ecuWH5l7++k8VLnt9o+7U3TWf/IZ/plr5b95k2bRbXX38zN9989YZYY+MzfOGUr3PDdZdutO+MGbczY8btAOy11+7c+uvJLFzY2K397fFcOZskttpqSwBaW1tpbfs2XwqFAldcN5nzzhrf4bFz7n2A0UcfvmG98ZklvL5yFf9wwH6bu9vWzR56+DFWrnpjo9gzzzTx3HPPd3BEm7FfPIFZv569ObuWT8WovCWs08pZ0u7AGN77Ku9mYHZELN6cHespCoUCp3ztm/yx+WVO/fxx7L3n7kyfdQdHHDKcnXbcod1jXn5lBc0tr3Dg/vsAUCwWueynN3Hpv5/Po/MWdGf3LWFfOPlzfP7kr9W6Gz1PTmZrlK2cJX0XmAmIti8kfDxbniHpgjLH1UuaL2n+z6fNqGZ/k1NXV8etU6/jvtun8+TTzzF/wZP89v6H+NLJx3d4zN33PsCIww+hrq4OgJm33cVhBx3A3/z1Tt3VbUvcsAP25Z1336Wx8dlad6XHiWKx4payzirn8cCeEbGuNCjpJ0AjcGl7B0VEA9AAsO5PS9P+t0OVbLvN1gzbb28e//0i/ri8hdFfbKt4Vq9ew6hTvsbds6Zs2Pfuex/gwvMmbFhf+NRinljUyMzb7uKdd1ezbt06ttqqH//6DVdNH1VfPGUMv/rVnZ3vaB+U+HBFpTpLzkXgE8BL74sPyLZ9pK1c9Qa9e/dm2222ZvWaNTwy7w987Stf4IH/vGXDPgccfeJGiXnpS8t48623GbLX32+I/fgH392wfMd/zaXxmSVOzB9hkjj55OM4/MjP17orPdNH5N0a5wL3SVoCLMtifwvsBpy9OTvWE7z2+iouvPhyCsUiUQyOPfJQDj/4wLLH3H3vA4w6+h+R1E29tFr7/9Ov4x8PO4gdd9yBF5fO54cTL2flqje4+sqL2WmnHZh95zQWLmxk9HFfBuCwQ4ezfHkLL7zwxxr3vIfKSeWs6GSun6RetH0NeOkNwXkRUdGo+0dlWMO6ZstPHFrrLliCWtc2b3LV8pd/H1txzvnYxJnJVkmdTqWLiGJEPBoRt2bt0UoTs5lZt4ti5a0MSYMk3S/paUmNks7J4j+Q1CxpQdZGlxzzPUlNkp6VdGxJfGQWayo3maKUH0Ixs3yp3rBGK3BeRPxe0jbAE5LmZtuujIjLS3eWtAcwFtiTtnt190r6VLb5OuAYYDkwT9LsiHi63MWdnM0sV6o1RS4iWoCWbPktSYt5b3i3PWOAmRGxBnhBUhNtQ8IATRGxFEDSzGzfssnZTwiaWb504QnB0mcyslbf3ikl7QLsCzyWhc6WtEjSFEnbZ7GBvDdxAtqq5IFl4mU5OZtZvnQhOUdEQ0QMLWkN7z+dpK2BW4FzI+JN4Abgk8AQ2irrKzbHx/CwhpnlSxUf35a0BW2J+ZcRcRtARKwo2X4TcFe22gwMKjl85yxGmXiHXDmbWa5EMSpu5ajtYYTJwOKI+ElJfEDJbicCT2XLs4GxkvpK2hUYTNsrL+YBgyXtKqkPbTcNO32jlStnM8uX6s3WOBj4KvCkpPVvJPs+cKqkIUAALwJnAkREo6RZtN3oawUmrJ92LOls4B6gDpgSEZ2+B9bJ2czypXqzNR6m7UVv7zenzDGTgEntxOeUO649Ts5mli85eXzbydnM8sXJ2cwsPVH4aLyVzsysZ3HlbGaWns6myPUUTs5mli9OzmZmCcrHkLOTs5nlS7TmIzs7OZtZvuQjNzs5m1m++IagmVmKXDmbmaXHlbOZWYpcOZuZpSdaa92D6nByNrNcCVfOZmYJcnI2M0uPK2czswQ5OZuZJSgK7X2zVM/j5GxmueLK2cwsQVF05WxmlhxXzmZmCYpw5Wxmlpy8VM69at0BM7NqKhZUcStH0iBJ90t6WlKjpHOy+A6S5kpakv3cPotL0jWSmiQtkrRfybnGZfsvkTSuks/h5GxmuRJFVdw60QqcFxF7AMOBCZL2AC4A7ouIwcB92TrAKGBw1uqBG6AtmQMXAQcCw4CL1if0cpyczSxXqpWcI6IlIn6fLb8FLAYGAmOAqdluU4ETsuUxwLRo8yiwnaQBwLHA3IhYGRGrgLnAyM4+h5OzmeVKROVNUr2k+SWtvr1zStoF2Bd4DOgfES3ZpleA/tnyQGBZyWHLs1hH8bJ8Q9DMcqUr85wjogFoKLePpK2BW4FzI+JN6b3zR0RI2ixv93flbGa5EqGKW2ckbUFbYv5lRNyWhVdkwxVkP1/N4s3AoJLDd85iHcXLcnI2s1wpFFRxK0dtJfJkYHFE/KRk02xg/YyLccCdJfHTslkbw4E/Z8Mf9wAjJG2f3QgckcXK8rCGmeVKFR9CORj4KvCkpAVZ7PvApcAsSeOBl4BTsm1zgNFAE/AOcHpbf2KlpB8B87L9JkbEys4u7uRsZrlSrXdrRMTDQEcnO6qd/QOY0MG5pgBTunJ9J2czy5XIx5dvOzmbWb74rXRmZgkqFPMxz8HJ2cxyxcMaZmYJKvqVoWZm6fH7nM3MEuRhjQpts/Phm/sS1gMdP2D/WnfBcsrDGmZmCfJsDTOzBOVkVMPJ2czyxcMaZmYJ8mwNM7ME5eTLt52czSxfosMXyfUsTs5mliutHtYwM0uPK2czswR5zNnMLEGunM3MEuTK2cwsQQVXzmZm6cnJt1Q5OZtZvhRdOZuZpScvLz7Kx7v1zMwyxS60zkiaIulVSU+VxH4gqVnSgqyNLtn2PUlNkp6VdGxJfGQWa5J0QSWfw8nZzHKlKFXcKvALYGQ78SsjYkjW5gBI2gMYC+yZHXO9pDpJdcB1wChgD+DUbN+yPKxhZrlSqOK5IuJBSbtUuPsYYGZErAFekNQEDMu2NUXEUgBJM7N9ny53MlfOZpYrRVXeJNVLml/S6iu8zNmSFmXDHttnsYHAspJ9lmexjuJlOTmbWa4UUcUtIhoiYmhJa6jgEjcAnwSGAC3AFZvjc3hYw8xyZXPP1oiIFeuXJd0E3JWtNgODSnbdOYtRJt4hV85mlitdGdb4MCQNKFk9EVg/k2M2MFZSX0m7AoOBx4F5wGBJu0rqQ9tNw9mdXceVs5nlSjXfrSFpBnA4sKOk5cBFwOGShtBWpL8InAkQEY2SZtF2o68VmBARhew8ZwP3AHXAlIho7OzaTs5mliuFKj4gGBGnthOeXGb/ScCkduJzgDldubaTs5nlit9KZ2aWICdnM7ME5eQrBJ2czSxfXDmbmSWomo9v15KTs5nlil+2b2aWIA9rmJklyMnZzCxBefkmFCdnM8sVjzmbmSXIszXMzBJUzMnAhpOzmeWKbwiamSUoH3Wzk7OZ5YwrZzOzBLUqH7Wzk7OZ5Uo+UrOTs5nljIc1zMwS5Kl0ZmYJykdqdnI2s5zxsIaZWYIKOamdnZzNLFfyUjn3qnUHzMyqKbrwpzOSpkh6VdJTJbEdJM2VtCT7uX0Wl6RrJDVJWiRpv5JjxmX7L5E0rpLP4eRsZrlS7EKrwC+Ake+LXQDcFxGDgfuydYBRwOCs1QM3QFsyBy4CDgSGARetT+jleFijim688TJGjTqK1157nf33PwaAvffeg2uvvYR+/frS2lrgnHMuZP78hXzqU5+koeFy9t13Ly666DKuuqqhxr23zeW48cdz9NgREMFLz7zET8+/mq//6J/Z7TO7gUTLC81ce97VrH5nNSO+PJJRp42mWCiy+p3V3PC961i+ZFmtP0KPUs2pdBHxoKRd3hceAxyeLU8F/gf4bhafFhEBPCppO0kDsn3nRsRKAElzaUv4M8pd25VzFU2f/muOP/60jWKXXPJ9Jk26igMPHMXEiVdwySXfB2DVqjc477yLnJRzbof+O/DZ0z/Hd477FueO+Bd61fXikM8dys0Tf863Rp3Dt0Z+k9defo1R4z4LwEN3PsC/HvtNzht9Lnf87DZO/7fxNf4EPU90oX1I/SOiJVt+BeifLQ8ESn+TLs9iHcXLcnKuoocffpxVq97YKBYRbLvtNgB8/OPb0NKyAoDXXnudJ55YxLp1rd3eT+tedXW96NOvD73qetF3y76sXLGSd99+d8P2Pn37QrSlitJ43636VTQuahtrJSpukuolzS9p9V25VlYlb5b/SR7W2My+/e0fctdd07n00guRenHEESfWukvWjVauWMmdDXdw4yOTWbt6LQsf+gMLH1oAwNmXfZP9jhjKsqY/8ouLJ284ZuRpozn+jDH03qI3F536b7Xqeo/VlV9oEdEAdPWfryskDYiIlmzY4tUs3gwMKtlv5yzWzHvDIOvj/9PZRT505Szp9DLbNvw2KhTe/rCXyIX6+q9y/vkT2W234XznOxP52c8uq3WXrBt9bNuPMWzEgXzjkK9zxrB/ou+W/TjsxMMB+On513DGsH+iuWk5h3zu0A3H/GbaHM467EymXzqVk//lizXqec9V5RuC7ZkNrJ9xMQ64syR+WjZrYzjw52z44x5ghKTtsxuBI7JYWZsyrPHDjjZERENEDI2IoXV1W2/CJXq+r3zlJO64424Abr31LoYO3afGPbLutPchQ1ixbAVvrnyTQmuBx37zCLvvv/uG7cVikYdnP8TwUf/wgWMfnv0Qw0Yc2J3dzYUqT6WbATwCfFrScknjgUuBYyQtAY7O1gHmAEuBJuAm4CyA7Ebgj4B5WZu4/uZgOWWHNSQt6mgT7w2CWxktLSs47LDhPPjgoxxxxME0Nb1Y6y5ZN/rTy6/xqX0/TZ9+fVi7ei2fOXgfnn9yCX/zdwN45aW2e0oHHDOM5ueXAzBglwG0vNgW3//IobS8+HLN+t5TVfMhlIg4tYNNR7WzbwATOjjPFGBKV67d2Zhzf+BYYNX74gL+tysX+iiYNu1aDj30IHbccXuamh7j4ot/wllnXcDll/+A3r3rWL16DRMmtE2J7N9/J373u7vYdtutKRaLnH32ePbd9yjeeuujPQyUN0sWPMcjc37H5f91FcVCgaWNS/ntLfcwccYkttx6SyTx4uIXuPHCGwAYNe6z7H3IEArrWnn7zbe59ltX1fgT9DyFyMdNVEWZDyJpMnBzRDzczrZbIuJLnV2gX7+/zcd/Kauq0f2H1LoLlqDbXpqtTT3Hl/7uxIpzzi0v3b7J19tcylbOEdHhJMtKErOZWXfLy/RDT6Uzs1zJy4uPnJzNLFf8TShmZgnysIaZWYLyMlvDydnMcsXDGmZmCfINQTOzBHnM2cwsQR7WMDNLULmnnnsSJ2czy5WCK2czs/R4WMPMLEEe1jAzS5ArZzOzBHkqnZlZgvz4tplZgjysYWaWICdnM7MEebaGmVmCXDmbmSXIszXMzBJUiHy8NLRXrTtgZlZNEVFx64ykFyU9KWmBpPlZbAdJcyUtyX5un8Ul6RpJTZIWSdpvUz6Hk7OZ5UqRqLhV6IiIGBIRQ7P1C4D7ImIwcF+2DjAKGJy1euCGTfkcTs5mlivRhT8f0hhgarY8FTihJD4t2jwKbCdpwIe9iJOzmeVKMaLiJqle0vySVv++0wXwW0lPlGzrHxEt2fIrQP9seSCwrOTY5VnsQ/ENQTPLla5UxBHRADSU2eWQiGiW9NfAXEnPvO/4kLRZpoc4OZtZrlRztkZENGc/X5V0OzAMWCFpQES0ZMMWr2a7NwODSg7fOYt9KB7WMLNc6cqwRjmSPiZpm/XLwAjgKWA2MC7bbRxwZ7Y8Gzgtm7UxHPhzyfBHl7lyNrNcqeJDKP2B2yVBW668JSJ+I2keMEvSeOAl4JRs/znAaKAJeAc4fVMu7uRsZrnSWUVcqYhYCuzTTvx14Kh24gFMqMrFcXI2s5zx49tmZgkqRKHWXagKJ2czyxW/MtTMLEF+ZaiZWYJcOZuZJahaszVqzcnZzHLFszXMzBKUl5ftOzmbWa54zNnMLEEeczYzS5ArZzOzBHmes5lZglw5m5klyLM1zMwS5BuCZmYJ8rCGmVmC/ISgmVmCXDmbmSUoL2POystvmZ5AUn1ENNS6H5YW/72w9vSqdQc+Yupr3QFLkv9e2Ac4OZuZJcjJ2cwsQU7O3cvjitYe/72wD/ANQTOzBLlyNjNLkJOzmVmCnJy7iaSRkp6V1CTpglr3x2pP0hRJr0p6qtZ9sfQ4OXcDSXXAdcAoYA/gVEl71LZXloBfACNr3QlLk5Nz9xgGNEXE0ohYC8wExtS4T1ZjEfEgsLLW/bA0OTl3j4HAspL15VnMzKxdTs5mZglycu4ezcCgkvWds5iZWbucnLvHPGCwpF0l9QHGArNr3CczS5iTczeIiFbgbOAeYDEwKyIaa9srqzVJM4BHgE9LWi5pfK37ZOnw49tmZgly5WxmliAnZzOzBDk5m5klyMnZzCxBTs5mZglycjYzS5CTs5lZgv4PcxokTDnx4jMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + CNN, train data', np.array(train_input_labels), np.round(dev_pred,0))"
      ],
      "metadata": {
        "id": "aOF95pmvmJZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362f16ca-1aeb-47dc-b43f-ccbe929d5b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + CNN, train data: accuracy = 0.9353, precision = 0.8768, recall = 0.8215, f1 = 0.8483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO can't analyze because some texts were discarded during conversion to ids\n",
        "\n",
        "train_y = train_input_labels\n",
        "train_y_predict = np.round(dev_pred,0)"
      ],
      "metadata": {
        "id": "xt42pkNS_093"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "-omYmQGZxieV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_input_labels), np.round(test_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "7LD-s2MtyKjA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "85c94b2e-f635-44a9-dbcb-8ec9b6f92b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + CNN, test data', np.array(test_input_labels), np.round(test_pred,0))"
      ],
      "metadata": {
        "id": "dGiiWFj0yRms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7f9844-08ad-47f3-fd30-11f3c7983e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + CNN, test data: accuracy = 0.9015, precision = 0.7984, recall = 0.7586, f1 = 0.7780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM"
      ],
      "metadata": {
        "id": "JqfIxHLRPFqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                                embedding_matrix.shape[1],\n",
        "                                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False)"
      ],
      "metadata": {
        "id": "Cy47mRpm5SIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classificaiton_rnn_model(rnn_dim):\n",
        "  \"\"\"\n",
        "  max_length:         maximum input length\n",
        "  rnn_dim:            dimension of the rnn \n",
        "  return_sequences:   should the output vectors get returned?  \n",
        "  return_state:       should the final cell states get returned?\n",
        "  \"\"\"\n",
        "  \n",
        "  rnn_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
        "\n",
        "  rnn_embeddings = rnn_embedding_layer(rnn_input_layer)\n",
        "\n",
        "  # only return the last output from the RNN calculation \n",
        "  rnn_output = tf.keras.layers.LSTM(rnn_dim, return_sequences=False, return_state=False, name='LSTM')\\\n",
        "              (rnn_embeddings)\n",
        "\n",
        "  rnn_hidden = tf.keras.layers.Dense(100, activation='relu', name='rnn_hidden')(rnn_output)\n",
        "\n",
        "\n",
        "  rnn_classification = tf.keras.layers.Dense(1, \n",
        "                                            activation='sigmoid', \n",
        "                                            name='rnn_classification')(rnn_hidden)\n",
        "\n",
        "  # model definition\n",
        "\n",
        "  rnn_model = tf.keras.models.Model(inputs=rnn_input_layer, outputs=[rnn_classification])\n",
        "\n",
        "  rnn_model.compile(loss='binary_crossentropy',\n",
        "                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,\n",
        "                                                  beta_1=0.9,\n",
        "                                                  beta_2=0.999,\n",
        "                                                  epsilon=1e-07,\n",
        "                                                  amsgrad=False,\n",
        "                                                  name='Adam'),\n",
        "                  metrics='accuracy')\n",
        "    \n",
        "  return rnn_model"
      ],
      "metadata": {
        "id": "hK3YxuI8eKTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = build_classificaiton_rnn_model(rnn_dim=3)"
      ],
      "metadata": {
        "id": "OHrHxtyk4cKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_history = rnn_model.fit(train_input,\n",
        "             np.array(train_input_labels),\n",
        "             validation_data=(test_input, np.array(test_input_labels)),\n",
        "             batch_size=32,\n",
        "              epochs=5\n",
        "             )"
      ],
      "metadata": {
        "id": "-AUPvbpc6RuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc1ade8-32c5-4dd6-ae40-65f854d48c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "144/144 [==============================] - 4s 7ms/step - loss: 0.5227 - accuracy: 0.7796 - val_loss: 0.4312 - val_accuracy: 0.7733\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8473 - val_loss: 0.3079 - val_accuracy: 0.8692\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.2873 - accuracy: 0.8834 - val_loss: 0.2813 - val_accuracy: 0.8823\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.2636 - accuracy: 0.8982 - val_loss: 0.2695 - val_accuracy: 0.8893\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.2500 - accuracy: 0.9040 - val_loss: 0.2583 - val_accuracy: 0.8893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_pred = rnn_model.predict(train_input)\n",
        "test_pred = rnn_model.predict(test_input)"
      ],
      "metadata": {
        "id": "ZwSlWRFUGk0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "2kbcOSmlzXPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_input_labels), np.round(dev_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "NGhe9NTTz56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "32647dcf-0c42-4141-8d96-5e930d871584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + LSTM model, train data: ', np.array(train_input_labels), np.round(dev_pred,0))"
      ],
      "metadata": {
        "id": "V86vJljoFz78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce18169-5719-4ed2-8993-8df27a8f28c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + LSTM model, train data: : accuracy = 0.9073, precision = 0.7909, recall = 0.7870, f1 = 0.7889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "d9bCMLtwzbdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_input_labels), np.round(test_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "x0AkRHhiz9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "fd16b04d-97fd-4706-b4c7-1383032888d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('W2V + LSTM model, test data: ', np.array(test_input_labels), np.round(test_pred,0))"
      ],
      "metadata": {
        "id": "lcGDGWK3zgtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219c6e72-9264-4601-afb0-27c966a5deb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2V + LSTM model, test data: : accuracy = 0.8893, precision = 0.7519, recall = 0.7663, f1 = 0.7590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT"
      ],
      "metadata": {
        "id": "w1IBwZ6ibHQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: have to split data again after W2V?\n",
        "X, y = data['text'], data['spam']\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)"
      ],
      "metadata": {
        "id": "FbbwrxBeU4m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "rXye48IxccJx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "12683f4d190a420e94c1d20bee5c1fdf",
            "849eef67193245559c5169a150ff89f4",
            "732e4d9c8afd4549a2f1b8ed7feae694",
            "c19ab1066d924f97b2876412dd5cf355",
            "3fcec71a462e430196d681727ee74859",
            "cc0af81b4a64405c9381ea20c9aacf0c",
            "fa73d38b67e740ecb55fd4e079ae3fde",
            "fbd746a65d30482bb5c7fb73562b0444",
            "13d3e10088c146fd93bee5ebe32d9d7e",
            "8777133cb93b4f58abd7ca3b20769b58",
            "1bd0dd9e3a7545f09c1b943208c6b8c6",
            "c35cc7ea104f4894b9f0eb902cd9c19f",
            "2f3d502d012144e08901076d3d1e0c02",
            "f179587c71c848ffa553bb1a4d101bd1",
            "900ff25546f9431aad60695d0ba770f9",
            "d519574bbe57492e8f9ea18a7c20369e",
            "02e868cd55b5467cb9081cfb2e636628",
            "95468b45c9684bc39b0e8a8d07a97267",
            "5e74d61f92c44065a963beb0161247dd",
            "540afbd9d3ce42be9e67754d21ca1a5b",
            "445fabbf0067475f9bfc52159aaebdf4",
            "694e1f99f3364decb0bdd314da2ae9a1",
            "be87f999bd6e40d49685355337ea7903",
            "02439c633f624ce7bf25fa4a91be5c96",
            "b1a21c7f18374e44bfaf934d7c3bfbd2",
            "9ab6fccd077c4c57b9fda66f09bc53a4",
            "b922c98f0b944edfb60407951f30b62c",
            "a29cc29f4d2b438b9bba1a9c7f09d408",
            "8b3d5373f0b4489eb5287d1686c0f834",
            "38d9bbfb1a5b42b48f2fe21cf6606051",
            "79ee1f88080f43a381d6376797012f87",
            "a0385514add24d339372ad087c7c6579",
            "cef3cc29a7614b408becf1e3711d6baf",
            "aeca78e97c8c4a51b7d2b000590a9dd9",
            "3aa4038b35214fbaaf9d41e83ec83d17",
            "031e7750705e43c18197c8057a348f4b",
            "3b6f651f4ecf4b338b89fbdc40e72ae6",
            "06e8826c48b64f5eafcfd7dcab96e596",
            "c55efcc482e64957a621798549407d4c",
            "7f299bd5917f41ac8408702f4380cab0",
            "aee391ac35074fd292f4c3a536fa7e2f",
            "2dd98028a24b44d6bffbc55e9db537b1",
            "89aad114413b4666bd8f341d2dd10e05",
            "8c1108acae334f5c9686d75b7b9923e4"
          ]
        },
        "outputId": "700ebabc-9841-4081-bc79-6709dae46638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12683f4d190a420e94c1d20bee5c1fdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c35cc7ea104f4894b9f0eb902cd9c19f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be87f999bd6e40d49685355337ea7903"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aeca78e97c8c4a51b7d2b000590a9dd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 100                # set max_length\n",
        "\n",
        "\n",
        "all_train_examples = list(train_X)\n",
        "all_test_examples = list(test_X)\n",
        "\n",
        "\n",
        "x_train = bert_tokenizer(all_train_examples, \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train = tf.convert_to_tensor(list(train_y))\n",
        "\n",
        "x_test = bert_tokenizer(all_test_examples, \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test = tf.convert_to_tensor(list(test_y))"
      ],
      "metadata": {
        "id": "Tz3kbAVobIh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bert_pooled_model(train_layers=-1,\n",
        "                          hidden_size = 100, \n",
        "                          dropout=0.3,\n",
        "                          learning_rate=0.00005):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the Pooled Ouutput for classification purposes\n",
        "    \"\"\"\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # TO-DO: play around with restricting and not restricting BERT layers\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "\n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') #--SOLUTION--\n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    ##bert_inputs = {'input_ids': input_ids,\n",
        "    #              'token_type_ids': token_type_ids,\n",
        "    #              'attention_mask': attention_mask\n",
        "    #               }\n",
        "\n",
        "    #bert_out = bert_model([input_ids, token_type_ids, attention_mask])\n",
        "\n",
        "    \n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                   'token_type_ids': token_type_ids,\n",
        "                   'attention_mask': attention_mask}         \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    pooled_token = bert_out[1]\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(pooled_token)\n",
        "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
        "\n",
        "    \n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy') \n",
        "\n",
        "\n",
        "    \n",
        "    return classification_model"
      ],
      "metadata": {
        "id": "P38CSU4MdCuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model = create_bert_pooled_model()"
      ],
      "metadata": {
        "id": "G-EjxbRtdbjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0156c681-9652-49c8-b775-2fd55f0c4022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model_history = pooled_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=1)  "
      ],
      "metadata": {
        "id": "Z2H4_W9TddnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae633791-d71c-4308-cc6e-f1b089055541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "611/611 [==============================] - 54s 63ms/step - loss: 0.1119 - accuracy: 0.9650 - val_loss: 0.1023 - val_accuracy: 0.9771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3K2UBrszEDyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "SQvNSj_Ihzt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "tITeF3S-mNhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "ZuDpR0Db0q3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "t7sl94GmpB44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "453ad805-276a-4812-aeba-7cb61143ccf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f50737c8150>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + FCN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "id": "6DPLZ7TMq5Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5c21e6-5e94-4d7b-880f-3488f3fa2fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + FCN, train data: : accuracy = 0.9853, precision = 0.9958, recall = 0.9331, f1 = 0.9635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "GSnDZLuR0uec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "fkVzGDvO0w_X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9650db09-d50a-4c0b-bb8f-6d441cf0706d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f50737b4c10>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "AJTkYBdb0xZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca373fe-efd7-48aa-c4b9-21bac0dc0eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + FCN, test data: : accuracy = 0.9771, precision = 0.9835, recall = 0.9087, f1 = 0.9447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT Analysis"
      ],
      "metadata": {
        "id": "nvR_4nFjOZ8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_predict = train_y_predict.ravel()"
      ],
      "metadata": {
        "id": "r9GIj68vnXge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spam examples\n",
        "data['text'][data[\"spam\"] == 1]"
      ],
      "metadata": {
        "id": "jDIZfakXgsOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6901c13-a823-4ffd-9ed5-a4be821e7cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "5       FreeMsg Hey there darling it's been 3 week's n...\n",
              "8       WINNER!! As a valued network customer you have...\n",
              "9       Had your mobile 11 months or more? U R entitle...\n",
              "11      SIX chances to win CASH! From 100 to 20,000 po...\n",
              "                              ...                        \n",
              "6102    You have passed the official certification onl...\n",
              "6103    Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...\n",
              "6104    Hi, I'm a Shopee Hiring Manager and I'm curren...\n",
              "6105    4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\n",
              "Pinaka mur...\n",
              "6106    Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...\n",
              "Name: text, Length: 1280, dtype: string"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missclassified_text = train_X[train_y != train_y_predict]\n",
        "missclassified_label = train_y[train_y != train_y_predict]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'missclassified_true_label': missclassified_label})\n",
        "\n",
        "#df_report['missclassified_true_label'].value_counts()\n",
        "df_report"
      ],
      "metadata": {
        "id": "zhz2qnZqJHdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "30af5feb-28f9-4976-bea6-de6fd4b10409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  \\\n",
              "5037  You won't believe it but it's true. It's Incre...   \n",
              "1430  For sale - arsenal dartboard. Good condition b...   \n",
              "2115  Sunshine Hols. To claim ur med holiday send a ...   \n",
              "2247  Hi ya babe x u 4goten bout me?' scammers getti...   \n",
              "5770  I sexually Identify as a Gabe Newell. Ever sin...   \n",
              "...                                                 ...   \n",
              "1235  \"Hello-/@drivby-:0quit edrunk sorry iff pthis ...   \n",
              "5797  Globe: You’ve won the Netflix Mug in our Givea...   \n",
              "3574  You won't believe it but it's true. It's Incre...   \n",
              "2863  Adult 18 Content Your video will be with you s...   \n",
              "6075  My colleague who is a retired social worker wa...   \n",
              "\n",
              "      missclassified_true_label  \n",
              "5037                          1  \n",
              "1430                          1  \n",
              "2115                          1  \n",
              "2247                          1  \n",
              "5770                          1  \n",
              "...                         ...  \n",
              "1235                          0  \n",
              "5797                          1  \n",
              "3574                          1  \n",
              "2863                          1  \n",
              "6075                          1  \n",
              "\n",
              "[72 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e07d66b-55d6-4368-b4a3-11cd202543a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>missclassified_true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5037</th>\n",
              "      <td>You won't believe it but it's true. It's Incre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>For sale - arsenal dartboard. Good condition b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2115</th>\n",
              "      <td>Sunshine Hols. To claim ur med holiday send a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>Hi ya babe x u 4goten bout me?' scammers getti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5770</th>\n",
              "      <td>I sexually Identify as a Gabe Newell. Ever sin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>\"Hello-/@drivby-:0quit edrunk sorry iff pthis ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5797</th>\n",
              "      <td>Globe: You’ve won the Netflix Mug in our Givea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3574</th>\n",
              "      <td>You won't believe it but it's true. It's Incre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2863</th>\n",
              "      <td>Adult 18 Content Your video will be with you s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6075</th>\n",
              "      <td>My colleague who is a retired social worker wa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e07d66b-55d6-4368-b4a3-11cd202543a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e07d66b-55d6-4368-b4a3-11cd202543a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e07d66b-55d6-4368-b4a3-11cd202543a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_X[train_y != train_y_predict].loc[1460]"
      ],
      "metadata": {
        "id": "NS5sFIWen1xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_report.loc[2965]"
      ],
      "metadata": {
        "id": "Dg1gvY-gKQXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1652b20c-d54c-44cb-909d-a336caaf1be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "missclassified_text          Do you ever notice that when you're driving, a...\n",
              "missclassified_true_label                                                    1\n",
              "Name: 2965, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Baseline BERT observations\n",
        "-----------------------------\n",
        "\n",
        "As expected more text messages that were SPAM got classified as HAM because HAM is the majority class in our dataset.\n",
        "\n",
        "I looked at a couple examples of texts that got misclassified as HAM and they're tricky to tell if it's a ham or spam messages. The 2 examples contained generic sayings that even a human could mistakenly classify as spam.\n",
        "\n",
        "\n",
        "*Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur Soul Ur Guide And U Will Never loose in world....gnun - Sent via WAY2SMS.COM*\n",
        "\n",
        "*1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cancer. 1Lemon/Day=No Fat. 1Cup Milk/day=No Bone Problms 3 Litres Watr/Day=No Diseases Snd ths 2 Whom U Care..:-)*\n",
        "\n",
        "\n",
        "In general the misclassified messages are hard to tell for certain that they are ham or spam.\n"
      ],
      "metadata": {
        "id": "8skK76XCHeC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT + CNN"
      ],
      "metadata": {
        "id": "wcXX9CM28l71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bert_cnn_model(train_layers=-1,\n",
        "                          hidden_size = 100, \n",
        "                          learning_rate=0.00005,\n",
        "                          num_filters = [100, 100, 50, 25],\n",
        "                          kernel_sizes = [3, 5, 10, 20],\n",
        "                          dense_layer_dims = 100,\n",
        "                          dropout = 0.3):\n",
        "    \"\"\"\n",
        "    Build a  classification model with BERT, where you apply CNN layers  to the BERT output\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # TO-DO: play around with restricting and not restricting BERT layers\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "    \n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') \n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    # bert_inputs = {'input_ids': input_ids} \n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                'token_type_ids': token_type_ids,\n",
        "                'attention_mask': attention_mask}      \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    pooled_token = bert_out[0][:, 1:-1]\n",
        "\n",
        "    # CNN -----\n",
        "\n",
        "    conv_layers_for_all_kernel_sizes = []\n",
        "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "        conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(pooled_token)\n",
        "        conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "        conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
        "\n",
        "    h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
        "    #h = keras.layers.Dropout(rate=dropout)(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(dense_layer_dims, activation='relu')(h)\n",
        "    h = tf.keras.layers.Dropout(rate=dropout)(h) \n",
        "\n",
        "    # -----\n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(h)\n",
        "\n",
        "    # classification_model = tf.keras.Model(inputs=[input_ids], outputs=[classification])\n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy')\n",
        "\n",
        "\n",
        "    ### END YOUR CODE\n",
        "    \n",
        "    return classification_model"
      ],
      "metadata": {
        "id": "jKXuto0I8pNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model()\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=1)  "
      ],
      "metadata": {
        "id": "fkQ5v7lI9Ppr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a38b16-f805-49be-9582-96f9fc27223d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 56s 65ms/step - loss: 0.0688 - accuracy: 0.9785 - val_loss: 0.1104 - val_accuracy: 0.9746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "zw3v5VG0BAjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ORW4C-bR3Z_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train report"
      ],
      "metadata": {
        "id": "5Gp9o1HI2tC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "IW32_54PCpg1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b226dce7-569f-4689-8562-dbd420b5a48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fb84b2390>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "id": "msQ5VDvRCrpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee69707-56c8-46ca-d267-2249c3b38753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9834, precision = 0.9947, recall = 0.9253, f1 = 0.9587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test report"
      ],
      "metadata": {
        "id": "4OnfDJiJ3khq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "3Yvu9Rsk4Dd-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "928424f4-f021-430b-9d95-4bf4d25fecae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fb4b09990>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "2lQNG1Oz3o7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a67cae2-3cde-424e-d35d-09faab99ed58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, test data: : accuracy = 0.9746, precision = 0.9715, recall = 0.9087, f1 = 0.9391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train\n",
        "\n",
        "  - Word2Vec embeddings\n",
        "    - CNN  |  accuracy = 0.9336, precision = 0.8344, recall = 0.8700, f1 = 0.8519\n",
        "    - LSTM  |  accuracy = 0.9172, precision = 0.8217, recall = 0.7956, f1 = 0.8085\n",
        "\n",
        "  - BERT with\n",
        "    - Fully connected network  |  accuracy = 0.9873, precision = 0.9827, recall = 0.9555, f1 = 0.9689\n",
        "    - CNN  |  accuracy = 0.9865, precision = 1.0000, recall = 0.9348, f1 = 0.9663\n",
        "\n",
        "- Test\n",
        "\n",
        "  - Word2Vec embeddings\n",
        "    - W2V + CNN, test data: : accuracy = 0.8949, precision = 0.7567, recall = 0.7773, f1 = 0.7669\n",
        "    - W2V + LSTM model, test data: : accuracy = 0.8897, precision = 0.7452, recall = 0.7656, f1 = 0.7553\n",
        "\n",
        "  - BERT with\n",
        "    - BERT + FCN, test data: : accuracy = 0.9885, precision = 0.9841, recall = 0.9611, f1 = 0.9724\n",
        "    - BERT + CNN, test data: : accuracy = 0.9828, precision = 0.9958, recall = 0.9222, f1 = 0.9576\n"
      ],
      "metadata": {
        "id": "1feUh1bIDy5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuned models"
      ],
      "metadata": {
        "id": "NlfXqmUi8a3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT tuning"
      ],
      "metadata": {
        "id": "scIsHg775HLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1:** Increase the number of epochs because the training kept on improving in the first epoch and we may want to have a couple passes through the model in order to find the most optimal weights for this classification task. Also tune if freezing or unfreezing BERT layers will improve performance. I assume that unfreezing the layers may introduce too many parameters and the model will overfit. But we're expecting the number of epochs to increase performance."
      ],
      "metadata": {
        "id": "TBGWQOpC56YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model = create_bert_pooled_model()"
      ],
      "metadata": {
        "id": "sSut37Sb5ZXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe454a5-83d0-4a05-bf43-ded22d6b0bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model_history = pooled_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=3)  "
      ],
      "metadata": {
        "id": "g5xRcuyI5xJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8258373f-99f8-4b34-cc2e-eaa999e9bf22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "611/611 [==============================] - 53s 61ms/step - loss: 0.0858 - accuracy: 0.9750 - val_loss: 0.1048 - val_accuracy: 0.9763\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 34s 56ms/step - loss: 0.0391 - accuracy: 0.9894 - val_loss: 0.0605 - val_accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 34s 56ms/step - loss: 0.0536 - accuracy: 0.9853 - val_loss: 0.1682 - val_accuracy: 0.9370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "i1Zhlh2l8PWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "SmBMa6qr8VSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "_fwXVGMy8hgd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "5b4e43b4-40f9-447a-ae22-27b73f103e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f501e9af650>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "ujsahj568sx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "73d6dc68-4c7d-4543-d774-05c72a15d59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f501e9155d0>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "print_metrics('BERT 3e + FCN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "id": "8MZXVo-w82-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d319537-f87f-49db-bfe3-bb6395f99f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, train data: : accuracy = 0.9609, precision = 0.8465, recall = 0.9921, f1 = 0.9135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "print_metrics('BERT 3e + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "Qe85CHhs86_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb8996f-a04b-473e-aceb-510d41467f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, test data: : accuracy = 0.9370, precision = 0.7888, recall = 0.9658, f1 = 0.8684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "missclassified_text = train_X[train_y != train_y_predict.reshape(-1)]\n",
        "missclassified_label = train_y[train_y != train_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "id": "dOsSKjxl_-Hs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "1e4fafc4-e7e5-41bd-bbfd-6efd55cee9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "838   Sir, I have been late in paying rent for the p...           0\n",
              "3430  I don't know jack shit about anything or i'd s...           0\n",
              "4111  Yo, you gonna still be in stock tomorrow/today...           0\n",
              "4491  My computer just fried the only essential part...           0\n",
              "4529  HOW ARE U? I HAVE MISSED U! I HAVENT BEEN UP 2...           0\n",
              "...                                                 ...         ...\n",
              "323   cud u tell ppl im gona b a bit l8 cos 2 buses ...           0\n",
              "342   I take it the post has come then! You must hav...           0\n",
              "1897  I tot u outside cos darren say u come shopping...           0\n",
              "1159                   Hey! There's veggie pizza... :/\n",
              "           0\n",
              "3454  Nowadays people are notixiquating the laxinorf...           0\n",
              "\n",
              "[191 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf149ccb-0176-4f22-98b4-03d1e1900c99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>Sir, I have been late in paying rent for the p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3430</th>\n",
              "      <td>I don't know jack shit about anything or i'd s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4111</th>\n",
              "      <td>Yo, you gonna still be in stock tomorrow/today...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4491</th>\n",
              "      <td>My computer just fried the only essential part...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4529</th>\n",
              "      <td>HOW ARE U? I HAVE MISSED U! I HAVENT BEEN UP 2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>cud u tell ppl im gona b a bit l8 cos 2 buses ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>I take it the post has come then! You must hav...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>I tot u outside cos darren say u come shopping...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>Hey! There's veggie pizza... :/</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3454</th>\n",
              "      <td>Nowadays people are notixiquating the laxinorf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>191 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf149ccb-0176-4f22-98b4-03d1e1900c99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf149ccb-0176-4f22-98b4-03d1e1900c99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf149ccb-0176-4f22-98b4-03d1e1900c99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "id": "Cw3hwJzD-GIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "811a4ebc-da57-4b92-c6ee-8fd0413c1b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "4811  Honey, can you pls find out how much they sell...           0\n",
              "893   Nutter. Cutter. Ctter. Cttergg. Cttargg. Ctarg...           0\n",
              "820   \"BOO BABE! U ENJOYIN YOURJOB? U SEEMED 2 B GET...           0\n",
              "3044        Your bill at 3 is £33.65 so thats not bad!\n",
              "           0\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "...                                                 ...         ...\n",
              "4016  You will be receiving this week's Triple Echo ...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0\n",
              "3227  Rose for red,red for blood,blood for heart,hea...           0\n",
              "4456  Storming msg: Wen u lift d phne, u say \"HELLO\"...           0\n",
              "1569  Today is ACCEPT DAY..U Accept me as? Brother S...           0\n",
              "\n",
              "[77 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a39500c-2018-4a04-8e4e-9bf459038072\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4811</th>\n",
              "      <td>Honey, can you pls find out how much they sell...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>Nutter. Cutter. Ctter. Cttergg. Cttargg. Ctarg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>820</th>\n",
              "      <td>\"BOO BABE! U ENJOYIN YOURJOB? U SEEMED 2 B GET...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3044</th>\n",
              "      <td>Your bill at 3 is £33.65 so thats not bad!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4016</th>\n",
              "      <td>You will be receiving this week's Triple Echo ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3227</th>\n",
              "      <td>Rose for red,red for blood,blood for heart,hea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4456</th>\n",
              "      <td>Storming msg: Wen u lift d phne, u say \"HELLO\"...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1569</th>\n",
              "      <td>Today is ACCEPT DAY..U Accept me as? Brother S...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a39500c-2018-4a04-8e4e-9bf459038072')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a39500c-2018-4a04-8e4e-9bf459038072 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a39500c-2018-4a04-8e4e-9bf459038072');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 Results:** As expected increasing number of epochs slightly improved the f1 score and accuracy. Running it on 3 epochs seemed like a good threshold as the loss function kept decresing but the accuracy stopped improving. We're getting pretty good results with only 18 text messages that got missclassfied from the test."
      ],
      "metadata": {
        "id": "jWSfz5EA9gkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze layers\n",
        "pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)"
      ],
      "metadata": {
        "id": "BlSsZB1z7TXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf36607-a05a-4182-ec23-99e823a899e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=3) "
      ],
      "metadata": {
        "id": "7E1tsBon7nDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e934680-8ae9-4fa1-dd7f-c76a78703c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 32s 41ms/step - loss: 0.0990 - accuracy: 0.9648 - val_loss: 0.0642 - val_accuracy: 0.9804\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 23s 38ms/step - loss: 0.0329 - accuracy: 0.9916 - val_loss: 0.0472 - val_accuracy: 0.9894\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 23s 37ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 0.0601 - val_accuracy: 0.9885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "_OpcuEbyAuIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model_unfreeze.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "IsfZJw01A0jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "wENCXkfaBQQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8c001f94-e77d-4dc4-b113-44c5907ce96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4feb05f910>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ],
      "metadata": {
        "id": "4joh3aupBQwG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "61d6699a-4851-4635-9144-256e96aa1f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4ecf4faa90>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "print_metrics('BERT 3e + FCN, train data: ', np.array(train_y, int), train_y_predict)"
      ],
      "metadata": {
        "id": "WRs8lu0JA76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d200dc6d-c3a9-49db-ea45-5a5c0055956d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, train data: : accuracy = 0.9984, precision = 0.9980, recall = 0.9941, f1 = 0.9961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "print_metrics('BERT 3e + FCN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "JBB3uuD3AqUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f732c7a-bd1f-4528-8df4-eedfca080a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + FCN, test data: : accuracy = 0.9885, precision = 0.9734, recall = 0.9734, f1 = 0.9734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "id": "_F0aKI--BZ7o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "0701823a-2796-478e-8daa-ec5816a36ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "5738  Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst & eà...           1\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "718   Book which lesson? then you msg me... I will c...           0\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "5581                                                N/a           1\n",
              "2680  New Tones This week include: 1)McFly-All Ab..,...           1\n",
              "4141  Leave it wif me lar... Ü wan to carry meh so h...           0\n",
              "334   Any chance you might have had with me evaporat...           0\n",
              "4330  1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...           0\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7db4aba7-f921-4e98-b751-5c289c410b1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst &amp; eà...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>Book which lesson? then you msg me... I will c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4141</th>\n",
              "      <td>Leave it wif me lar... Ü wan to carry meh so h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>Any chance you might have had with me evaporat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4330</th>\n",
              "      <td>1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7db4aba7-f921-4e98-b751-5c289c410b1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7db4aba7-f921-4e98-b751-5c289c410b1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7db4aba7-f921-4e98-b751-5c289c410b1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 Results:** Unfreezing the BERT model layers helped with increasing the F1 score to 0.9745 on running the model for 3 epochs. The performance on the training set was excellent which may mean that we're slightly overfitting. \n",
        "\n",
        "Because the performance kept improving we may try to run on a couple more epochs to see if overfitting becomes worse and see if we will hit lower performance on the validation set."
      ],
      "metadata": {
        "id": "7l9OgX4CCA8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze layers\n",
        "pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOcZs6nZCwYq",
        "outputId": "cc097773-72db-414a-a3b1-f55ca9d23feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change to 5 epochs\n",
        "pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sSSN7ULC1es",
        "outputId": "a96ba460-ea57-46c1-c0a1-173bb781d77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 33s 42ms/step - loss: 0.0920 - accuracy: 0.9662 - val_loss: 0.0627 - val_accuracy: 0.9828\n",
            "Epoch 2/5\n",
            "611/611 [==============================] - 23s 37ms/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.0645 - val_accuracy: 0.9853\n",
            "Epoch 3/5\n",
            "611/611 [==============================] - 22s 37ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0593 - val_accuracy: 0.9861\n",
            "Epoch 4/5\n",
            "611/611 [==============================] - 22s 37ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.0706 - val_accuracy: 0.9885\n",
            "Epoch 5/5\n",
            "611/611 [==============================] - 23s 38ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.0666 - val_accuracy: 0.9877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "_EkvhANcE1R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels = pooled_bert_model_unfreeze.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "F3HqKj74EcdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "5TwzjWs8EM2w",
        "outputId": "8ebe8467-6470-47b2-c8b6-c4ff2e6bf517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "3044        Your bill at 3 is £33.65 so thats not bad!\n",
              "           0\n",
              "5667  Keep safe and let me assist you to have a CÀSH...           1\n",
              "5738  Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst & eà...           1\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "5581                                                N/a           1\n",
              "2680  New Tones This week include: 1)McFly-All Ab..,...           1\n",
              "3422  Welcome! Please reply with your AGE and GENDER...           1\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "6068  Keep safe and let me assist you to have a CÀSH...           1\n",
              "5709  Need additional funds? We process bank cashloa...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6018d12-701e-4263-906d-d71916ec1c56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3044</th>\n",
              "      <td>Your bill at 3 is £33.65 so thats not bad!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5667</th>\n",
              "      <td>Keep safe and let me assist you to have a CÀSH...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst &amp; eà...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3422</th>\n",
              "      <td>Welcome! Please reply with your AGE and GENDER...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6068</th>\n",
              "      <td>Keep safe and let me assist you to have a CÀSH...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5709</th>\n",
              "      <td>Need additional funds? We process bank cashloa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6018d12-701e-4263-906d-d71916ec1c56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6018d12-701e-4263-906d-d71916ec1c56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6018d12-701e-4263-906d-d71916ec1c56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "print_metrics('BERT 5e + FCN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "# test\n",
        "print_metrics('test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP-dGTD6ExBx",
        "outputId": "7a9ecc4a-6758-4504-950d-573750b5b0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 5e + FCN, train data: : accuracy = 0.9992, precision = 1.0000, recall = 0.9961, f1 = 0.9980\n",
            "test data: : accuracy = 0.9877, precision = 0.9844, recall = 0.9582, f1 = 0.9711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 Results:** Increasing the number of epochs to 5 has resulted in some overfitting, we see a degraded performance on the test set in F1 score and increase in the number of misclassified examples. As a result of this experiment BERT model with unfrozen layers and 3 epochs proved to produce really good results. \n",
        "\n",
        "Original untuned model test performance:\n",
        "accuracy = 0.9828, precision = 0.9797, recall = 0.9377, f1 = 0.9583\n",
        "\n",
        "\n",
        "Tuned model test performance:\n",
        "accuracy = 0.9893, precision = 0.9841, recall = 0.9650, f1 = 0.9745\n"
      ],
      "metadata": {
        "id": "MLkuzmXNFO08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT + CNN tuning"
      ],
      "metadata": {
        "id": "1CIcslSTOgOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BERT + CNN 3e un"
      ],
      "metadata": {
        "id": "ACy_uNr2M3y2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1:** Increase number of epochs and unfreeze BERT layers, not much improvement."
      ],
      "metadata": {
        "id": "rJdcEHPfQ3nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1)\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsaCz6dnPDgO",
        "outputId": "d35ce766-7665-428c-e1ae-94f4c5632ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 70s 93ms/step - loss: 0.0794 - accuracy: 0.9730 - val_loss: 0.0610 - val_accuracy: 0.9804\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 53s 87ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 54s 88ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0449 - val_accuracy: 0.9885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "TP7lfF9UQvQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdvlFabDQcSH",
        "outputId": "43c5f7e4-001f-4bf0-ad66-4bcaac0542ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9990, precision = 0.9971, recall = 0.9980, f1 = 0.9975\n",
            "BERT + CNN, test data: : accuracy = 0.9885, precision = 0.9770, recall = 0.9696, f1 = 0.9733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "EdNr3Qec3WhC",
        "outputId": "60d3712f-2374-4a33-f151-cbb0aa9b0e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "5738  Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst & eà...           1\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "718   Book which lesson? then you msg me... I will c...           0\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "5581                                                N/a           1\n",
              "2680  New Tones This week include: 1)McFly-All Ab..,...           1\n",
              "334   Any chance you might have had with me evaporat...           0\n",
              "3142                    Customer place i will call you\n",
              "           0\n",
              "6008  Daghang salamat sa suporta ug pagsalig nga iny...           1\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d044a61-64d9-4dd0-a334-0745de111ca1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst &amp; eà...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>Book which lesson? then you msg me... I will c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>Any chance you might have had with me evaporat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3142</th>\n",
              "      <td>Customer place i will call you</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6008</th>\n",
              "      <td>Daghang salamat sa suporta ug pagsalig nga iny...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d044a61-64d9-4dd0-a334-0745de111ca1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d044a61-64d9-4dd0-a334-0745de111ca1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d044a61-64d9-4dd0-a334-0745de111ca1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BERT + CNN 3e un kernel"
      ],
      "metadata": {
        "id": "rsB0IRhLM7PP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2:** Change kernel sizes, from lit review Roy et al. used the following kernel sizes. Kernel sizes improved the model. But now it overfits given that we're running it on 3 epochs."
      ],
      "metadata": {
        "id": "hPHddgjfRCcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVMinOwPPxU4",
        "outputId": "74726e70-390f-4b15-a609-e244c5658ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 78s 116ms/step - loss: 0.0880 - accuracy: 0.9675 - val_loss: 0.0518 - val_accuracy: 0.9828\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 62s 102ms/step - loss: 0.0353 - accuracy: 0.9902 - val_loss: 0.0486 - val_accuracy: 0.9877\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 62s 101ms/step - loss: 0.0229 - accuracy: 0.9939 - val_loss: 0.0537 - val_accuracy: 0.9885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ],
      "metadata": {
        "id": "JpLxOK_yRSOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics('BERT + CNN kernel, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PALsjyI1RS5a",
        "outputId": "39a4c2e0-2acf-4a0f-e2de-06ffe78dbe00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN kernel, train data: : accuracy = 0.9984, precision = 0.9951, recall = 0.9971, f1 = 0.9961\n",
            "test data: : accuracy = 0.9885, precision = 0.9698, recall = 0.9772, f1 = 0.9735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "G1Haq6M-3c1u",
        "outputId": "9bd4e75f-9e20-4754-e613-37c4954a7d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "714   Save yourself the stress. If the person has a ...           0\n",
              "1429  Tell you what, if you make a little spreadshee...           0\n",
              "5381  Somebody set up a website where you can play h...           0\n",
              "718   Book which lesson? then you msg me... I will c...           0\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...           0\n",
              "5581                                                N/a           1\n",
              "2680  New Tones This week include: 1)McFly-All Ab..,...           1\n",
              "334   Any chance you might have had with me evaporat...           0\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69a8c9e4-0dcd-41c6-b3f6-99ae36548dc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>Save yourself the stress. If the person has a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1429</th>\n",
              "      <td>Tell you what, if you make a little spreadshee...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5381</th>\n",
              "      <td>Somebody set up a website where you can play h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>Book which lesson? then you msg me... I will c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>Any chance you might have had with me evaporat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69a8c9e4-0dcd-41c6-b3f6-99ae36548dc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69a8c9e4-0dcd-41c6-b3f6-99ae36548dc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69a8c9e4-0dcd-41c6-b3f6-99ae36548dc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BERT + CNN 3e un filters"
      ],
      "metadata": {
        "id": "TM-DpiZ1NB13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 3:** Decrease the number of filters to offset overfitting and possibly increase performance"
      ],
      "metadata": {
        "id": "VnaafpFDThAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5],\n",
        "                                       num_filters = [32,64,128])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy32_mv7TMm7",
        "outputId": "f7bafaf4-153c-451d-bf73-a06ee31cbb16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "611/611 [==============================] - 36s 44ms/step - loss: 0.0822 - accuracy: 0.9722 - val_loss: 0.0984 - val_accuracy: 0.9664\n",
            "Epoch 2/3\n",
            "611/611 [==============================] - 24s 39ms/step - loss: 0.0334 - accuracy: 0.9879 - val_loss: 0.0489 - val_accuracy: 0.9885\n",
            "Epoch 3/3\n",
            "611/611 [==============================] - 24s 39ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0559 - val_accuracy: 0.9845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)\n",
        "\n",
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ],
      "metadata": {
        "id": "sVf6Q3ZBUGSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d76523-de2e-4396-d5e4-37b2c16341be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9982, precision = 1.0000, recall = 0.9912, f1 = 0.9956\n",
            "BERT + CNN, test data: : accuracy = 0.9845, precision = 0.9880, recall = 0.9392, f1 = 0.9630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HdBV-7BtXLbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation"
      ],
      "metadata": {
        "id": "_suEHlIKjKat"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BERT + FCN 5e"
      ],
      "metadata": {
        "id": "ou2wxegwJ8KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X)"
      ],
      "metadata": {
        "id": "R8k87gioltGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e88a249-19bb-4c5a-ca37-12133cd0539e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4885"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X[:977])\n",
        "len(train_X[977:1954])\n",
        "len(train_X[1954:2931])\n",
        "len(train_X[2931:3908])\n",
        "len(train_X[3908:4885])"
      ],
      "metadata": {
        "id": "ySIcuBlBk4jN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a8336b8-6871-459a-f900-4168c3b15b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "977"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first fold\n",
        "len(train_X[977:4885]) + len(train_X[:977])"
      ],
      "metadata": {
        "id": "QdRE1Ot2mer5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a8cb1e-8b6d-46c4-8057-6ae81de0f0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4885"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_val = 5\n",
        "# FOLD_SIZE = 977\n",
        "# for i in range(cross_val):\n",
        "#   test_1 = train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]\n",
        "#   test_2 = train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)]\n"
      ],
      "metadata": {
        "id": "0vdErCr6xAgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CROSS_VAL = 5\n",
        "FOLD_SIZE = 977\n",
        "\n",
        "for i in range(CROSS_VAL):\n",
        "  max_length = 100\n",
        "  #max_length = 160                  # set max_length\n",
        "\n",
        "  all_train_examples = list(train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]])\n",
        "  all_val_examples = list(train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)])\n",
        "  all_test_examples = list(test_X)\n",
        "\n",
        "  x_train = bert_tokenizer(all_train_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_train = tf.convert_to_tensor(list(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]))\n",
        "\n",
        "  x_test = bert_tokenizer(all_test_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_test = tf.convert_to_tensor(list(test_y))\n",
        "\n",
        "  x_val = bert_tokenizer(all_val_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_val = tf.convert_to_tensor(list(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)]))\n",
        "\n",
        "  # unfreeze layers\n",
        "  pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)\n",
        "\n",
        "  # change to 5 epochs\n",
        "  pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                    y_train,   \n",
        "                                                    validation_data=([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask], y_val),    \n",
        "                                                    batch_size=8, \n",
        "                                                    epochs=5) \n",
        "\n",
        "  train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "  train_y_predict = train_predict_labels.round(0)\n",
        "\n",
        "  val_predict_labels = pooled_bert_model_unfreeze.predict([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask])\n",
        "  val_y_predict = val_predict_labels.round(0)\n",
        "\n",
        "  # train\n",
        "  print_metrics('BERT 5e + FCN, train', np.array(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]], int), train_y_predict)\n",
        "  # validation\n",
        "  print_metrics('BERT 5e + FCN, validation', np.array(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)], int), val_y_predict)"
      ],
      "metadata": {
        "id": "gYyW1APYkiaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bc9048-3d93-4cae-a157-d4f5a5bed367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_9/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_9/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 28s 43ms/step - loss: 0.1203 - accuracy: 0.9555 - val_loss: 0.0339 - val_accuracy: 0.9898\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0379 - accuracy: 0.9895 - val_loss: 0.0293 - val_accuracy: 0.9898\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0320 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0464 - val_accuracy: 0.9908\n",
            "BERT 5e + FCN, train: accuracy = 0.9995, precision = 0.9988, recall = 0.9988, f1 = 0.9988\n",
            "BERT 5e + FCN, validation: accuracy = 0.9908, precision = 0.9801, recall = 0.9752, f1 = 0.9777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_10/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_10/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 28s 43ms/step - loss: 0.1042 - accuracy: 0.9662 - val_loss: 0.0396 - val_accuracy: 0.9898\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0403 - accuracy: 0.9882 - val_loss: 0.0464 - val_accuracy: 0.9877\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 18s 38ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.0307 - val_accuracy: 0.9908\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0148 - accuracy: 0.9959 - val_loss: 0.0284 - val_accuracy: 0.9949\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0420 - val_accuracy: 0.9939\n",
            "BERT 5e + FCN, train: accuracy = 0.9990, precision = 1.0000, recall = 0.9951, f1 = 0.9975\n",
            "BERT 5e + FCN, validation: accuracy = 0.9939, precision = 1.0000, recall = 0.9704, f1 = 0.9850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "489/489 [==============================] - 46s 63ms/step - loss: 0.1020 - accuracy: 0.9678 - val_loss: 0.0863 - val_accuracy: 0.9765\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0537 - accuracy: 0.9880 - val_loss: 0.1279 - val_accuracy: 0.9734\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0803 - accuracy: 0.9813 - val_loss: 0.1575 - val_accuracy: 0.9498\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0594 - accuracy: 0.9852 - val_loss: 0.1080 - val_accuracy: 0.9826\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 28s 57ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.1093 - val_accuracy: 0.9826\n",
            "BERT 5e + FCN, train: accuracy = 0.9982, precision = 0.9988, recall = 0.9926, f1 = 0.9957\n",
            "BERT 5e + FCN, validation: accuracy = 0.9826, precision = 0.9749, recall = 0.9417, f1 = 0.9580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_12/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_12/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_12/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_12/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 28s 43ms/step - loss: 0.1019 - accuracy: 0.9632 - val_loss: 0.0376 - val_accuracy: 0.9877\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0371 - accuracy: 0.9890 - val_loss: 0.0487 - val_accuracy: 0.9857\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0218 - val_accuracy: 0.9918\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 19s 38ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.0269 - val_accuracy: 0.9887\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.0348 - val_accuracy: 0.9887\n",
            "BERT 5e + FCN, train: accuracy = 0.9985, precision = 1.0000, recall = 0.9925, f1 = 0.9962\n",
            "BERT 5e + FCN, validation: accuracy = 0.9887, precision = 0.9903, recall = 0.9579, f1 = 0.9739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_13/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_13/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_13/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_13/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 29s 43ms/step - loss: 0.1030 - accuracy: 0.9632 - val_loss: 0.0342 - val_accuracy: 0.9877\n",
            "Epoch 2/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0381 - accuracy: 0.9898 - val_loss: 0.0283 - val_accuracy: 0.9898\n",
            "Epoch 3/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0304 - accuracy: 0.9910 - val_loss: 0.0266 - val_accuracy: 0.9928\n",
            "Epoch 4/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.0321 - val_accuracy: 0.9918\n",
            "Epoch 5/5\n",
            "489/489 [==============================] - 18s 37ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.0232 - val_accuracy: 0.9928\n",
            "BERT 5e + FCN, train: accuracy = 0.9967, precision = 0.9880, recall = 0.9964, f1 = 0.9922\n",
            "BERT 5e + FCN, validation: accuracy = 0.9928, precision = 0.9695, recall = 0.9948, f1 = 0.9820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy = 0.9908, precision = 0.9801, recall = 0.9752, f1 = 0.9777\n",
        "\n",
        "accuracy = 0.9939, precision = 1.0000, recall = 0.9704, f1 = 0.9850\n",
        "\n",
        "accuracy = 0.9826, precision = 0.9749, recall = 0.9417, f1 = 0.9580\n",
        "\n",
        "accuracy = 0.9887, precision = 0.9903, recall = 0.9579, f1 = 0.9739\n",
        "\n",
        "accuracy = 0.9928, precision = 0.9695, recall = 0.9948, f1 = 0.9820"
      ],
      "metadata": {
        "id": "t4hScVQZ4NAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation results\n",
        "cross_val_acc = [0.9908, 0.9939,0.9826,0.9887,0.9928]\n",
        "cross_val_precision = [0.9801, 1.0000, 0.9749, 0.9903, 0.9695]\n",
        "cross_val_recall = [0.9752, 0.9704, 0.9417, 0.9579, 0.9948]\n",
        "cross_val_f1 = [0.9777, 0.9850, 0.9580, 0.9739, 0.9820]\n",
        "\n",
        "print(\"mean accuracy\", np.mean(cross_val_acc))\n",
        "print(\"mean f1\", np.mean(cross_val_f1))\n",
        "\n",
        "print(\"st dev accuracy\", np.std(cross_val_acc))\n",
        "print(\"se dev f1\", np.std(cross_val_f1))"
      ],
      "metadata": {
        "id": "_pn9z7wQpwEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ddeb786-a27e-4f9d-e2ec-37d0774fbd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy 0.9897600000000001\n",
            "mean f1 0.97532\n",
            "st dev accuracy 0.003996298287165254\n",
            "se dev f1 0.009444448104574463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RmExkj8Z9G03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BERT + CNN 3e un kernel"
      ],
      "metadata": {
        "id": "NQCvVYYoKH-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CROSS_VAL = 5\n",
        "FOLD_SIZE = 977\n",
        "\n",
        "for i in range(CROSS_VAL):\n",
        "  max_length = 100\n",
        "  #max_length = 160                  # set max_length\n",
        "\n",
        "  all_train_examples = list(train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]])\n",
        "  all_val_examples = list(train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)])\n",
        "  all_test_examples = list(test_X)\n",
        "\n",
        "  x_train = bert_tokenizer(all_train_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_train = tf.convert_to_tensor(list(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]))\n",
        "\n",
        "  x_test = bert_tokenizer(all_test_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_test = tf.convert_to_tensor(list(test_y))\n",
        "\n",
        "  x_val = bert_tokenizer(all_val_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_val = tf.convert_to_tensor(list(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)]))\n",
        "\n",
        "  cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "  cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)\n",
        "\n",
        "\n",
        "\n",
        "  train_predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "  train_y_predict = train_predict_labels.round(0)\n",
        "\n",
        "  val_predict_labels = cnn_bert_model.predict([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask])\n",
        "  val_y_predict = val_predict_labels.round(0)\n",
        "\n",
        "  # train\n",
        "  print_metrics('BERT 3e + CNN kernel un, train', np.array(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]], int), train_y_predict)\n",
        "  # validation\n",
        "  print_metrics('validation', np.array(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)], int), val_y_predict)"
      ],
      "metadata": {
        "id": "cbUWBxG6hkCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e363664e-130e-4ece-ae83-47946252009f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_14/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_14/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_14/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_14/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_14/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_14/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_14/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_14/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_14/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 30s 47ms/step - loss: 0.0867 - accuracy: 0.9693 - val_loss: 0.0559 - val_accuracy: 0.9836\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 40ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 40ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0554 - val_accuracy: 0.9869\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9982, precision = 1.0000, recall = 0.9914, f1 = 0.9957\n",
            "validation: accuracy = 0.9918, precision = 0.9949, recall = 0.9653, f1 = 0.9799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_15/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_15/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_15/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_15/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_15/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_15/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_15/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_15/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_15/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 30s 47ms/step - loss: 0.0890 - accuracy: 0.9706 - val_loss: 0.0734 - val_accuracy: 0.9763\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0523 - val_accuracy: 0.9836\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 40ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0467 - val_accuracy: 0.9885\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9987, precision = 0.9951, recall = 0.9988, f1 = 0.9969\n",
            "validation: accuracy = 0.9939, precision = 0.9950, recall = 0.9754, f1 = 0.9851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_16/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_16/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_16/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_16/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 31s 47ms/step - loss: 0.0865 - accuracy: 0.9719 - val_loss: 0.0494 - val_accuracy: 0.9861\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0478 - val_accuracy: 0.9877\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 40ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.0633 - val_accuracy: 0.9861\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9980, precision = 1.0000, recall = 0.9901, f1 = 0.9950\n",
            "validation: accuracy = 0.9877, precision = 0.9850, recall = 0.9563, f1 = 0.9704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_17/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_17/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_17/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_17/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_17/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_17/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_17/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_17/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_17/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 31s 48ms/step - loss: 0.0985 - accuracy: 0.9660 - val_loss: 0.0484 - val_accuracy: 0.9877\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 40ms/step - loss: 0.0324 - accuracy: 0.9910 - val_loss: 0.0549 - val_accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 40ms/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.0652 - val_accuracy: 0.9877\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9990, precision = 0.9988, recall = 0.9963, f1 = 0.9975\n",
            "validation: accuracy = 0.9928, precision = 0.9905, recall = 0.9766, f1 = 0.9835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_18/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_18/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_18/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_18/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_18/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_18/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_18/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_18/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_18/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 30s 46ms/step - loss: 0.0889 - accuracy: 0.9706 - val_loss: 0.0718 - val_accuracy: 0.9812\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 40ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.0547 - val_accuracy: 0.9861\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 40ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.0577 - val_accuracy: 0.9861\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9980, precision = 1.0000, recall = 0.9903, f1 = 0.9951\n",
            "validation: accuracy = 0.9939, precision = 1.0000, recall = 0.9688, f1 = 0.9841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy = 0.9918, precision = 0.9949, recall = 0.9653, f1 = 0.9799\n",
        "\n",
        "accuracy = 0.9939, precision = 0.9950, recall = 0.9754, f1 = 0.9851\n",
        "\n",
        "accuracy = 0.9877, precision = 0.9850, recall = 0.9563, f1 = 0.9704\n",
        "\n",
        "accuracy = 0.9928, precision = 0.9905, recall = 0.9766, f1 = 0.9835\n",
        "\n",
        "accuracy = 0.9939, precision = 1.0000, recall = 0.9688, f1 = 0.9841\n"
      ],
      "metadata": {
        "id": "4ZPhvf8ozQTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation results\n",
        "cross_val_acc = [0.9918, 0.9939,0.9877,0.9928,0.9939]\n",
        "cross_val_precision = [0.9949, 0.9950,0.9850,0.9905,1.0000]\n",
        "cross_val_recall = [0.9653,0.9754,0.9563,0.9766,0.9688]\n",
        "cross_val_f1 = [0.9799, 0.9851, 0.9704, 0.9835, 0.9841]\n",
        "\n",
        "print(\"mean accuracy\", np.mean(cross_val_acc))\n",
        "print(\"mean f1\", np.mean(cross_val_f1))\n",
        "\n",
        "print(\"st dev accuracy\", np.std(cross_val_acc))\n",
        "print(\"se dev f1\", np.std(cross_val_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENs2yinEzV64",
        "outputId": "592ef23d-643b-4e67-e624-eeda3a9a7962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy 0.9920199999999999\n",
            "mean f1 0.9805999999999999\n",
            "st dev accuracy 0.002297302766289192\n",
            "se dev f1 0.005393329213018597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BERT + CNN 3e un kernel 160 len"
      ],
      "metadata": {
        "id": "LEfX4XGVKxDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CROSS_VAL = 5\n",
        "FOLD_SIZE = 977\n",
        "\n",
        "for i in range(CROSS_VAL):\n",
        "  #max_length = 100\n",
        "  max_length = 160                  # set max_length\n",
        "\n",
        "  all_train_examples = list(train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]])\n",
        "  all_val_examples = list(train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)])\n",
        "  all_test_examples = list(test_X)\n",
        "\n",
        "  x_train = bert_tokenizer(all_train_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_train = tf.convert_to_tensor(list(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]))\n",
        "\n",
        "  x_test = bert_tokenizer(all_test_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_test = tf.convert_to_tensor(list(test_y))\n",
        "\n",
        "  x_val = bert_tokenizer(all_val_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_val = tf.convert_to_tensor(list(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)]))\n",
        "\n",
        "  cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "  cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)\n",
        "\n",
        "\n",
        "\n",
        "  train_predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "  train_y_predict = train_predict_labels.round(0)\n",
        "\n",
        "  val_predict_labels = cnn_bert_model.predict([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask])\n",
        "  val_y_predict = val_predict_labels.round(0)\n",
        "\n",
        "  # train\n",
        "  print_metrics('BERT 3e + CNN kernel un 160, train', np.array(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]], int), train_y_predict)\n",
        "  # validation\n",
        "  print_metrics('validation', np.array(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)], int), val_y_predict)"
      ],
      "metadata": {
        "id": "E_niVw1piMlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff4dbb0-53d2-4c08-b364-11d26ce38437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_19/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_19/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_19/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_19/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_19/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_19/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_19/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_19/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_19/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 30s 47ms/step - loss: 0.0905 - accuracy: 0.9711 - val_loss: 0.0574 - val_accuracy: 0.9820\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.0580 - val_accuracy: 0.9861\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9995, precision = 1.0000, recall = 0.9975, f1 = 0.9988\n",
            "validation: accuracy = 0.9898, precision = 0.9800, recall = 0.9703, f1 = 0.9751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_20/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_20/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_20/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_20/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_20/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_20/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_20/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_20/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_20/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 31s 47ms/step - loss: 0.0831 - accuracy: 0.9716 - val_loss: 0.0468 - val_accuracy: 0.9885\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.0491 - val_accuracy: 0.9885\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0598 - val_accuracy: 0.9902\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9987, precision = 1.0000, recall = 0.9939, f1 = 0.9969\n",
            "validation: accuracy = 0.9939, precision = 0.9950, recall = 0.9754, f1 = 0.9851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_21/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_21/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_21/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_21/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_21/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_21/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_21/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_21/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_21/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 30s 47ms/step - loss: 0.0923 - accuracy: 0.9665 - val_loss: 0.0556 - val_accuracy: 0.9836\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0358 - accuracy: 0.9885 - val_loss: 0.0464 - val_accuracy: 0.9877\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0557 - val_accuracy: 0.9894\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9987, precision = 1.0000, recall = 0.9938, f1 = 0.9969\n",
            "validation: accuracy = 0.9877, precision = 0.9899, recall = 0.9515, f1 = 0.9703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_22/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_22/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_22/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_22/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_22/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_22/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_22/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_22/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_22/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 30s 47ms/step - loss: 0.0827 - accuracy: 0.9719 - val_loss: 0.0514 - val_accuracy: 0.9845\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 42ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0606 - val_accuracy: 0.9861\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0593 - val_accuracy: 0.9877\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9990, precision = 1.0000, recall = 0.9950, f1 = 0.9975\n",
            "validation: accuracy = 0.9908, precision = 0.9952, recall = 0.9626, f1 = 0.9786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_23/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_23/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_23/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_23/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_23/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_23/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_23/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_23/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_23/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "489/489 [==============================] - 31s 47ms/step - loss: 0.0977 - accuracy: 0.9660 - val_loss: 0.0709 - val_accuracy: 0.9828\n",
            "Epoch 2/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.0552 - val_accuracy: 0.9853\n",
            "Epoch 3/3\n",
            "489/489 [==============================] - 20s 41ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.0498 - val_accuracy: 0.9894\n",
            "BERT 3e + CNN kernel un 160, train: accuracy = 0.9987, precision = 1.0000, recall = 0.9939, f1 = 0.9970\n",
            "validation: accuracy = 0.9928, precision = 0.9843, recall = 0.9792, f1 = 0.9817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy = 0.9898, precision = 0.9800, recall = 0.9703, f1 = 0.9751\n",
        "\n",
        "accuracy = 0.9939, precision = 0.9950, recall = 0.9754, f1 = 0.9851\n",
        "\n",
        "accuracy = 0.9877, precision = 0.9899, recall = 0.9515, f1 = 0.9703\n",
        "\n",
        "accuracy = 0.9908, precision = 0.9952, recall = 0.9626, f1 = 0.9786\n",
        "\n",
        "accuracy = 0.9928, precision = 0.9843, recall = 0.9792, f1 = 0.9817"
      ],
      "metadata": {
        "id": "RuO_LeMw0oG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation results\n",
        "cross_val_acc = [0.9898,0.9939,0.9877,0.9908,0.9928]\n",
        "cross_val_precision = [0.9800, 0.9950, 0.9899, 0.9952,0.9843]\n",
        "cross_val_recall = [0.9703,0.9754,0.9515,0.9626,0.9792]\n",
        "cross_val_f1 = [0.9751, 0.9851, 0.9703, 0.9786, 0.9817]\n",
        "\n",
        "print(\"mean accuracy\", np.mean(cross_val_acc))\n",
        "print(\"mean f1\", np.mean(cross_val_f1))\n",
        "\n",
        "print(\"st dev accuracy\", np.std(cross_val_acc))\n",
        "print(\"se dev f1\", np.std(cross_val_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sPFw0Xv0Cwf",
        "outputId": "afec67d5-64a0-4148-8162-4b67cc81c1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy 0.991\n",
            "mean f1 0.9781600000000001\n",
            "st dev accuracy 0.0021918029108475927\n",
            "se dev f1 0.005138715792880537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Count unknown tokens"
      ],
      "metadata": {
        "id": "gThMPxB9_HjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for sms in data['english']:\n",
        "  if ('[UNK]' in bert_tokenizer.tokenize(sms)):\n",
        "    count += 1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "id": "mvnw49FrDD0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1f1b2f-079f-40ff-918f-9f347f4affc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for sms in data[data['crowd'] == 1]['english']:\n",
        "  if ('[UNK]' in bert_tokenizer.tokenize(sms)):\n",
        "    count += 1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "id": "jNgvXDu7_sGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7b52e0-c67d-4b7a-e875-109a3da2a8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for sms in data[data['crowd'] == 0]['english']:\n",
        "  if ('[UNK]' in bert_tokenizer.tokenize(sms)):\n",
        "    count += 1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "id": "jnpYrfDEE-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a331dcdf-68df-4053-852d-f4d19454cc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use SBERT to plot 2 datasets"
      ],
      "metadata": {
        "id": "ETPjZp03ZPgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n6gNssCaEjZf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}