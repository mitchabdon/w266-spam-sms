{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL6g1T8Jeyi1"
      },
      "source": [
        "## Table of content and model results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLV56_3nA3-"
      },
      "source": [
        "\n",
        "### UCI data alone\n",
        "\n",
        "#### Baseline\n",
        "\n",
        "W2V + CNN\n",
        "\n",
        "> train data: accuracy = 0.9646, precision = 0.8825, recall = 0.8613, f1 = 0.8718\n",
        ">\n",
        "> test data: accuracy = 0.9209, precision = 0.7619, recall = 0.7044, f1 = 0.7320\n",
        "\n",
        "W2V + LSTM model\n",
        "\n",
        "> train data: accuracy = 0.9362, precision = 0.7766, recall = 0.7620, f1 = 0.7692\n",
        ">\n",
        "> test data: accuracy = 0.9354, precision = 0.8151, recall = 0.7484, f1 = 0.7803\n",
        ">\n",
        "BERT\n",
        "\n",
        "> train data: accuracy = 0.9688, precision = 0.8240, recall = 0.9711, f1 = 0.8915\n",
        ">\n",
        "> test data: accuracy = 0.9525, precision = 0.7650, recall = 0.9623, f1 = 0.8524\n",
        "\n",
        "BERT + CNN\n",
        ">train data: : accuracy = 0.9821, precision = 0.8908, recall = 0.9847, f1 = 0.9354\n",
        ">\n",
        ">test data: : accuracy = 0.9695, precision = 0.8453, recall = 0.9623, f1 = 0.9000\n",
        "\n",
        "#### Tuned\n",
        "\n",
        "BERT 3 epochs\n",
        "\n",
        "> train data: : accuracy = 0.9879, precision = 0.9377, recall = 0.9728, f1 = 0.9549\n",
        ">\n",
        "> test data: : accuracy = 0.9803, precision = 0.9202, recall = 0.9434, f1 = 0.9317\n",
        "\n",
        "BERT 3e + FCN unfreeze\n",
        ">train data: accuracy = 0.9987, precision = 1.0000, recall = 0.9898, f1 = 0.9949\n",
        ">\n",
        ">test data: accuracy = 0.9919, precision = 0.9870, recall = 0.9560, f1 = 0.9712\n",
        "\n",
        "\n",
        "BERT 5e + FCN unfreeze, \n",
        ">train data: : accuracy = 0.9996, precision = 0.9966, recall = 1.0000, f1 = 0.9983\n",
        ">\n",
        ">test data: : accuracy = 0.9901, precision = 0.9625, recall = 0.9686, f1 = 0.9655\n",
        "\n",
        "\n",
        "BERT + CNN, \n",
        ">train data: : accuracy = 0.9960, precision = 0.9703, recall = 1.0000, f1 = 0.9849\n",
        ">\n",
        ">test data: : accuracy = 0.9874, precision = 0.9290, recall = 0.9874, f1 = 0.9573\n",
        "\n",
        "\n",
        "BERT 3e + CNN kernel\n",
        ">train data: : accuracy = 0.9991, precision = 1.0000, recall = 0.9932, f1 = 0.9966\n",
        ">\n",
        ">test data: : accuracy = 0.9928, precision = 0.9809, recall = 0.9686, f1 = 0.9747"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AitRMbM6R_23"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFMQmofaT2x_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30cdfbf-80b4-483c-a196-fd6d83f096e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gensim==3.8.3 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZepWG26Pb36a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cbbb03-3046-415b-fde5-383e37237276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 66.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 48.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBz57saHcLid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e29ebc-15db-4a17-f95f-fbf8a0b77270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow-text==2.8.2 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvPhbSW1rrdp"
      },
      "outputs": [],
      "source": [
        "# misc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)\n",
        "\n",
        "# report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# word2vec\n",
        "import nltk\n",
        "import gensim\n",
        "from nltk.data import find\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "# BERT\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from transformers import BertTokenizer, TFBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYU51GnwRSs_",
        "outputId": "1e03ac9d-f000-4471-ffb2-24c5b4030b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6oStQMXSEyO"
      },
      "source": [
        "## Load and clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrMlYjGDYkpI"
      },
      "outputs": [],
      "source": [
        "# convert labels to ints function\n",
        "def label_to_int(data):\n",
        "  data['spam'][data['spam'] == 'ham'] = 0\n",
        "  data['spam'][data['spam'] == 'spam'] = 1\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qKPfQ2pryxr"
      },
      "outputs": [],
      "source": [
        "# # read in lines because it's a txt file seprated by \\t\n",
        "# file = open(\"/content/drive/MyDrive/W266: SMS Spam Detection Final Project/data/SMSSpamCollection\", \"r\")\n",
        "# lines = file.readlines()\n",
        "# texts = []\n",
        "# for line in lines:\n",
        "#     texts.append(line.split(\"\\t\"))\n",
        "# uci_data = pd.DataFrame(data=texts, columns=[\"spam\", \"text\"])\n",
        "\n",
        "# # convert labels to ints\n",
        "# uci_data = label_to_int(uci_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-66Bp-yUtJ-M"
      },
      "outputs": [],
      "source": [
        "# preview\n",
        "# uci_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "FB3CKlGmwzCE",
        "outputId": "e285c338-205e-4b5c-e88f-c70cfa355b88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  spam                                               text  \\\n",
              "0              0     0  Go until jurong point, crazy.. Available only ...   \n",
              "1              1     0                    Ok lar... Joking wif u oni...\\n   \n",
              "2              2     1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3              3     0  U dun say so early hor... U c already then say...   \n",
              "4              4     0  Nah I don't think he goes to usf, he lives aro...   \n",
              "...          ...   ...                                                ...   \n",
              "6102        6102     1  You have passed the official certification onl...   \n",
              "6103        6103     1  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...   \n",
              "6104        6104     1  Hi, I'm a Shopee Hiring Manager and I'm curren...   \n",
              "6105        6105     1  4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...   \n",
              "6106        6106     1  Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...   \n",
              "\n",
              "      crowd                                            spanish language  \\\n",
              "0         0  Vaya hasta Jurong Point, loco ... disponible s...       en   \n",
              "1         0               Ok lar ... bromeando wif u oni ...\\n       en   \n",
              "2         0  Entrada gratuita en 2 una compensación de wkly...       en   \n",
              "3         0    No digo tan temprano hor ... ya c ya digo ...\\n       en   \n",
              "4         0  No, no creo que vaya a la USF, aunque vive por...       en   \n",
              "...     ...                                                ...      ...   \n",
              "6102      1  Ha aprobado la certificación oficial de la aud...       en   \n",
              "6103      1  ¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...       en   \n",
              "6104      1  Hola, soy un gerente de contratación de Shopee...       en   \n",
              "6105      1  ¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...      fil   \n",
              "6106      1  Sissy, solo 1p por apuesta para Cutt.ly/BingOp...      fil   \n",
              "\n",
              "                                                english  \n",
              "0     Go until jurong point, crazy.. Available only ...  \n",
              "1                       Ok lar... Joking wif u oni...\\n  \n",
              "2     Free entry in 2 a wkly comp to win FA Cup fina...  \n",
              "3     U dun say so early hor... U c already then say...  \n",
              "4     Nah I don't think he goes to usf, he lives aro...  \n",
              "...                                                 ...  \n",
              "6102  You have passed the official certification onl...  \n",
              "6103  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...  \n",
              "6104  Hi, I'm a Shopee Hiring Manager and I'm curren...  \n",
              "6105  4 pcs solar lights for only 1,499!\\nMost cheap...  \n",
              "6106  Sissy, just 1p per bet for cutt.ly/bingoplus-p...  \n",
              "\n",
              "[6107 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68e017ca-534e-4509-970a-4ec63d698c2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>spam</th>\n",
              "      <th>text</th>\n",
              "      <th>crowd</th>\n",
              "      <th>spanish</th>\n",
              "      <th>language</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Vaya hasta Jurong Point, loco ... disponible s...</td>\n",
              "      <td>en</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar ... bromeando wif u oni ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>0</td>\n",
              "      <td>Entrada gratuita en 2 una compensación de wkly...</td>\n",
              "      <td>en</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "      <td>No digo tan temprano hor ... ya c ya digo ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "      <td>No, no creo que vaya a la USF, aunque vive por...</td>\n",
              "      <td>en</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6102</th>\n",
              "      <td>6102</td>\n",
              "      <td>1</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "      <td>1</td>\n",
              "      <td>Ha aprobado la certificación oficial de la aud...</td>\n",
              "      <td>en</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6103</th>\n",
              "      <td>6103</td>\n",
              "      <td>1</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...</td>\n",
              "      <td>en</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6104</th>\n",
              "      <td>6104</td>\n",
              "      <td>1</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "      <td>1</td>\n",
              "      <td>Hola, soy un gerente de contratación de Shopee...</td>\n",
              "      <td>en</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6105</th>\n",
              "      <td>6105</td>\n",
              "      <td>1</td>\n",
              "      <td>4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...</td>\n",
              "      <td>fil</td>\n",
              "      <td>4 pcs solar lights for only 1,499!\\nMost cheap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6106</th>\n",
              "      <td>6106</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, solo 1p por apuesta para Cutt.ly/BingOp...</td>\n",
              "      <td>fil</td>\n",
              "      <td>Sissy, just 1p per bet for cutt.ly/bingoplus-p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6107 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68e017ca-534e-4509-970a-4ec63d698c2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68e017ca-534e-4509-970a-4ec63d698c2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68e017ca-534e-4509-970a-4ec63d698c2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# rename uci data to just data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/W266: SMS Spam Detection Final Project/data/data_clean_trans.csv\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47UovwLKgvce",
        "outputId": "a4c61cea-71c5-4b00-d139-c9a4e37fda69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0     Int64\n",
              "spam           Int64\n",
              "text          string\n",
              "crowd          Int64\n",
              "spanish       string\n",
              "language      string\n",
              "english       string\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data = data.convert_dtypes()\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "VpMtEUdhlSJ1",
        "outputId": "f6521c83-c5c3-4602-d24c-3d9b2b6bdaa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  spam                                               text  \\\n",
              "0              0     0  Go until jurong point, crazy.. Available only ...   \n",
              "1              1     0                     Ok lar... Joking wif u oni...\n",
              "   \n",
              "2              2     1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3              3     0  U dun say so early hor... U c already then say...   \n",
              "4              4     0  Nah I don't think he goes to usf, he lives aro...   \n",
              "...          ...   ...                                                ...   \n",
              "5569        5569     1  This is the 2nd time we have tried 2 contact u...   \n",
              "5570        5570     0              Will ü b going to esplanade fr home?\n",
              "   \n",
              "5571        5571     0  Pity, * was in mood for that. So...any other s...   \n",
              "5572        5572     0  The guy did some bitching but I acted like i'd...   \n",
              "5573        5573     0                        Rofl. Its true to its name\n",
              "   \n",
              "\n",
              "      crowd                                            spanish language  \\\n",
              "0         0  Vaya hasta Jurong Point, loco ... disponible s...       en   \n",
              "1         0                Ok lar ... bromeando wif u oni ...\n",
              "       en   \n",
              "2         0  Entrada gratuita en 2 una compensación de wkly...       en   \n",
              "3         0     No digo tan temprano hor ... ya c ya digo ...\n",
              "       en   \n",
              "4         0  No, no creo que vaya a la USF, aunque vive por...       en   \n",
              "...     ...                                                ...      ...   \n",
              "5569      0  Esta es la segunda vez que hemos probado 2 con...       en   \n",
              "5570      0                     ¿Ü B irá a Explanade Fr Home?\n",
              "       en   \n",
              "5571      0  Lástima, * estaba de humor para eso. Entonces ...       en   \n",
              "5572      0  El tipo hizo un poco de perra, pero actué como...       en   \n",
              "5573      0                         Rofl. Es fiel a su nombre\n",
              "       en   \n",
              "\n",
              "                                                english  \n",
              "0     Go until jurong point, crazy.. Available only ...  \n",
              "1                        Ok lar... Joking wif u oni...\n",
              "  \n",
              "2     Free entry in 2 a wkly comp to win FA Cup fina...  \n",
              "3     U dun say so early hor... U c already then say...  \n",
              "4     Nah I don't think he goes to usf, he lives aro...  \n",
              "...                                                 ...  \n",
              "5569  This is the 2nd time we have tried 2 contact u...  \n",
              "5570              Will ü b going to esplanade fr home?\n",
              "  \n",
              "5571  Pity, * was in mood for that. So...any other s...  \n",
              "5572  The guy did some bitching but I acted like i'd...  \n",
              "5573                        Rofl. Its true to its name\n",
              "  \n",
              "\n",
              "[5574 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2edfe5e1-9f96-413b-b3ee-7cf366645e79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>spam</th>\n",
              "      <th>text</th>\n",
              "      <th>crowd</th>\n",
              "      <th>spanish</th>\n",
              "      <th>language</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Vaya hasta Jurong Point, loco ... disponible s...</td>\n",
              "      <td>en</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar ... bromeando wif u oni ...</td>\n",
              "      <td>en</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>0</td>\n",
              "      <td>Entrada gratuita en 2 una compensación de wkly...</td>\n",
              "      <td>en</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "      <td>No digo tan temprano hor ... ya c ya digo ...</td>\n",
              "      <td>en</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "      <td>No, no creo que vaya a la USF, aunque vive por...</td>\n",
              "      <td>en</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>5569</td>\n",
              "      <td>1</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>0</td>\n",
              "      <td>Esta es la segunda vez que hemos probado 2 con...</td>\n",
              "      <td>en</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>5570</td>\n",
              "      <td>0</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "      <td>0</td>\n",
              "      <td>¿Ü B irá a Explanade Fr Home?</td>\n",
              "      <td>en</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>5571</td>\n",
              "      <td>0</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>0</td>\n",
              "      <td>Lástima, * estaba de humor para eso. Entonces ...</td>\n",
              "      <td>en</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5572</th>\n",
              "      <td>5572</td>\n",
              "      <td>0</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>0</td>\n",
              "      <td>El tipo hizo un poco de perra, pero actué como...</td>\n",
              "      <td>en</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5573</th>\n",
              "      <td>5573</td>\n",
              "      <td>0</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>0</td>\n",
              "      <td>Rofl. Es fiel a su nombre</td>\n",
              "      <td>en</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5574 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2edfe5e1-9f96-413b-b3ee-7cf366645e79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2edfe5e1-9f96-413b-b3ee-7cf366645e79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2edfe5e1-9f96-413b-b3ee-7cf366645e79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# remove crowdsourced text messages\n",
        "data = data[data['crowd'] == 0]\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RuqEtIVSOkg"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6pRHRdg8MoI",
        "outputId": "a592a8f9-97ec-4b75-f5a5-10b6c4cb6dfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "747"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "sum(data[\"spam\"] == 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKlzqlpy8u1Y",
        "outputId": "125f518e-259b-4642-a461-a2e1f1158a63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4827"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "sum(data[\"spam\"] == 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zyt8a-UOE6n"
      },
      "outputs": [],
      "source": [
        "# TO-DO: possibly implement SMOTE\n",
        "# https://fatemerhmi.github.io/files/Classification_of_imbalanced_dataset_using_BERT_embedding.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmTIZRghbCkw"
      },
      "source": [
        "## Split the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlJMJlhpVtnu"
      },
      "outputs": [],
      "source": [
        "# TO-DO: data is unbalanced we may need to fix it\n",
        "X, y = data['text'], data['spam']\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVX5ga_ODFrz"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYG1iASIDEj6"
      },
      "outputs": [],
      "source": [
        "def print_metrics(test_name, y_true, y_pred):\n",
        "    print('%s: accuracy = %.4f, precision = %.4f, recall = %.4f, f1 = %.4f'\n",
        "          % (test_name,\n",
        "             metrics.accuracy_score(y_true, y_pred),\n",
        "             metrics.precision_score(y_true, y_pred),\n",
        "             metrics.recall_score(y_true, y_pred),\n",
        "             metrics.f1_score(y_true, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0oBtsKoSTEU"
      },
      "source": [
        "## Base models\n",
        "\n",
        "- Word2Vec embeddings\n",
        "  - CNN\n",
        "  - LSTM\n",
        "\n",
        "- BERT embeddings\n",
        "  - Fully connected network\n",
        "  - CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MySc4TsBTRdT"
      },
      "source": [
        "#### Word2Vec embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BFkjykfSUQy",
        "outputId": "e1409ee3-25f4-419a-98f9-5e9c6a048bff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Unzipping models/word2vec_sample.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('word2vec_sample')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz7wtvLeXJb4"
      },
      "outputs": [],
      "source": [
        "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY2qQt3oTxpw"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJwX14iJWwvp"
      },
      "outputs": [],
      "source": [
        "# creating a Word2Vec embedding\n",
        "EMBEDDING_DIM = len(model['university'])      # we know... it's 300\n",
        "\n",
        "# initialize embedding matrix and word-to-id map:\n",
        "embedding_matrix = np.zeros((len(model.vocab.keys()) + 1, EMBEDDING_DIM))       \n",
        "vocab_dict = {}\n",
        "\n",
        "# build the embedding matrix and the word-to-id map:\n",
        "for i, word in enumerate(model.vocab.keys()):\n",
        "    embedding_vector = model[word]\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        vocab_dict[word] = i\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlQF33RqYvfP"
      },
      "outputs": [],
      "source": [
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "train_tokens = tokenizer.tokenize(train_X)\n",
        "test_tokens = tokenizer.tokenize(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SvpFHLNZVJb",
        "outputId": "ccc7b54b-6e91-4457-d87e-5b8896348739"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(22,), dtype=string, numpy=\n",
              "array([b'Double', b'mins', b'and', b'txts', b'4', b'6months', b'FREE',\n",
              "       b'Bluetooth', b'on', b'Orange.', b'Available', b'on', b'Sony,',\n",
              "       b'Nokia', b'Motorola', b'phones.', b'Call', b'MobileUpd8', b'on',\n",
              "       b'08000839402', b'or', b'call2optout/N9DX'], dtype=object)>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_tokens[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTR331lLZi8d"
      },
      "outputs": [],
      "source": [
        "# TO-DO: make sure this is tuned\n",
        "MAX_SEQUENCE_LENGTH = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohRUVRzOZmi7"
      },
      "outputs": [],
      "source": [
        "def sents_to_ids(token_list_list, label_list, num_examples=100000000):\n",
        "    \"\"\"\n",
        "    converting a list of strings to a list of lists of word ids\n",
        "    \"\"\"\n",
        "    text_ids = []\n",
        "    text_labels = []\n",
        "    example_count = 0\n",
        "    use_token_list_list = token_list_list[:num_examples]\n",
        "    for i, token_list in enumerate(use_token_list_list):\n",
        "        if i < num_examples:\n",
        "            try:\n",
        "                example = []\n",
        "                for token in list(token_list.numpy()):\n",
        "                    decoded = token.decode('utf-8').replace('.','').replace(',','').replace('!','')\n",
        "                    try:\n",
        "                        example.append(vocab_dict[decoded])\n",
        "                        \n",
        "                    except:\n",
        "                        example.append(43981)\n",
        "                if len(example) >= MAX_SEQUENCE_LENGTH:\n",
        "                    text_ids.append(example[:MAX_SEQUENCE_LENGTH])\n",
        "                    text_labels.append(label_list[i])\n",
        "                    if example_count % 5000 == 0:\n",
        "                        print('Examples processed: ', example_count)\n",
        "                    example_count += 1\n",
        "                else:\n",
        "                    pass\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    \n",
        "    print('Number of examples retained: ', example_count) \n",
        "    return (np.array(text_ids),   np.array(text_labels)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsNjF9JlZzl2"
      },
      "outputs": [],
      "source": [
        "# TO-DO: reaname\n",
        "# this is used here and in the BERT model\n",
        "y_train = tf.convert_to_tensor(list(train_y))\n",
        "y_test = tf.convert_to_tensor(list(test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJrOVPu2Zniw",
        "outputId": "555be2b6-94b5-45a5-dfe7-085c42ae1f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples processed:  0\n",
            "Number of examples retained:  4183\n",
            "Examples processed:  0\n",
            "Number of examples retained:  1037\n"
          ]
        }
      ],
      "source": [
        "train_input, train_input_labels = sents_to_ids(train_tokens, y_train)\n",
        "test_input, test_input_labels = sents_to_ids(test_tokens, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCn1BoEaPA6E"
      },
      "source": [
        "#### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hypVVE0gVWFs"
      },
      "outputs": [],
      "source": [
        "cnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                            embedding_matrix.shape[1],\n",
        "                            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ6kHgIYV4Z-"
      },
      "outputs": [],
      "source": [
        "# Specify model hyperparameters.\n",
        "epochs = 10\n",
        "num_filters = [3, 2, 1]\n",
        "kernel_sizes = [2, 4, 5]\n",
        "dense_layer_dims = [100, 30]\n",
        "dropout_rate = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3uG2-WBV_qX"
      },
      "outputs": [],
      "source": [
        "cnn_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-JgitXCWAEs"
      },
      "outputs": [],
      "source": [
        "cnn_embeddings = cnn_embedding_layer(cnn_input_layer)\n",
        "\n",
        "h = cnn_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIlpLN0GWCOv"
      },
      "outputs": [],
      "source": [
        "conv_layers_for_all_kernel_sizes = []\n",
        "for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "    conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
        "    conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "    conv_layers_for_all_kernel_sizes.append(conv_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1Nv8GblWHoz"
      },
      "outputs": [],
      "source": [
        "h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28nx55AtWJCJ"
      },
      "outputs": [],
      "source": [
        "h = keras.layers.Dropout(rate=dropout_rate)(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbUQSErWWLbj"
      },
      "outputs": [],
      "source": [
        "for dense_layer_dim in dense_layer_dims:  \n",
        "    h = keras.layers.Dense(dense_layer_dim, activation='relu')(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_RnD91QWMeO"
      },
      "outputs": [],
      "source": [
        "cnn_prediction = keras.layers.Dense(1, activation='sigmoid')(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wnq2VzMtWRv7"
      },
      "outputs": [],
      "source": [
        "cnn_model = keras.Model(inputs=cnn_input_layer, outputs=cnn_prediction)\n",
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # From information theory notebooks.\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOuRrsY_WUqs",
        "outputId": "daf4cd36-efaf-4b61-a673-4e30f575bafc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 5, 300)       13194600    ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 4, 3)         1803        ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 2, 2)         2402        ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 1, 1)         1501        ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_9 (Global  (None, 3)           0           ['conv1d_11[0][0]']              \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " global_max_pooling1d_10 (Globa  (None, 2)           0           ['conv1d_12[0][0]']              \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " global_max_pooling1d_11 (Globa  (None, 1)           0           ['conv1d_13[0][0]']              \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 6)            0           ['global_max_pooling1d_9[0][0]', \n",
            "                                                                  'global_max_pooling1d_10[0][0]',\n",
            "                                                                  'global_max_pooling1d_11[0][0]']\n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 6)            0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 100)          700         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 30)           3030        ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 1)            31          ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,204,067\n",
            "Trainable params: 9,467\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpYEf_jcWX5h",
        "outputId": "34d2f9bc-892f-4f24-ab68-58c865891541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "131/131 [==============================] - 1s 6ms/step - loss: 0.2222 - accuracy: 0.9068 - val_loss: 0.2416 - val_accuracy: 0.9122\n",
            "Epoch 2/5\n",
            "131/131 [==============================] - 1s 5ms/step - loss: 0.2097 - accuracy: 0.9154 - val_loss: 0.2395 - val_accuracy: 0.9171\n",
            "Epoch 3/5\n",
            "131/131 [==============================] - 1s 5ms/step - loss: 0.1927 - accuracy: 0.9245 - val_loss: 0.2356 - val_accuracy: 0.9132\n",
            "Epoch 4/5\n",
            "131/131 [==============================] - 1s 5ms/step - loss: 0.1901 - accuracy: 0.9252 - val_loss: 0.2388 - val_accuracy: 0.9161\n",
            "Epoch 5/5\n",
            "131/131 [==============================] - 1s 5ms/step - loss: 0.1788 - accuracy: 0.9316 - val_loss: 0.2205 - val_accuracy: 0.9209\n"
          ]
        }
      ],
      "source": [
        "cnn_history = cnn_model.fit(train_input,\n",
        "             np.array(train_input_labels),\n",
        "             validation_data=(test_input, np.array(test_input_labels)),\n",
        "             batch_size=32,\n",
        "             epochs=5\n",
        "             )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms5WvFFmxfVp"
      },
      "source": [
        "##### Train report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CaQHMQ0njBT"
      },
      "outputs": [],
      "source": [
        "dev_pred = cnn_model.predict(train_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdKTBCbhx_Zc"
      },
      "outputs": [],
      "source": [
        "test_pred = cnn_model.predict(test_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "VaVtHFQfmEWM",
        "outputId": "c50a5e50-7e85-411c-a671-9a1753598de7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TO-DO: not sure if rounding is the right way?\n",
        "\n",
        "sns.heatmap(confusion_matrix(np.array(train_input_labels), np.round(dev_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOF95pmvmJZD",
        "outputId": "6e5039fd-cc1f-461c-b45a-6a3d000de05a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W2V + CNN, train data: : accuracy = 0.9646, precision = 0.8825, recall = 0.8613, f1 = 0.8718\n"
          ]
        }
      ],
      "source": [
        "print_metrics('W2V + CNN, train data: ', np.array(train_input_labels), np.round(dev_pred,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt42pkNS_093"
      },
      "outputs": [],
      "source": [
        "# TO-DO can't analyze because some texts were discarded during conversion to ids\n",
        "\n",
        "train_y = train_input_labels\n",
        "train_y_predict = np.round(dev_pred,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-omYmQGZxieV"
      },
      "source": [
        "##### Test report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "7LD-s2MtyKjA",
        "outputId": "e2e1733e-28f6-4b5c-8512-528aecee65d4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_input_labels), np.round(test_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGiiWFj0yRms",
        "outputId": "68b4e11f-997e-4cb9-a7d4-de5f0a0e664d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W2V + CNN, test data: : accuracy = 0.9209, precision = 0.7619, recall = 0.7044, f1 = 0.7320\n"
          ]
        }
      ],
      "source": [
        "print_metrics('W2V + CNN, test data: ', np.array(test_input_labels), np.round(test_pred,0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqfIxHLRPFqv"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy47mRpm5SIV"
      },
      "outputs": [],
      "source": [
        "rnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                                embedding_matrix.shape[1],\n",
        "                                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK3YxuI8eKTx"
      },
      "outputs": [],
      "source": [
        "def build_classificaiton_rnn_model(rnn_dim):\n",
        "  \"\"\"\n",
        "  max_length:         maximum input length\n",
        "  rnn_dim:            dimension of the rnn \n",
        "  return_sequences:   should the output vectors get returned?  \n",
        "  return_state:       should the final cell states get returned?\n",
        "  \"\"\"\n",
        "  \n",
        "  rnn_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
        "\n",
        "  rnn_embeddings = rnn_embedding_layer(rnn_input_layer)\n",
        "\n",
        "  # only return the last output from the RNN calculation \n",
        "  rnn_output = tf.keras.layers.LSTM(rnn_dim, return_sequences=False, return_state=False, name='LSTM')\\\n",
        "              (rnn_embeddings)\n",
        "\n",
        "  rnn_hidden = tf.keras.layers.Dense(100, activation='relu', name='rnn_hidden')(rnn_output)\n",
        "\n",
        "\n",
        "  rnn_classification = tf.keras.layers.Dense(1, \n",
        "                                            activation='sigmoid', \n",
        "                                            name='rnn_classification')(rnn_hidden)\n",
        "\n",
        "  # model definition\n",
        "\n",
        "  rnn_model = tf.keras.models.Model(inputs=rnn_input_layer, outputs=[rnn_classification])\n",
        "\n",
        "  rnn_model.compile(loss='binary_crossentropy',\n",
        "                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,\n",
        "                                                  beta_1=0.9,\n",
        "                                                  beta_2=0.999,\n",
        "                                                  epsilon=1e-07,\n",
        "                                                  amsgrad=False,\n",
        "                                                  name='Adam'),\n",
        "                  metrics='accuracy')\n",
        "    \n",
        "  return rnn_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHrHxtyk4cKe"
      },
      "outputs": [],
      "source": [
        "rnn_model = build_classificaiton_rnn_model(rnn_dim=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AUPvbpc6RuU",
        "outputId": "874a8276-7e3b-4259-fdef-8b1143c0bf2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "131/131 [==============================] - 4s 10ms/step - loss: 0.4401 - accuracy: 0.8563 - val_loss: 0.3573 - val_accuracy: 0.8467\n",
            "Epoch 2/5\n",
            "131/131 [==============================] - 1s 5ms/step - loss: 0.3002 - accuracy: 0.8671 - val_loss: 0.2721 - val_accuracy: 0.8910\n",
            "Epoch 3/5\n",
            "131/131 [==============================] - 1s 5ms/step - loss: 0.2390 - accuracy: 0.9111 - val_loss: 0.2286 - val_accuracy: 0.9286\n",
            "Epoch 4/5\n",
            "131/131 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9242 - val_loss: 0.2065 - val_accuracy: 0.9364\n",
            "Epoch 5/5\n",
            "131/131 [==============================] - 1s 5ms/step - loss: 0.1955 - accuracy: 0.9357 - val_loss: 0.2030 - val_accuracy: 0.9354\n"
          ]
        }
      ],
      "source": [
        "rnn_history = rnn_model.fit(train_input,\n",
        "             np.array(train_input_labels),\n",
        "             validation_data=(test_input, np.array(test_input_labels)),\n",
        "             batch_size=32,\n",
        "              epochs=5\n",
        "             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwSlWRFUGk0r"
      },
      "outputs": [],
      "source": [
        "dev_pred = rnn_model.predict(train_input)\n",
        "test_pred = rnn_model.predict(test_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kbcOSmlzXPM"
      },
      "source": [
        "##### Train report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NGhe9NTTz56f",
        "outputId": "ea680f97-7c28-4148-dad4-05ba727e9d84"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_input_labels), np.round(dev_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V86vJljoFz78",
        "outputId": "cc1d3f8f-b1fc-4e65-e7bb-8ce13de17f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W2V + LSTM model, train data: : accuracy = 0.9362, precision = 0.7766, recall = 0.7620, f1 = 0.7692\n"
          ]
        }
      ],
      "source": [
        "print_metrics('W2V + LSTM model, train data: ', np.array(train_input_labels), np.round(dev_pred,0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9bCMLtwzbdv"
      },
      "source": [
        "##### Test report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "x0AkRHhiz9ac",
        "outputId": "19fc7924-28da-4d5f-ff9b-2ec7cdb85539"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_input_labels), np.round(test_pred,0)), annot=True, fmt='g');  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcGDGWK3zgtL",
        "outputId": "be4eb642-9840-4911-9484-f733ac412d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W2V + LSTM model, test data: : accuracy = 0.9354, precision = 0.8151, recall = 0.7484, f1 = 0.7803\n"
          ]
        }
      ],
      "source": [
        "print_metrics('W2V + LSTM model, test data: ', np.array(test_input_labels), np.round(test_pred,0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1IBwZ6ibHQh"
      },
      "source": [
        "#### BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "72aa9602f1fc4111a2f4370f3a5cd6c4",
            "3380740f7137429da91d072d583f6e28",
            "e214fc2b31a741c0a895fe2f63745d86",
            "60dda7bfe9fe4c5c9f0fbcd8d572c4e2",
            "b0aa6662e8a14c7fa380c178bfab05ec",
            "bd2cf02f9a7348fa83ddb4a325fd5f01",
            "03c5533f119048eab4847567772d8e06",
            "d9d7c7c60d4c4032b7d64414f91e8e67",
            "4dbd12d433c64074ac802c05ae7cab8a",
            "565832ee669445558191d878390a116c",
            "17086c6a0f1a45ccad9883be90d55f7c",
            "98e654930b4b425292bfd7ade8d5b0f0",
            "e1b7a7c548d24c71bb8aeac88fc210dd",
            "1dd1de7a2bcf402e864d0723f3c318dd",
            "13352a21c9624704874f4ca2a76cca00",
            "09c58eeda1fd443cac48cd1e99c3b1dc",
            "bbccaf3a19e14cad91eeb04855ff69cd",
            "7d3c5038064b4f829cca8b8bcf67600e",
            "4afac3b1b08b4faa8ebd9f4ca366a824",
            "20cee5c9cbaf4e0685add696e31a5a8c",
            "fef7ed115d644605b62357d0ab454368",
            "9e58bc2b8c7c4bcd94c560b9daaa9ddc",
            "721128853fc74edba61276522807272f",
            "e6bc4b25770047f298037f5584a24095",
            "ec0aaa1a8b9746758f49e397ae4288c4",
            "3a78ec5f622a499499ebc6c72a9316f1",
            "a04e5ad4615a4d55b661d60be4637690",
            "e6eacf4631484979b512665c5a13ba96",
            "2fff2bd4dae24af793d3cb4bb30a38cb",
            "249a2a9483864f499eaff52be920bbad",
            "3c55417ea7f841ccb45912ded0e54eb3",
            "7d4188faa5654ca98a296df6c561d07c",
            "e8fc1e9d63c944e39fb76bf0ebdfa28e",
            "5d79935c0c6e4ef496eca79a4941af4d",
            "e84330ae695a46de99ccec3177deed4c",
            "07b3251799fb46b89488693c6d76368e",
            "6229e18cc5cb4fee868da38698cad140",
            "c9b2872b41354420b19a97b9ec44ea59",
            "95dd35e71ff646b99e09f672d8ced572",
            "2f16a1d21074403981b09b38b56d7cac",
            "33d9f7184e2844929bfd2d6e612841e3",
            "28a509de4a804cca93c5b1392d3aa644",
            "518060ca3beb4750886a47badf0c93b6",
            "b7b24797ccd44bfe904b9dbb44923bc0"
          ]
        },
        "id": "rXye48IxccJx",
        "outputId": "026c380f-b48c-451a-ea9a-aca322c03814"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72aa9602f1fc4111a2f4370f3a5cd6c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98e654930b4b425292bfd7ade8d5b0f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "721128853fc74edba61276522807272f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d79935c0c6e4ef496eca79a4941af4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz3kbAVobIh7"
      },
      "outputs": [],
      "source": [
        "max_length = 100              # set max_length\n",
        "\n",
        "\n",
        "all_train_examples = list(train_X)\n",
        "all_test_examples = list(test_X)\n",
        "\n",
        "\n",
        "x_train = bert_tokenizer(all_train_examples, \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train = tf.convert_to_tensor(list(train_y))\n",
        "\n",
        "x_test = bert_tokenizer(all_test_examples, \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test = tf.convert_to_tensor(list(test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P38CSU4MdCuk"
      },
      "outputs": [],
      "source": [
        "def create_bert_pooled_model(train_layers=-1,\n",
        "                          hidden_size = 100, \n",
        "                          dropout=0.3,\n",
        "                          learning_rate=0.00005):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the Pooled Ouutput for classification purposes\n",
        "    \"\"\"\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # TO-DO: play around with restricting and not restricting BERT layers\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "\n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') #--SOLUTION--\n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    ##bert_inputs = {'input_ids': input_ids,\n",
        "    #              'token_type_ids': token_type_ids,\n",
        "    #              'attention_mask': attention_mask\n",
        "    #               }\n",
        "\n",
        "    #bert_out = bert_model([input_ids, token_type_ids, attention_mask])\n",
        "\n",
        "    \n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                   'token_type_ids': token_type_ids,\n",
        "                   'attention_mask': attention_mask}         \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    pooled_token = bert_out[1]\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(pooled_token)\n",
        "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
        "\n",
        "    \n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy') \n",
        "\n",
        "\n",
        "    \n",
        "    return classification_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-EjxbRtdbjc",
        "outputId": "298b0bb5-40bd-4606-b316-33b652d1a345"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "pooled_bert_model = create_bert_pooled_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2H4_W9TddnM",
        "outputId": "f80bbae2-36bf-4091-bd72-ddaef537729d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "558/558 [==============================] - 131s 205ms/step - loss: 0.1463 - accuracy: 0.9507 - val_loss: 0.1338 - val_accuracy: 0.9525\n"
          ]
        }
      ],
      "source": [
        "pooled_bert_model_history = pooled_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=1)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K2UBrszEDyP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQvNSj_Ihzt6"
      },
      "outputs": [],
      "source": [
        "train_predict_labels = pooled_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tITeF3S-mNhh"
      },
      "outputs": [],
      "source": [
        "test_predict_labels = pooled_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuDpR0Db0q3r"
      },
      "source": [
        "##### Train report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "t7sl94GmpB44",
        "outputId": "4c245a32-e6be-4179-86eb-d79aad4b59b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f422c159950>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DPLZ7TMq5Ci",
        "outputId": "df7fe36b-75f8-40a2-8bfa-c1aada5d1a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT + FCN, train data: : accuracy = 0.9688, precision = 0.8240, recall = 0.9711, f1 = 0.8915\n"
          ]
        }
      ],
      "source": [
        "print_metrics('BERT + FCN, train data', np.array(train_y, int), train_y_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSnDZLuR0uec"
      },
      "source": [
        "##### Test report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "fkVzGDvO0w_X",
        "outputId": "34e47922-ce1d-43a7-8d99-f2bc371a2f27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f421aa39910>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJTkYBdb0xZ4",
        "outputId": "53b585e4-d2ae-467e-e975-05e12b0e83b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT + FCN, test data: : accuracy = 0.9525, precision = 0.7650, recall = 0.9623, f1 = 0.8524\n"
          ]
        }
      ],
      "source": [
        "print_metrics('BERT + FCN, test data', np.array(test_y, int), test_y_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvR_4nFjOZ8W"
      },
      "source": [
        "#### BERT Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9GIj68vnXge"
      },
      "outputs": [],
      "source": [
        "train_y_predict = train_y_predict.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDIZfakXgsOC",
        "outputId": "264e6301-e5a6-40a2-c25e-98e3682fce12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "5       FreeMsg Hey there darling it's been 3 week's n...\n",
              "8       WINNER!! As a valued network customer you have...\n",
              "9       Had your mobile 11 months or more? U R entitle...\n",
              "11      SIX chances to win CASH! From 100 to 20,000 po...\n",
              "                              ...                        \n",
              "6091    Install, Play, CA$H Out! Easy Game, Easy Win! ...\n",
              "6092    Y0U  SELECTED AS A F U/L L-T I/-M E EMPLOYEE W...\n",
              "6093    Payday Promo!\n",
              "40p is credited to your account ...\n",
              "6094    Hello, you have received a sal a ry of 2787, y...\n",
              "6095    Dear, please accept J.0B 0ffers from your frie...\n",
              "Name: text, Length: 1269, dtype: string"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# spam examples\n",
        "data['text'][data[\"spam\"] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zhz2qnZqJHdX",
        "outputId": "08b5b0fa-8541-45df-964b-652afcb8926e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-13094d5d-305e-430b-affc-782c9e4db323\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>missclassified_true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4330</th>\n",
              "      <td>1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5771</th>\n",
              "      <td>My Grandfather smoked his whole life. I was ab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>Message:some text missing* Sender:Name Missing...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4200</th>\n",
              "      <td>cmon babe, make me horny, *turn* me on! Txt me...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1353</th>\n",
              "      <td>Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur S...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4949</th>\n",
              "      <td>Hi this is Amy, we will be sending you a free ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3824</th>\n",
              "      <td>Please protect yourself from e-threats. SIB ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4659</th>\n",
              "      <td>This message is from a great Doctor in India:-...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>Do you ever notice that when you're driving, a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5758</th>\n",
              "      <td>Register reward, log in to reward, rotation re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4729</th>\n",
              "      <td>I (Career Tel) have added u as a contact on IN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5955</th>\n",
              "      <td>Imagine a life without worry.\n",
              "Play for Fun? Pl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5769</th>\n",
              "      <td>Excuse me? I find vaping to be one of the best...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst &amp; eà...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Did you hear about the new \"Divorce Barbie\"? I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5791</th>\n",
              "      <td>,,need low % for Money this time..im willing t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>Will u meet ur dream partner soon? Is ur caree...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5839</th>\n",
              "      <td>Play and earn ~ registration rewards, sign-in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4650</th>\n",
              "      <td>Please protect yourself from e-threats. SIB ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4069</th>\n",
              "      <td>TBS/PERSOLVO. been chasing us since Sept for£3...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5768</th>\n",
              "      <td>Come on in, feel free to do some looking.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5687</th>\n",
              "      <td>Huwag sayangin ang boto. Dito na sa sigurado. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>Filthy stories and GIRLS waiting for your</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1875</th>\n",
              "      <td>Would you like to see my XXX pics they are so ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3419</th>\n",
              "      <td>LIFE has never been this much fun and great un...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>Do you realize that in about 40 years, we'll h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>Bought one ringtone and now getting texts cost...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4473</th>\n",
              "      <td>3. You have received your mobile content. Enjoy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>Hi, Mobile no.  &amp;lt;#&amp;gt;  has added you in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2402</th>\n",
              "      <td>Babe: U want me dont u baby! Im nasty and have...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5046</th>\n",
              "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5451</th>\n",
              "      <td>Latest News! Police station toilet stolen, cop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Are you unique enough? Find out from 30th Augu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2863</th>\n",
              "      <td>Adult 18 Content Your video will be with you s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13094d5d-305e-430b-affc-782c9e4db323')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13094d5d-305e-430b-affc-782c9e4db323 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13094d5d-305e-430b-affc-782c9e4db323');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    missclassified_text  \\\n",
              "4330  1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...   \n",
              "5771  My Grandfather smoked his whole life. I was ab...   \n",
              "410   Message:some text missing* Sender:Name Missing...   \n",
              "4200  cmon babe, make me horny, *turn* me on! Txt me...   \n",
              "1353  Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur S...   \n",
              "2774  How come it takes so little time for a child w...   \n",
              "4949  Hi this is Amy, we will be sending you a free ...   \n",
              "3824  Please protect yourself from e-threats. SIB ne...   \n",
              "4659  This message is from a great Doctor in India:-...   \n",
              "2965  Do you ever notice that when you're driving, a...   \n",
              "5372  dating:i have had two of these. Only started a...   \n",
              "5758  Register reward, log in to reward, rotation re...   \n",
              "4729  I (Career Tel) have added u as a contact on IN...   \n",
              "5955  Imagine a life without worry.\n",
              "Play for Fun? Pl...   \n",
              "5769  Excuse me? I find vaping to be one of the best...   \n",
              "5738  Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst & eà...   \n",
              "68    Did you hear about the new \"Divorce Barbie\"? I...   \n",
              "5791  ,,need low % for Money this time..im willing t...   \n",
              "227   Will u meet ur dream partner soon? Is ur caree...   \n",
              "5839  Play and earn ~ registration rewards, sign-in ...   \n",
              "5     FreeMsg Hey there darling it's been 3 week's n...   \n",
              "4650  Please protect yourself from e-threats. SIB ne...   \n",
              "4069  TBS/PERSOLVO. been chasing us since Sept for£3...   \n",
              "5768          Come on in, feel free to do some looking.   \n",
              "5687  Huwag sayangin ang boto. Dito na sa sigurado. ...   \n",
              "955          Filthy stories and GIRLS waiting for your\n",
              "   \n",
              "1875  Would you like to see my XXX pics they are so ...   \n",
              "3419  LIFE has never been this much fun and great un...   \n",
              "751   Do you realize that in about 40 years, we'll h...   \n",
              "1460  Bought one ringtone and now getting texts cost...   \n",
              "4473   3. You have received your mobile content. Enjoy\n",
              "   \n",
              "2379  Hi, Mobile no.  &lt;#&gt;  has added you in th...   \n",
              "2402  Babe: U want me dont u baby! Im nasty and have...   \n",
              "869   Hello. We need some posh birds and chaps to us...   \n",
              "5046  We have sent JD for Customer Service cum Accou...   \n",
              "5451  Latest News! Police station toilet stolen, cop...   \n",
              "191   Are you unique enough? Find out from 30th Augu...   \n",
              "2863  Adult 18 Content Your video will be with you s...   \n",
              "\n",
              "      missclassified_true_label  \n",
              "4330                          0  \n",
              "5771                          1  \n",
              "410                           0  \n",
              "4200                          1  \n",
              "1353                          0  \n",
              "2774                          1  \n",
              "4949                          1  \n",
              "3824                          0  \n",
              "4659                          0  \n",
              "2965                          1  \n",
              "5372                          1  \n",
              "5758                          1  \n",
              "4729                          0  \n",
              "5955                          1  \n",
              "5769                          1  \n",
              "5738                          1  \n",
              "68                            1  \n",
              "5791                          1  \n",
              "227                           1  \n",
              "5839                          1  \n",
              "5                             1  \n",
              "4650                          0  \n",
              "4069                          1  \n",
              "5768                          1  \n",
              "5687                          1  \n",
              "955                           1  \n",
              "1875                          1  \n",
              "3419                          1  \n",
              "751                           1  \n",
              "1460                          1  \n",
              "4473                          1  \n",
              "2379                          0  \n",
              "2402                          1  \n",
              "869                           1  \n",
              "5046                          0  \n",
              "5451                          1  \n",
              "191                           1  \n",
              "2863                          1  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "missclassified_text = train_X[train_y != train_y_predict]\n",
        "missclassified_label = train_y[train_y != train_y_predict]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'missclassified_true_label': missclassified_label})\n",
        "\n",
        "#df_report['missclassified_true_label'].value_counts()\n",
        "df_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NS5sFIWen1xA",
        "outputId": "f6b2b36e-2c65-446f-c9ff-4445e85e4436"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bought one ringtone and now getting texts costing 3 pound offering more tones etc\\n'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X[train_y != train_y_predict].loc[1460]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg1gvY-gKQXr",
        "outputId": "f99cfd4a-dc63-4d24-ee0d-def433414b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "missclassified_text          Do you ever notice that when you're driving, a...\n",
              "missclassified_true_label                                                    1\n",
              "Name: 2965, dtype: object"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_report.loc[2965]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6sAdIAZhqbu"
      },
      "outputs": [],
      "source": [
        "# TO-DO: Run models on just the UCI dataset to understand results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8skK76XCHeC-"
      },
      "source": [
        "##### Baseline BERT observations\n",
        "-----------------------------\n",
        "\n",
        "As expected more text messages that were SPAM got classified as HAM because HAM is the majority class in our dataset.\n",
        "\n",
        "I looked at a couple examples of texts that got misclassified as HAM and they're tricky to tell if it's a ham or spam messages. The 2 examples contained generic sayings that even a human could mistakenly classify as spam.\n",
        "\n",
        "\n",
        "*Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur Soul Ur Guide And U Will Never loose in world....gnun - Sent via WAY2SMS.COM*\n",
        "\n",
        "*1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cancer. 1Lemon/Day=No Fat. 1Cup Milk/day=No Bone Problms 3 Litres Watr/Day=No Diseases Snd ths 2 Whom U Care..:-)*\n",
        "\n",
        "\n",
        "In general the misclassified messages are hard to tell for certain that they are ham or spam.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcXX9CM28l71"
      },
      "source": [
        "#### BERT + CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKXuto0I8pNY"
      },
      "outputs": [],
      "source": [
        "def create_bert_cnn_model(train_layers=-1,\n",
        "                          hidden_size = 100, \n",
        "                          learning_rate=0.00005,\n",
        "                          num_filters = [100, 100, 50, 25],\n",
        "                          kernel_sizes = [3, 5, 10, 20],\n",
        "                          dense_layer_dims = 100,\n",
        "                          dropout = 0.3):\n",
        "    \"\"\"\n",
        "    Build a  classification model with BERT, where you apply CNN layers  to the BERT output\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # TO-DO: play around with restricting and not restricting BERT layers\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "    \n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') \n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    # bert_inputs = {'input_ids': input_ids} \n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                'token_type_ids': token_type_ids,\n",
        "                'attention_mask': attention_mask}      \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    pooled_token = bert_out[0][:, 1:-1]\n",
        "\n",
        "    # CNN -----\n",
        "\n",
        "    conv_layers_for_all_kernel_sizes = []\n",
        "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "        conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(pooled_token)\n",
        "        conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "        conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
        "\n",
        "    h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
        "    #h = keras.layers.Dropout(rate=dropout)(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(dense_layer_dims, activation='relu')(h)\n",
        "    h = tf.keras.layers.Dropout(rate=dropout)(h) \n",
        "\n",
        "    # -----\n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(h)\n",
        "\n",
        "    # classification_model = tf.keras.Model(inputs=[input_ids], outputs=[classification])\n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy')\n",
        "\n",
        "\n",
        "    ### END YOUR CODE\n",
        "    \n",
        "    return classification_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkQ5v7lI9Ppr",
        "outputId": "d4966e4e-97d1-4665-b35f-b521e8c1cda8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "558/558 [==============================] - 165s 225ms/step - loss: 0.0781 - accuracy: 0.9785 - val_loss: 0.1563 - val_accuracy: 0.9695\n"
          ]
        }
      ],
      "source": [
        "cnn_bert_model = create_bert_cnn_model()\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=1)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw3v5VG0BAjT"
      },
      "outputs": [],
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORW4C-bR3Z_v"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gp9o1HI2tC1"
      },
      "source": [
        "##### Train report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "IW32_54PCpg1",
        "outputId": "0bd1c6e0-f2ed-4f0b-a39a-23c42d50f1a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4198c747d0>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msQ5VDvRCrpQ",
        "outputId": "a09c5228-ce35-4186-94c7-65dea74ae224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9821, precision = 0.8908, recall = 0.9847, f1 = 0.9354\n"
          ]
        }
      ],
      "source": [
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OnfDJiJ3khq"
      },
      "source": [
        "##### Test report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "3Yvu9Rsk4Dd-",
        "outputId": "c0df302b-177a-41c0-a76f-3daeabcc179f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4198be6e90>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lQNG1Oz3o7M",
        "outputId": "e8dddd24-02d1-421d-b160-b9e649d44509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT + CNN, test data: : accuracy = 0.9695, precision = 0.8453, recall = 0.9623, f1 = 0.9000\n"
          ]
        }
      ],
      "source": [
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlfXqmUi8a3I"
      },
      "source": [
        "## Tuned models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scIsHg775HLa"
      },
      "source": [
        "#### BERT tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBGWQOpC56YA"
      },
      "source": [
        "**Experiment 1:** Increase the number of epochs because the training kept on improving in the first epoch and we may want to have a couple passes through the model in order to find the most optimal weights for this classification task. Also tune if freezing or unfreezing BERT layers will improve performance. I assume that unfreezing the layers may introduce too many parameters and the model will overfit. But we're expecting the number of epochs to increase performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSut37Sb5ZXj",
        "outputId": "ea0b7b98-ea00-43d9-9314-acf9232617b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "pooled_bert_model = create_bert_pooled_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5xRcuyI5xJY",
        "outputId": "4eaeca10-1140-4c67-f7a1-9ce2f825ab9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "558/558 [==============================] - 142s 210ms/step - loss: 0.0778 - accuracy: 0.9771 - val_loss: 0.0555 - val_accuracy: 0.9865\n",
            "Epoch 2/3\n",
            "558/558 [==============================] - 114s 204ms/step - loss: 0.0535 - accuracy: 0.9877 - val_loss: 0.0609 - val_accuracy: 0.9910\n",
            "Epoch 3/3\n",
            "558/558 [==============================] - 114s 204ms/step - loss: 0.0645 - accuracy: 0.9852 - val_loss: 0.0954 - val_accuracy: 0.9803\n"
          ]
        }
      ],
      "source": [
        "pooled_bert_model_history = pooled_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=3)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1Zhlh2l8PWl"
      },
      "outputs": [],
      "source": [
        "train_predict_labels = pooled_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmBMa6qr8VSY"
      },
      "outputs": [],
      "source": [
        "test_predict_labels = pooled_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_fwXVGMy8hgd",
        "outputId": "fdb83041-043c-4ee6-dfa1-1c4e0fc68dbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f41109fc050>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# train\n",
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ujsahj568sx0",
        "outputId": "1f751864-75e3-446d-a9a8-0d38606515de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f411099b7d0>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# test\n",
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MZXVo-w82-X",
        "outputId": "451e1c94-3050-43f9-bbf4-e20bc3754778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT 3e + FCN, train data: : accuracy = 0.9879, precision = 0.9377, recall = 0.9728, f1 = 0.9549\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "print_metrics('BERT 3e + FCN, train data', np.array(train_y, int), train_y_predict)\n",
        "# test\n",
        "print_metrics('BERT 3e + FCN, test data', np.array(test_y, int), test_y_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe85CHhs86_7",
        "outputId": "bf0c92a5-452a-4caa-afcb-3d52be71d685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT 3e + FCN, test data: : accuracy = 0.9803, precision = 0.9202, recall = 0.9434, f1 = 0.9317\n"
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "dOsSKjxl_-Hs",
        "outputId": "4a76fd43-beb8-4e9a-a265-d2f61628f07f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-675b23d4-af22-4fc7-b169-e405871672be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5771</th>\n",
              "      <td>My Grandfather smoked his whole life. I was ab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4141</th>\n",
              "      <td>Leave it wif me lar... Ü wan to carry meh so h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4949</th>\n",
              "      <td>Hi this is Amy, we will be sending you a free ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>URGENT, IMPORTANT INFORMATION FOR O2 USER. TOD...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4394</th>\n",
              "      <td>RECPT 1/3. You have ordered a Ringtone. Your o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>dating:i have had two of these. Only started a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2692</th>\n",
              "      <td>Hey tmr meet at bugis 930 ?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Did you hear about the new \"Divorce Barbie\"? I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>I only haf msn. It's yijue@hotmail.com</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5768</th>\n",
              "      <td>Come on in, feel free to do some looking.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-675b23d4-af22-4fc7-b169-e405871672be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-675b23d4-af22-4fc7-b169-e405871672be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-675b23d4-af22-4fc7-b169-e405871672be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "5771  My Grandfather smoked his whole life. I was ab...           1\n",
              "4141  Leave it wif me lar... Ü wan to carry meh so h...           0\n",
              "4949  Hi this is Amy, we will be sending you a free ...           1\n",
              "1407  URGENT, IMPORTANT INFORMATION FOR O2 USER. TOD...           1\n",
              "4394  RECPT 1/3. You have ordered a Ringtone. Your o...           1\n",
              "5372  dating:i have had two of these. Only started a...           1\n",
              "2692                       Hey tmr meet at bugis 930 ?\n",
              "           0\n",
              "68    Did you hear about the new \"Divorce Barbie\"? I...           1\n",
              "136             I only haf msn. It's yijue@hotmail.com\n",
              "           0\n",
              "5768          Come on in, feel free to do some looking.           1\n",
              "869   Hello. We need some posh birds and chaps to us...           1"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train\n",
        "missclassified_text = train_X[train_y != train_y_predict.reshape(-1)]\n",
        "missclassified_label = train_y[train_y != train_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "Cw3hwJzD-GIl",
        "outputId": "0c50d115-12e1-4275-9bbe-be7ca9cfc0f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a41056ee-5033-400f-82d0-5c2fd484e98d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>missclassified_true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5931</th>\n",
              "      <td>Register a bonus, invite bonuses, and receive ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5767</th>\n",
              "      <td>Stay a while 'cause somethings always cooking.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5963</th>\n",
              "      <td>Download to get an exclusive bonus, the super ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>Book which lesson? then you msg me... I will c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3864</th>\n",
              "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991</th>\n",
              "      <td>(Bank of Granite issues Strong-Buy) EXPLOSIVE ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2823</th>\n",
              "      <td>ROMCAPspam Everyone around should be respondin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5773</th>\n",
              "      <td>Budget for all your needs, type yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1638</th>\n",
              "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>Hi ya babe x u 4goten bout me?' scammers getti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4249</th>\n",
              "      <td>accordingly. I repeat, just text the word ok o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>For sale - arsenal dartboard. Good condition b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4016</th>\n",
              "      <td>You will be receiving this week's Triple Echo ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a41056ee-5033-400f-82d0-5c2fd484e98d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a41056ee-5033-400f-82d0-5c2fd484e98d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a41056ee-5033-400f-82d0-5c2fd484e98d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    missclassified_text  \\\n",
              "5931  Register a bonus, invite bonuses, and receive ...   \n",
              "5767     Stay a while 'cause somethings always cooking.   \n",
              "989   Yun ah.the ubi one say if ü wan call by tomorr...   \n",
              "5581                                                N/a   \n",
              "5963  Download to get an exclusive bonus, the super ...   \n",
              "718   Book which lesson? then you msg me... I will c...   \n",
              "4298  thesmszone.com lets you send free anonymous an...   \n",
              "3864  Oh my god! I've found your number again! I'm s...   \n",
              "3991  (Bank of Granite issues Strong-Buy) EXPLOSIVE ...   \n",
              "2823  ROMCAPspam Everyone around should be respondin...   \n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...   \n",
              "2663  Hello darling how are you today? I would love ...   \n",
              "5773               Budget for all your needs, type yes    \n",
              "1638  0A$NETWORKS allow companies to bill for SMS, s...   \n",
              "2247  Hi ya babe x u 4goten bout me?' scammers getti...   \n",
              "4249  accordingly. I repeat, just text the word ok o...   \n",
              "1430  For sale - arsenal dartboard. Good condition b...   \n",
              "4016  You will be receiving this week's Triple Echo ...   \n",
              "\n",
              "      missclassified_true_label  \n",
              "5931                          1  \n",
              "5767                          1  \n",
              "989                           0  \n",
              "5581                          1  \n",
              "5963                          1  \n",
              "718                           0  \n",
              "4298                          1  \n",
              "3864                          1  \n",
              "3991                          1  \n",
              "2823                          1  \n",
              "263                           0  \n",
              "2663                          1  \n",
              "5773                          1  \n",
              "1638                          1  \n",
              "2247                          1  \n",
              "4249                          1  \n",
              "1430                          1  \n",
              "4016                          1  "
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWSfz5EA9gkW"
      },
      "source": [
        "**Experiment 1 Results:** As expected increasing number of epochs slightly improved the f1 score and accuracy. Running it on 3 epochs seemed like a good threshold as the loss function kept decresing but the accuracy stopped improving. We're getting pretty good results with only 18 text messages that got missclassfied from the test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlSsZB1z7TXY",
        "outputId": "c0fcba81-1ee2-4d3d-bccb-92abce59ae8e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# unfreeze layers\n",
        "pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E1tsBon7nDo",
        "outputId": "90c34194-9aa7-4a24-f036-7e710f60b1f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "558/558 [==============================] - 75s 110ms/step - loss: 0.0925 - accuracy: 0.9682 - val_loss: 0.0398 - val_accuracy: 0.9892\n",
            "Epoch 2/3\n",
            "558/558 [==============================] - 54s 97ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.0305 - val_accuracy: 0.9928\n",
            "Epoch 3/3\n",
            "558/558 [==============================] - 54s 97ms/step - loss: 0.0204 - accuracy: 0.9948 - val_loss: 0.0250 - val_accuracy: 0.9919\n"
          ]
        }
      ],
      "source": [
        "pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=3) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OpcuEbyAuIp"
      },
      "outputs": [],
      "source": [
        "train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsfZJw01A0jH"
      },
      "outputs": [],
      "source": [
        "test_predict_labels = pooled_bert_model_unfreeze.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wENCXkfaBQQC",
        "outputId": "f398714a-e5b3-4381-f3dd-11b5c036d6bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8fa93bb990>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# train\n",
        "sns.heatmap(confusion_matrix(np.array(train_y, int), np.array(train_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "4joh3aupBQwG",
        "outputId": "f0ad180d-cb54-40ae-a1f2-6f4c99f70e34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8fa8d68490>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# test\n",
        "sns.heatmap(confusion_matrix(np.array(test_y, int), np.array(test_y_predict.reshape(-1), int)), annot=True, fmt='g')  #annot=True to annotate cells, ftm='g' to disable scientific notation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRs8lu0JA76b",
        "outputId": "7b7bca5b-0917-430b-c7b3-73d0b1339345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT 3e + FCN unfreeze, train data: accuracy = 0.9987, precision = 1.0000, recall = 0.9898, f1 = 0.9949\n",
            "test data: accuracy = 0.9919, precision = 0.9870, recall = 0.9560, f1 = 0.9712\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "print_metrics('BERT 3e + FCN unfreeze, train data', np.array(train_y, int), train_y_predict)\n",
        "# test\n",
        "print_metrics('test data', np.array(test_y, int), test_y_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "_F0aKI--BZ7o",
        "outputId": "64939e45-207a-4eaf-e8ab-56f8b3836aed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7571cefa-b46d-4cc2-810a-d4ff291926c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>Do you ever notice that when you're driving, a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>SMS. ac JSco: Energy is high, but u may not kn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5451</th>\n",
              "      <td>Latest News! Police station toilet stolen, cop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3530</th>\n",
              "      <td>Xmas &amp; New Years Eve tickets are now on sale f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3141</th>\n",
              "      <td>sexy sexy cum and text me im wet and warm and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7571cefa-b46d-4cc2-810a-d4ff291926c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7571cefa-b46d-4cc2-810a-d4ff291926c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7571cefa-b46d-4cc2-810a-d4ff291926c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0\n",
              "2965  Do you ever notice that when you're driving, a...           1\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "1500  SMS. ac JSco: Energy is high, but u may not kn...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "5451  Latest News! Police station toilet stolen, cop...           1\n",
              "3530  Xmas & New Years Eve tickets are now on sale f...           1\n",
              "3141  sexy sexy cum and text me im wet and warm and ...           1"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l9OgX4CCA8m"
      },
      "source": [
        "**Experiment 1 Results:** Unfreezing the BERT model layers helped with increasing the F1 score to 0.9745 on running the model for 3 epochs. The performance on the training set was excellent which may mean that we're slightly overfitting. \n",
        "\n",
        "Because the performance kept improving we may try to run on a couple more epochs to see if overfitting becomes worse and see if we will hit lower performance on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOcZs6nZCwYq",
        "outputId": "b633aee5-db1f-4741-b3a6-b622ee83b91f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# unfreeze layers\n",
        "pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sSSN7ULC1es",
        "outputId": "6ea0122c-675c-4ced-f93e-a08649d89bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_2/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_2/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "558/558 [==============================] - 70s 112ms/step - loss: 0.0707 - accuracy: 0.9780 - val_loss: 0.0374 - val_accuracy: 0.9865\n",
            "Epoch 2/5\n",
            "558/558 [==============================] - 54s 97ms/step - loss: 0.0237 - accuracy: 0.9930 - val_loss: 0.0459 - val_accuracy: 0.9892\n",
            "Epoch 3/5\n",
            "558/558 [==============================] - 54s 98ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0425 - val_accuracy: 0.9857\n",
            "Epoch 4/5\n",
            "558/558 [==============================] - 55s 99ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0303 - val_accuracy: 0.9910\n",
            "Epoch 5/5\n",
            "558/558 [==============================] - 54s 97ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0438 - val_accuracy: 0.9901\n"
          ]
        }
      ],
      "source": [
        "# change to 5 epochs\n",
        "pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                  y_train,   \n",
        "                                                  validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                                  batch_size=8, \n",
        "                                                  epochs=5) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EkvhANcE1R8"
      },
      "outputs": [],
      "source": [
        "train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = train_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3HqKj74EcdL"
      },
      "outputs": [],
      "source": [
        "test_predict_labels = pooled_bert_model_unfreeze.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "5TwzjWs8EM2w",
        "outputId": "fed91877-907b-42b3-8278-ce7f37dc5d99"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8ca83de9-185d-45c7-8c7a-9a7354b95772\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>Do you ever notice that when you're driving, a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4252</th>\n",
              "      <td>Omg Joanna is freaking me out. She's looked th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2493</th>\n",
              "      <td>No drama Pls.i have had enough from you and fa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5451</th>\n",
              "      <td>Latest News! Police station toilet stolen, cop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1638</th>\n",
              "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3432</th>\n",
              "      <td>Yeah if we do have to get a random dude we nee...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1612</th>\n",
              "      <td>645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ca83de9-185d-45c7-8c7a-9a7354b95772')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ca83de9-185d-45c7-8c7a-9a7354b95772 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ca83de9-185d-45c7-8c7a-9a7354b95772');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0\n",
              "2965  Do you ever notice that when you're driving, a...           1\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "4252  Omg Joanna is freaking me out. She's looked th...           0\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "2493  No drama Pls.i have had enough from you and fa...           0\n",
              "5451  Latest News! Police station toilet stolen, cop...           1\n",
              "1638  0A$NETWORKS allow companies to bill for SMS, s...           1\n",
              "3432  Yeah if we do have to get a random dude we nee...           0\n",
              "1612                                                645           0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test\n",
        "missclassified_text = test_X[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "missclassified_label = test_y[np.array(test_y, int) != test_y_predict.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP-dGTD6ExBx",
        "outputId": "d94343df-4c13-459b-aea0-6b66be21eb89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT 5e + FCN unfreeze, train data: : accuracy = 0.9996, precision = 0.9966, recall = 1.0000, f1 = 0.9983\n",
            "test data: : accuracy = 0.9901, precision = 0.9625, recall = 0.9686, f1 = 0.9655\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "print_metrics('BERT 5e + FCN unfreeze, train data: ', np.array(train_y, int), train_y_predict)\n",
        "# test\n",
        "print_metrics('test data: ', np.array(test_y, int), test_y_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLkuzmXNFO08"
      },
      "source": [
        "**Experiment 1 Results:** Increasing the number of epochs to 5 has resulted in some overfitting, we see a degraded performance on the test set in F1 score and increase in the number of misclassified examples. As a result of this experiment BERT model with unfrozen layers and 3 epochs proved to produce really good results. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CIcslSTOgOY"
      },
      "source": [
        "#### BERT + CNN tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJdcEHPfQ3nn"
      },
      "source": [
        "**Experiment 1:** Increase number of epochs and unfreeze BERT layers, not much improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsaCz6dnPDgO",
        "outputId": "02a0ecf1-ee80-44df-f7c2-5ba7e00882e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_3/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_3/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_3/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_3/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "558/558 [==============================] - 79s 110ms/step - loss: 0.0589 - accuracy: 0.9800 - val_loss: 0.0361 - val_accuracy: 0.9892\n",
            "Epoch 2/3\n",
            "558/558 [==============================] - 58s 104ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.0316 - val_accuracy: 0.9910\n",
            "Epoch 3/3\n",
            "558/558 [==============================] - 58s 104ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0522 - val_accuracy: 0.9874\n"
          ]
        }
      ],
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1)\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP7lfF9UQvQZ"
      },
      "outputs": [],
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdvlFabDQcSH",
        "outputId": "507968ce-1d0c-415d-c9c5-65e7037de720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT + CNN, train data: : accuracy = 0.9960, precision = 0.9703, recall = 1.0000, f1 = 0.9849\n",
            "BERT + CNN, test data: : accuracy = 0.9874, precision = 0.9290, recall = 0.9874, f1 = 0.9573\n"
          ]
        }
      ],
      "source": [
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('test data: ', np.array(test_y, int), test_y_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPHddgjfRCcA"
      },
      "source": [
        "**Experiment 2:** Change kernel sizes, from lit review Roy et al. used the following kernel sizes. Kernel sizes improved the model. But now it overfits given that we're running it on 3 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVMinOwPPxU4",
        "outputId": "319f2f74-2305-4601-a920-30fb39ff931b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "558/558 [==============================] - 74s 109ms/step - loss: 0.0660 - accuracy: 0.9773 - val_loss: 0.0292 - val_accuracy: 0.9901\n",
            "Epoch 2/3\n",
            "558/558 [==============================] - 56s 101ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0289 - val_accuracy: 0.9919\n",
            "Epoch 3/3\n",
            "558/558 [==============================] - 52s 93ms/step - loss: 0.0176 - accuracy: 0.9935 - val_loss: 0.0376 - val_accuracy: 0.9901\n"
          ]
        }
      ],
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpLxOK_yRSOP"
      },
      "outputs": [],
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PALsjyI1RS5a",
        "outputId": "27e8a4d3-840e-4482-bc86-6b1566938bd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT 3e + CNN kernel, train data: : accuracy = 0.9973, precision = 0.9800, recall = 1.0000, f1 = 0.9899\n",
            "test data: : accuracy = 0.9901, precision = 0.9568, recall = 0.9748, f1 = 0.9657\n"
          ]
        }
      ],
      "source": [
        "print_metrics('BERT 3e + CNN kernel, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('test data: ', np.array(test_y, int), test_y_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnaafpFDThAp"
      },
      "source": [
        "**Experiment 3:** Decrease the number of filters to offset overfitting and possibly increase performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy32_mv7TMm7",
        "outputId": "07e327b1-8b8a-4009-b739-b726ce18c577"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "558/558 [==============================] - 68s 107ms/step - loss: 0.0726 - accuracy: 0.9769 - val_loss: 0.0379 - val_accuracy: 0.9901\n",
            "Epoch 2/3\n",
            "558/558 [==============================] - 57s 101ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.0784 - val_accuracy: 0.9758\n",
            "Epoch 3/3\n",
            "558/558 [==============================] - 57s 102ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0391 - val_accuracy: 0.9901\n"
          ]
        }
      ],
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5],\n",
        "                                       num_filters = [32,64,128])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVf6Q3ZBUGSJ"
      },
      "outputs": [],
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)\n",
        "\n",
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXC2WoZvVOVn"
      },
      "source": [
        "**Experiment 4:** Run on 2 epochs this supposed to be the best performing BERT + CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMYfOUxaVL0R"
      },
      "outputs": [],
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNYosbLuVr1d"
      },
      "outputs": [],
      "source": [
        "predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "train_y_predict = predict_labels.round(0)\n",
        "test_predict_labels = cnn_bert_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
        "test_y_predict = test_predict_labels.round(0)\n",
        "\n",
        "print_metrics('BERT + CNN, train data: ', np.array(train_y, int), train_y_predict)\n",
        "print_metrics('BERT + CNN, test data: ', np.array(test_y, int), test_y_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhD5Hw9mSisl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZLA2cfwXObdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation"
      ],
      "metadata": {
        "id": "eNgjK_yFak__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BERT + FCN 5e"
      ],
      "metadata": {
        "id": "oDMUjciSdbaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr2peWxTeyP_",
        "outputId": "dde02792-017b-4460-cb10-9c85b5f4ae6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4459"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CROSS_VAL = 5\n",
        "FOLD_SIZE = 891"
      ],
      "metadata": {
        "id": "Q8Dnl_9RfDJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(CROSS_VAL):\n",
        "  max_length = 100              # set max_length\n",
        "\n",
        "  all_train_examples = list(train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]])\n",
        "  all_val_examples = list(train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)])\n",
        "  all_test_examples = list(test_X)\n",
        "\n",
        "  x_train = bert_tokenizer(all_train_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_train = tf.convert_to_tensor(list(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]))\n",
        "\n",
        "  x_test = bert_tokenizer(all_test_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_test = tf.convert_to_tensor(list(test_y))\n",
        "\n",
        "  x_val = bert_tokenizer(all_val_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_val = tf.convert_to_tensor(list(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)]))\n",
        "\n",
        "  # unfreeze layers\n",
        "  pooled_bert_model_unfreeze = create_bert_pooled_model(train_layers=1)\n",
        "\n",
        "  # change to 5 epochs\n",
        "  pooled_bert_model_history = pooled_bert_model_unfreeze.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                                    y_train,   \n",
        "                                                    validation_data=([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask], y_val),    \n",
        "                                                    batch_size=8, \n",
        "                                                    epochs=5) \n",
        "\n",
        "  train_predict_labels = pooled_bert_model_unfreeze.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "  train_y_predict = train_predict_labels.round(0)\n",
        "\n",
        "  val_predict_labels = pooled_bert_model_unfreeze.predict([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask])\n",
        "  val_y_predict = val_predict_labels.round(0)\n",
        "\n",
        "  # train\n",
        "  print_metrics('BERT 5e + FCN, train', np.array(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]], int), train_y_predict)\n",
        "  # validation\n",
        "  print_metrics('BERT 5e + FCN, validation', np.array(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)], int), val_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmUepeNDaleY",
        "outputId": "8cd3a53f-dcb9-413f-9cb8-756c1716de6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_1/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_1/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_1/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 57s 104ms/step - loss: 0.0810 - accuracy: 0.9725 - val_loss: 0.0442 - val_accuracy: 0.9865\n",
            "Epoch 2/5\n",
            "446/446 [==============================] - 44s 98ms/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.0955 - val_accuracy: 0.9663\n",
            "Epoch 3/5\n",
            "446/446 [==============================] - 43s 96ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.0253 - val_accuracy: 0.9933\n",
            "Epoch 4/5\n",
            "446/446 [==============================] - 44s 99ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.0341 - val_accuracy: 0.9933\n",
            "Epoch 5/5\n",
            "446/446 [==============================] - 43s 97ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0282 - val_accuracy: 0.9921\n",
            "BERT 5e + FCN, train: accuracy = 0.9992, precision = 0.9957, recall = 0.9979, f1 = 0.9968\n",
            "BERT 5e + FCN, validation: accuracy = 0.9921, precision = 0.9669, recall = 0.9750, f1 = 0.9710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_2/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_2/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 57s 106ms/step - loss: 0.0942 - accuracy: 0.9691 - val_loss: 0.0336 - val_accuracy: 0.9910\n",
            "Epoch 2/5\n",
            "446/446 [==============================] - 43s 97ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 0.0279 - val_accuracy: 0.9933\n",
            "Epoch 3/5\n",
            "446/446 [==============================] - 43s 96ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.0346 - val_accuracy: 0.9921\n",
            "Epoch 4/5\n",
            "446/446 [==============================] - 43s 97ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0264 - val_accuracy: 0.9899\n",
            "Epoch 5/5\n",
            "446/446 [==============================] - 43s 97ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0352 - val_accuracy: 0.9944\n",
            "BERT 5e + FCN, train: accuracy = 1.0000, precision = 1.0000, recall = 1.0000, f1 = 1.0000\n",
            "BERT 5e + FCN, validation: accuracy = 0.9944, precision = 1.0000, recall = 0.9569, f1 = 0.9780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_3/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_3/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_3/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_3/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 56s 106ms/step - loss: 0.1043 - accuracy: 0.9604 - val_loss: 0.0369 - val_accuracy: 0.9854\n",
            "Epoch 2/5\n",
            "446/446 [==============================] - 43s 97ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.0393 - val_accuracy: 0.9877\n",
            "Epoch 3/5\n",
            "446/446 [==============================] - 43s 96ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0312 - val_accuracy: 0.9899\n",
            "Epoch 4/5\n",
            "446/446 [==============================] - 43s 97ms/step - loss: 0.0118 - accuracy: 0.9952 - val_loss: 0.0348 - val_accuracy: 0.9910\n",
            "Epoch 5/5\n",
            "446/446 [==============================] - 43s 96ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0401 - val_accuracy: 0.9921\n",
            "BERT 5e + FCN, train: accuracy = 0.9994, precision = 1.0000, recall = 0.9956, f1 = 0.9978\n",
            "BERT 5e + FCN, validation: accuracy = 0.9921, precision = 0.9919, recall = 0.9531, f1 = 0.9721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_4/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_4/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_4/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 57s 106ms/step - loss: 0.0831 - accuracy: 0.9725 - val_loss: 0.0417 - val_accuracy: 0.9877\n",
            "Epoch 2/5\n",
            "446/446 [==============================] - 43s 96ms/step - loss: 0.0286 - accuracy: 0.9919 - val_loss: 0.0369 - val_accuracy: 0.9854\n",
            "Epoch 3/5\n",
            "446/446 [==============================] - 44s 98ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0415 - val_accuracy: 0.9899\n",
            "Epoch 4/5\n",
            "446/446 [==============================] - 43s 96ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0362 - val_accuracy: 0.9888\n",
            "Epoch 5/5\n",
            "446/446 [==============================] - 44s 98ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0406 - val_accuracy: 0.9877\n",
            "BERT 5e + FCN, train: accuracy = 0.9989, precision = 0.9937, recall = 0.9979, f1 = 0.9958\n",
            "BERT 5e + FCN, validation: accuracy = 0.9877, precision = 0.9412, recall = 0.9655, f1 = 0.9532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 58s 107ms/step - loss: 0.1139 - accuracy: 0.9574 - val_loss: 0.0203 - val_accuracy: 0.9955\n",
            "Epoch 2/5\n",
            "446/446 [==============================] - 43s 97ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 0.0167 - val_accuracy: 0.9944\n",
            "Epoch 3/5\n",
            "446/446 [==============================] - 55s 124ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0250 - val_accuracy: 0.9933\n",
            "Epoch 4/5\n",
            "446/446 [==============================] - 47s 105ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.0192 - val_accuracy: 0.9933\n",
            "Epoch 5/5\n",
            "446/446 [==============================] - 44s 98ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0213 - val_accuracy: 0.9955\n",
            "BERT 5e + FCN, train: accuracy = 0.9964, precision = 0.9756, recall = 0.9979, f1 = 0.9866\n",
            "BERT 5e + FCN, validation: accuracy = 0.9955, precision = 0.9725, recall = 0.9907, f1 = 0.9815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy = 0.9921, precision = 0.9669, recall = 0.9750, f1 = 0.9710\n",
        "\n",
        "accuracy = 0.9944, precision = 1.0000, recall = 0.9569, f1 = 0.9780\n",
        "\n",
        "accuracy = 0.9921, precision = 0.9919, recall = 0.9531, f1 = 0.9721\n",
        "\n",
        "accuracy = 0.9877, precision = 0.9412, recall = 0.9655, f1 = 0.9532\n",
        "\n",
        "accuracy = 0.9955, precision = 0.9725, recall = 0.9907, f1 = 0.9815"
      ],
      "metadata": {
        "id": "Vju4gkE8d4Fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation results\n",
        "cross_val_acc = [0.9921, 0.9944, 0.9921, 0.9877,0.9955]\n",
        "cross_val_precision = []\n",
        "cross_val_recall = []\n",
        "cross_val_f1 = [0.9710, 0.9780, 0.9721, 0.9532,0.9815]\n",
        "\n",
        "print(\"mean accuracy\", np.mean(cross_val_acc))\n",
        "print(\"mean f1\", np.mean(cross_val_f1))\n",
        "\n",
        "print(\"st dev accuracy\", np.std(cross_val_acc))\n",
        "print(\"se dev f1\", np.std(cross_val_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aT07FT2dyZh",
        "outputId": "28202f9a-03a4-40ce-a34c-602a3fdc990b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy 0.99236\n",
            "mean f1 0.97116\n",
            "st dev accuracy 0.0026785070468453103\n",
            "se dev f1 0.009769053178276785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BERT + CNN 3e un kernel"
      ],
      "metadata": {
        "id": "xQ3-DkwZd9Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(CROSS_VAL):\n",
        "  max_length = 100                # set max_length\n",
        "\n",
        "  all_train_examples = list(train_X.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]])\n",
        "  all_val_examples = list(train_X[FOLD_SIZE*i:FOLD_SIZE*(i+1)])\n",
        "  all_test_examples = list(test_X)\n",
        "\n",
        "  x_train = bert_tokenizer(all_train_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_train = tf.convert_to_tensor(list(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]]))\n",
        "\n",
        "  x_test = bert_tokenizer(all_test_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_test = tf.convert_to_tensor(list(test_y))\n",
        "\n",
        "  x_val = bert_tokenizer(all_val_examples, \n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding='max_length', \n",
        "                return_tensors='tf')\n",
        "\n",
        "  y_val = tf.convert_to_tensor(list(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)]))\n",
        "\n",
        "  cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "  cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)\n",
        "\n",
        "\n",
        "\n",
        "  train_predict_labels = cnn_bert_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask])\n",
        "  train_y_predict = train_predict_labels.round(0)\n",
        "\n",
        "  val_predict_labels = cnn_bert_model.predict([x_val.input_ids, x_val.token_type_ids, x_val.attention_mask])\n",
        "  val_y_predict = val_predict_labels.round(0)\n",
        "\n",
        "  # train\n",
        "  print_metrics('BERT 3e + CNN kernel un, train', np.array(train_y.iloc[np.r_[0:FOLD_SIZE*i,FOLD_SIZE*(i+1):FOLD_SIZE*5]], int), train_y_predict)\n",
        "  # validation\n",
        "  print_metrics('validation', np.array(train_y[FOLD_SIZE*i:FOLD_SIZE*(i+1)], int), val_y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53C7FEsnd9lK",
        "outputId": "c8a22452-f1fa-4b65-e72b-f7d4c2234c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_6/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_6/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_6/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_6/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 68s 117ms/step - loss: 0.0755 - accuracy: 0.9728 - val_loss: 0.0463 - val_accuracy: 0.9892\n",
            "Epoch 2/3\n",
            "446/446 [==============================] - 48s 109ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.0288 - val_accuracy: 0.9928\n",
            "Epoch 3/3\n",
            "446/446 [==============================] - 47s 106ms/step - loss: 0.0153 - accuracy: 0.9938 - val_loss: 0.0294 - val_accuracy: 0.9937\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9997, precision = 1.0000, recall = 0.9979, f1 = 0.9989\n",
            "validation: accuracy = 0.9944, precision = 0.9915, recall = 0.9667, f1 = 0.9789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_7/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_7/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_7/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_7/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 61s 115ms/step - loss: 0.0858 - accuracy: 0.9689 - val_loss: 0.0509 - val_accuracy: 0.9874\n",
            "Epoch 2/3\n",
            "446/446 [==============================] - 48s 108ms/step - loss: 0.0269 - accuracy: 0.9930 - val_loss: 0.0277 - val_accuracy: 0.9937\n",
            "Epoch 3/3\n",
            "446/446 [==============================] - 47s 106ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0281 - val_accuracy: 0.9910\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9994, precision = 0.9979, recall = 0.9979, f1 = 0.9979\n",
            "validation: accuracy = 0.9910, precision = 0.9909, recall = 0.9397, f1 = 0.9646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_8/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_8/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_8/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 62s 115ms/step - loss: 0.0779 - accuracy: 0.9739 - val_loss: 0.0307 - val_accuracy: 0.9901\n",
            "Epoch 2/3\n",
            "446/446 [==============================] - 48s 108ms/step - loss: 0.0272 - accuracy: 0.9896 - val_loss: 0.0303 - val_accuracy: 0.9892\n",
            "Epoch 3/3\n",
            "446/446 [==============================] - 47s 106ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0333 - val_accuracy: 0.9910\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9989, precision = 0.9935, recall = 0.9978, f1 = 0.9957\n",
            "validation: accuracy = 0.9921, precision = 0.9690, recall = 0.9766, f1 = 0.9728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_9/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_9/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_9/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_9/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 62s 119ms/step - loss: 0.0879 - accuracy: 0.9697 - val_loss: 0.0376 - val_accuracy: 0.9874\n",
            "Epoch 2/3\n",
            "446/446 [==============================] - 48s 108ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.0336 - val_accuracy: 0.9928\n",
            "Epoch 3/3\n",
            "446/446 [==============================] - 47s 106ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.0341 - val_accuracy: 0.9928\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9992, precision = 1.0000, recall = 0.9936, f1 = 0.9968\n",
            "validation: accuracy = 0.9933, precision = 1.0000, recall = 0.9483, f1 = 0.9735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_10/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_10/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_10/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_10/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "446/446 [==============================] - 62s 118ms/step - loss: 0.0803 - accuracy: 0.9733 - val_loss: 0.0288 - val_accuracy: 0.9910\n",
            "Epoch 2/3\n",
            "446/446 [==============================] - 49s 109ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.0734 - val_accuracy: 0.9758\n",
            "Epoch 3/3\n",
            "446/446 [==============================] - 48s 107ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.0364 - val_accuracy: 0.9919\n",
            "BERT 3e + CNN kernel un, train: accuracy = 0.9992, precision = 0.9938, recall = 1.0000, f1 = 0.9969\n",
            "validation: accuracy = 0.9955, precision = 0.9813, recall = 0.9813, f1 = 0.9813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy = 0.9944, precision = 0.9915, recall = 0.9667, f1 = 0.9789\n",
        "\n",
        "accuracy = 0.9910, precision = 0.9909, recall = 0.9397, f1 = 0.9646\n",
        "\n",
        "accuracy = 0.9921, precision = 0.9690, recall = 0.9766, f1 = 0.9728\n",
        "\n",
        "accuracy = 0.9933, precision = 1.0000, recall = 0.9483, f1 = 0.9735\n",
        "\n",
        "accuracy = 0.9955, precision = 0.9813, recall = 0.9813, f1 = 0.9813"
      ],
      "metadata": {
        "id": "VSnJBZKzeXlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation results\n",
        "cross_val_acc = [0.9944,0.9910,0.9921,0.9933,0.9955]\n",
        "cross_val_precision = []\n",
        "cross_val_recall = []\n",
        "cross_val_f1 = [0.9789, 0.9646, 0.9728, 0.9735, 0.9813]\n",
        "\n",
        "print(\"mean accuracy\", np.mean(cross_val_acc))\n",
        "print(\"mean f1\", np.mean(cross_val_f1))\n",
        "\n",
        "print(\"st dev accuracy\", np.std(cross_val_acc))\n",
        "print(\"se dev f1\", np.std(cross_val_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKQvDt_leYK-",
        "outputId": "b0d013fe-f982-492d-838d-70b88778b394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy 0.99326\n",
            "mean f1 0.9742200000000001\n",
            "st dev accuracy 0.0015982490419205759\n",
            "se dev f1 0.0057811417557433915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train on just UCI and test on both"
      ],
      "metadata": {
        "id": "oYVOiLtVCVN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_all = pd.read_csv(\"/content/drive/MyDrive/W266: SMS Spam Detection Final Project/data/data_clean_trans.csv\")\n",
        "data_all"
      ],
      "metadata": {
        "id": "2Gv7uyDhqH_0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "99620d2a-1d8c-4813-faa4-a7b10a961119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  spam                                               text  \\\n",
              "0              0     0  Go until jurong point, crazy.. Available only ...   \n",
              "1              1     0                    Ok lar... Joking wif u oni...\\n   \n",
              "2              2     1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3              3     0  U dun say so early hor... U c already then say...   \n",
              "4              4     0  Nah I don't think he goes to usf, he lives aro...   \n",
              "...          ...   ...                                                ...   \n",
              "6102        6102     1  You have passed the official certification onl...   \n",
              "6103        6103     1  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...   \n",
              "6104        6104     1  Hi, I'm a Shopee Hiring Manager and I'm curren...   \n",
              "6105        6105     1  4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...   \n",
              "6106        6106     1  Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...   \n",
              "\n",
              "      crowd                                            spanish language  \\\n",
              "0         0  Vaya hasta Jurong Point, loco ... disponible s...       en   \n",
              "1         0               Ok lar ... bromeando wif u oni ...\\n       en   \n",
              "2         0  Entrada gratuita en 2 una compensación de wkly...       en   \n",
              "3         0    No digo tan temprano hor ... ya c ya digo ...\\n       en   \n",
              "4         0  No, no creo que vaya a la USF, aunque vive por...       en   \n",
              "...     ...                                                ...      ...   \n",
              "6102      1  Ha aprobado la certificación oficial de la aud...       en   \n",
              "6103      1  ¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...       en   \n",
              "6104      1  Hola, soy un gerente de contratación de Shopee...       en   \n",
              "6105      1  ¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...      fil   \n",
              "6106      1  Sissy, solo 1p por apuesta para Cutt.ly/BingOp...      fil   \n",
              "\n",
              "                                                english  \n",
              "0     Go until jurong point, crazy.. Available only ...  \n",
              "1                       Ok lar... Joking wif u oni...\\n  \n",
              "2     Free entry in 2 a wkly comp to win FA Cup fina...  \n",
              "3     U dun say so early hor... U c already then say...  \n",
              "4     Nah I don't think he goes to usf, he lives aro...  \n",
              "...                                                 ...  \n",
              "6102  You have passed the official certification onl...  \n",
              "6103  Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...  \n",
              "6104  Hi, I'm a Shopee Hiring Manager and I'm curren...  \n",
              "6105  4 pcs solar lights for only 1,499!\\nMost cheap...  \n",
              "6106  Sissy, just 1p per bet for cutt.ly/bingoplus-p...  \n",
              "\n",
              "[6107 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51f259a9-d9ba-44db-8fc5-21aac4dbfe7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>spam</th>\n",
              "      <th>text</th>\n",
              "      <th>crowd</th>\n",
              "      <th>spanish</th>\n",
              "      <th>language</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Vaya hasta Jurong Point, loco ... disponible s...</td>\n",
              "      <td>en</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar ... bromeando wif u oni ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>0</td>\n",
              "      <td>Entrada gratuita en 2 una compensación de wkly...</td>\n",
              "      <td>en</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "      <td>No digo tan temprano hor ... ya c ya digo ...\\n</td>\n",
              "      <td>en</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "      <td>No, no creo que vaya a la USF, aunque vive por...</td>\n",
              "      <td>en</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6102</th>\n",
              "      <td>6102</td>\n",
              "      <td>1</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "      <td>1</td>\n",
              "      <td>Ha aprobado la certificación oficial de la aud...</td>\n",
              "      <td>en</td>\n",
              "      <td>You have passed the official certification onl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6103</th>\n",
              "      <td>6103</td>\n",
              "      <td>1</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡Gana la gran j@ckp0t hasta 1 m php! 100 Get 1...</td>\n",
              "      <td>en</td>\n",
              "      <td>Win The Big J@CKP0T Up To 1M PHP! 100 GET 100,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6104</th>\n",
              "      <td>6104</td>\n",
              "      <td>1</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "      <td>1</td>\n",
              "      <td>Hola, soy un gerente de contratación de Shopee...</td>\n",
              "      <td>en</td>\n",
              "      <td>Hi, I'm a Shopee Hiring Manager and I'm curren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6105</th>\n",
              "      <td>6105</td>\n",
              "      <td>1</td>\n",
              "      <td>4 PCS SOLAR LIGHTS FOR ONLY 1,499 !\\nPinaka mu...</td>\n",
              "      <td>1</td>\n",
              "      <td>¡4 PCS Luces solares por solo 1,499!\\n¡La mayo...</td>\n",
              "      <td>fil</td>\n",
              "      <td>4 pcs solar lights for only 1,499!\\nMost cheap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6106</th>\n",
              "      <td>6106</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, 1P lang per bet kay cutt.ly/BingoPlus-P...</td>\n",
              "      <td>1</td>\n",
              "      <td>Sissy, solo 1p por apuesta para Cutt.ly/BingOp...</td>\n",
              "      <td>fil</td>\n",
              "      <td>Sissy, just 1p per bet for cutt.ly/bingoplus-p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6107 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51f259a9-d9ba-44db-8fc5-21aac4dbfe7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51f259a9-d9ba-44db-8fc5-21aac4dbfe7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51f259a9-d9ba-44db-8fc5-21aac4dbfe7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data_all['text'], data_all['spam']\n",
        "\n",
        "train_X_all, test_X_all, train_y_all, test_y_all = train_test_split(X, y, \n",
        "                                                    train_size=0.8,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123,\n",
        "                                                    shuffle=True)"
      ],
      "metadata": {
        "id": "pHqXUya2DFUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_test_examples_all = list(test_X_all)\n",
        "\n",
        "\n",
        "x_test_all = bert_tokenizer(all_test_examples_all, \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test_all = tf.convert_to_tensor(list(test_y_all))"
      ],
      "metadata": {
        "id": "E7jVMDlfDs3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_bert_model = create_bert_cnn_model(train_layers=1,\n",
        "                                       kernel_sizes = [2, 3, 4, 5])\n",
        "\n",
        "cnn_bert_model_history = cnn_bert_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
        "                                            y_train,   \n",
        "                                            validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], y_test),    \n",
        "                                            batch_size=8, \n",
        "                                            epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CMCizZpErfl",
        "outputId": "72d77018-58da-4870-8830-33697688c936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_2/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model_2/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model_2/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model_2/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "558/558 [==============================] - 61s 90ms/step - loss: 0.0801 - accuracy: 0.9726 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
            "Epoch 2/3\n",
            "558/558 [==============================] - 48s 85ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 0.0367 - val_accuracy: 0.9910\n",
            "Epoch 3/3\n",
            "558/558 [==============================] - 47s 84ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.0364 - val_accuracy: 0.9928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict_labels_all = cnn_bert_model.predict([x_test_all.input_ids, x_test_all.token_type_ids, x_test_all.attention_mask])\n",
        "test_y_predict_all = test_predict_labels_all.round(0)\n",
        "\n",
        "print_metrics('test data: ', np.array(test_y_all, int), test_y_predict_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4h8o7AtEdqG",
        "outputId": "803c7379-29dd-462b-8560-44f7659f5ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test data: : accuracy = 0.9820, precision = 0.9918, recall = 0.9240, f1 = 0.9567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "missclassified_text = test_X_all[np.array(test_y_all, int) != test_y_predict_all.reshape(-1)]\n",
        "missclassified_label = test_y_all[np.array(test_y_all, int) != test_y_predict_all.reshape(-1)]\n",
        "\n",
        "df_report = pd.DataFrame({'missclassified_text': missclassified_text, 'true_label': missclassified_label})\n",
        "\n",
        "df_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "n-if969XFSXf",
        "outputId": "7e1608d9-a8e1-40c5-d2d5-9d7ff428b954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    missclassified_text  true_label\n",
              "5704  Makakatanggap ka ng 5000 cash! Pumunta lang sa...           1\n",
              "5667  Keep safe and let me assist you to have a CÀSH...           1\n",
              "5738  Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst & eà...           1\n",
              "2663  Hello darling how are you today? I would love ...           1\n",
              "5701  Sino gusto matampal ng 5M, ako din char! Tara ...           1\n",
              "5996  Pinas Baon na sa 11.6 Trilyon utang sa 5 taon ...           1\n",
              "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...           0\n",
              "5914  Hi'im Ram offering  Personal cashloan for Empl...           1\n",
              "5581                                                N/a           1\n",
              "5783  50k - 2M is the offer just inquire now get it ...           1\n",
              "5577  GOOD DAY REFERENCES!                          ...           1\n",
              "6008  Daghang salamat sa suporta ug pagsalig nga iny...           1\n",
              "5799  You will get an income of 240 to 700 pesos for...           1\n",
              "6066  Woodsville Residences\\nin Merville Paranaque\\n...           1\n",
              "2774  How come it takes so little time for a child w...           1\n",
              "5578  Mag laro at kumita habang nasa bahay Lang! Win...           1\n",
              "5959  Maligayang Linggo Sa Bvvin, Best Slots Platfor...           1\n",
              "4298  thesmszone.com lets you send free anonymous an...           1\n",
              "6068  Keep safe and let me assist you to have a CÀSH...           1\n",
              "5709  Need additional funds? We process bank cashloa...           1\n",
              "3094  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...           0\n",
              "5668  Ang aking pangarap sa para ating bansa ay ipag...           1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2fa20b1-fef0-4964-96c6-8e6ed290730d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missclassified_text</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5704</th>\n",
              "      <td>Makakatanggap ka ng 5000 cash! Pumunta lang sa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5667</th>\n",
              "      <td>Keep safe and let me assist you to have a CÀSH...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>Hi! Wànt to àvàil Our Pèrsonàl Loàn? Fàst &amp; eà...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2663</th>\n",
              "      <td>Hello darling how are you today? I would love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5701</th>\n",
              "      <td>Sino gusto matampal ng 5M, ako din char! Tara ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>Pinas Baon na sa 11.6 Trilyon utang sa 5 taon ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUN...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5914</th>\n",
              "      <td>Hi'im Ram offering  Personal cashloan for Empl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5581</th>\n",
              "      <td>N/a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5783</th>\n",
              "      <td>50k - 2M is the offer just inquire now get it ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5577</th>\n",
              "      <td>GOOD DAY REFERENCES!                          ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6008</th>\n",
              "      <td>Daghang salamat sa suporta ug pagsalig nga iny...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5799</th>\n",
              "      <td>You will get an income of 240 to 700 pesos for...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6066</th>\n",
              "      <td>Woodsville Residences\\nin Merville Paranaque\\n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>How come it takes so little time for a child w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5578</th>\n",
              "      <td>Mag laro at kumita habang nasa bahay Lang! Win...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5959</th>\n",
              "      <td>Maligayang Linggo Sa Bvvin, Best Slots Platfor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298</th>\n",
              "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6068</th>\n",
              "      <td>Keep safe and let me assist you to have a CÀSH...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5709</th>\n",
              "      <td>Need additional funds? We process bank cashloa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3094</th>\n",
              "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5668</th>\n",
              "      <td>Ang aking pangarap sa para ating bansa ay ipag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2fa20b1-fef0-4964-96c6-8e6ed290730d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2fa20b1-fef0-4964-96c6-8e6ed290730d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2fa20b1-fef0-4964-96c6-8e6ed290730d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z3H4BFEPHNIo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MySc4TsBTRdT",
        "HCn1BoEaPA6E",
        "JqfIxHLRPFqv",
        "w1IBwZ6ibHQh",
        "nvR_4nFjOZ8W",
        "wcXX9CM28l71",
        "scIsHg775HLa"
      ],
      "name": "W266: UCI Dataset SMS Spam Detection Final Project.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72aa9602f1fc4111a2f4370f3a5cd6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3380740f7137429da91d072d583f6e28",
              "IPY_MODEL_e214fc2b31a741c0a895fe2f63745d86",
              "IPY_MODEL_60dda7bfe9fe4c5c9f0fbcd8d572c4e2"
            ],
            "layout": "IPY_MODEL_b0aa6662e8a14c7fa380c178bfab05ec"
          }
        },
        "3380740f7137429da91d072d583f6e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2cf02f9a7348fa83ddb4a325fd5f01",
            "placeholder": "​",
            "style": "IPY_MODEL_03c5533f119048eab4847567772d8e06",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "e214fc2b31a741c0a895fe2f63745d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d7c7c60d4c4032b7d64414f91e8e67",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dbd12d433c64074ac802c05ae7cab8a",
            "value": 213450
          }
        },
        "60dda7bfe9fe4c5c9f0fbcd8d572c4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565832ee669445558191d878390a116c",
            "placeholder": "​",
            "style": "IPY_MODEL_17086c6a0f1a45ccad9883be90d55f7c",
            "value": " 208k/208k [00:00&lt;00:00, 315kB/s]"
          }
        },
        "b0aa6662e8a14c7fa380c178bfab05ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd2cf02f9a7348fa83ddb4a325fd5f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c5533f119048eab4847567772d8e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9d7c7c60d4c4032b7d64414f91e8e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dbd12d433c64074ac802c05ae7cab8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "565832ee669445558191d878390a116c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17086c6a0f1a45ccad9883be90d55f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98e654930b4b425292bfd7ade8d5b0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1b7a7c548d24c71bb8aeac88fc210dd",
              "IPY_MODEL_1dd1de7a2bcf402e864d0723f3c318dd",
              "IPY_MODEL_13352a21c9624704874f4ca2a76cca00"
            ],
            "layout": "IPY_MODEL_09c58eeda1fd443cac48cd1e99c3b1dc"
          }
        },
        "e1b7a7c548d24c71bb8aeac88fc210dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbccaf3a19e14cad91eeb04855ff69cd",
            "placeholder": "​",
            "style": "IPY_MODEL_7d3c5038064b4f829cca8b8bcf67600e",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "1dd1de7a2bcf402e864d0723f3c318dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4afac3b1b08b4faa8ebd9f4ca366a824",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20cee5c9cbaf4e0685add696e31a5a8c",
            "value": 29
          }
        },
        "13352a21c9624704874f4ca2a76cca00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef7ed115d644605b62357d0ab454368",
            "placeholder": "​",
            "style": "IPY_MODEL_9e58bc2b8c7c4bcd94c560b9daaa9ddc",
            "value": " 29.0/29.0 [00:00&lt;00:00, 405B/s]"
          }
        },
        "09c58eeda1fd443cac48cd1e99c3b1dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbccaf3a19e14cad91eeb04855ff69cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3c5038064b4f829cca8b8bcf67600e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4afac3b1b08b4faa8ebd9f4ca366a824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20cee5c9cbaf4e0685add696e31a5a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fef7ed115d644605b62357d0ab454368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e58bc2b8c7c4bcd94c560b9daaa9ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "721128853fc74edba61276522807272f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6bc4b25770047f298037f5584a24095",
              "IPY_MODEL_ec0aaa1a8b9746758f49e397ae4288c4",
              "IPY_MODEL_3a78ec5f622a499499ebc6c72a9316f1"
            ],
            "layout": "IPY_MODEL_a04e5ad4615a4d55b661d60be4637690"
          }
        },
        "e6bc4b25770047f298037f5584a24095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6eacf4631484979b512665c5a13ba96",
            "placeholder": "​",
            "style": "IPY_MODEL_2fff2bd4dae24af793d3cb4bb30a38cb",
            "value": "Downloading config.json: 100%"
          }
        },
        "ec0aaa1a8b9746758f49e397ae4288c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_249a2a9483864f499eaff52be920bbad",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c55417ea7f841ccb45912ded0e54eb3",
            "value": 570
          }
        },
        "3a78ec5f622a499499ebc6c72a9316f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d4188faa5654ca98a296df6c561d07c",
            "placeholder": "​",
            "style": "IPY_MODEL_e8fc1e9d63c944e39fb76bf0ebdfa28e",
            "value": " 570/570 [00:00&lt;00:00, 7.84kB/s]"
          }
        },
        "a04e5ad4615a4d55b661d60be4637690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6eacf4631484979b512665c5a13ba96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fff2bd4dae24af793d3cb4bb30a38cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "249a2a9483864f499eaff52be920bbad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c55417ea7f841ccb45912ded0e54eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d4188faa5654ca98a296df6c561d07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8fc1e9d63c944e39fb76bf0ebdfa28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d79935c0c6e4ef496eca79a4941af4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e84330ae695a46de99ccec3177deed4c",
              "IPY_MODEL_07b3251799fb46b89488693c6d76368e",
              "IPY_MODEL_6229e18cc5cb4fee868da38698cad140"
            ],
            "layout": "IPY_MODEL_c9b2872b41354420b19a97b9ec44ea59"
          }
        },
        "e84330ae695a46de99ccec3177deed4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95dd35e71ff646b99e09f672d8ced572",
            "placeholder": "​",
            "style": "IPY_MODEL_2f16a1d21074403981b09b38b56d7cac",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "07b3251799fb46b89488693c6d76368e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d9f7184e2844929bfd2d6e612841e3",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28a509de4a804cca93c5b1392d3aa644",
            "value": 526681800
          }
        },
        "6229e18cc5cb4fee868da38698cad140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_518060ca3beb4750886a47badf0c93b6",
            "placeholder": "​",
            "style": "IPY_MODEL_b7b24797ccd44bfe904b9dbb44923bc0",
            "value": " 502M/502M [00:11&lt;00:00, 60.4MB/s]"
          }
        },
        "c9b2872b41354420b19a97b9ec44ea59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95dd35e71ff646b99e09f672d8ced572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f16a1d21074403981b09b38b56d7cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33d9f7184e2844929bfd2d6e612841e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28a509de4a804cca93c5b1392d3aa644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "518060ca3beb4750886a47badf0c93b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b24797ccd44bfe904b9dbb44923bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}